{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMOQ5LlUoi6J"
      },
      "source": [
        "# Catboost Modelling\n",
        "\n",
        "In this notebook, a final sales forecasting model based on the CatBoost algorithm is created. More information can be found here: https://catboost.ai/\n",
        "\n",
        "Just as the Random Forest model, the final model is also a tree-based model. These types of algorithms lend themselves well to predicting target features that are not normally distributed, as is the case with sales here. Moreover, CatBoost is specifically tailored to datasets with many categorical variables. With the expception of weather and lag variables, this dataset mainly contains categorical features, including dummy variables.\n",
        "\n",
        "Given the flexibility of CatBoost, no additional preprocessing is necessary. It can handle object (categorical) variables, missing values and responds well to non-normally distributed target variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NpIqYpvCouyT",
        "outputId": "c36acd81-9d83-436c-f666-d81c19ca1cab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.5-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting sktime\n",
            "  Downloading sktime-0.31.0-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.1.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: joblib<1.5,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from sktime) (1.4.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from sktime) (24.1)\n",
            "Collecting scikit-base<0.9.0,>=0.6.1 (from sktime)\n",
            "  Downloading scikit_base-0.8.2-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: scikit-learn<1.6.0,>=0.24 in /usr/local/lib/python3.10/dist-packages (from sktime) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.6.0,>=0.24->sktime) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Downloading catboost-1.2.5-cp310-cp310-manylinux2014_x86_64.whl (98.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sktime-0.31.0-py3-none-any.whl (24.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_base-0.8.2-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.1/134.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-base, sktime, catboost\n",
            "Successfully installed catboost-1.2.5 scikit-base-0.8.2 sktime-0.31.0\n"
          ]
        }
      ],
      "source": [
        "pip install catboost sktime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jWL5gZXnoi6N"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "s:\\Repos\\sweet-spot-donut-sales-forecasting\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as md\n",
        "from matplotlib.patches import Patch\n",
        "import seaborn as sns\n",
        "import datetime as dt\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder, RobustScaler, FunctionTransformer, PolynomialFeatures, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import cross_val_score, RandomizedSearchCV\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.metrics import mean_absolute_percentage_error, r2_score, mean_squared_error\n",
        "import sktime \n",
        "\n",
        "from sklearn.model_selection import TimeSeriesSplit, StratifiedKFold\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "\n",
        "from catboost import CatBoostRegressor\n",
        "import catboost as cb\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "#sktime libraries\n",
        "\n",
        "from sktime.forecasting.compose import make_reduction, ForecastingPipeline, TransformedTargetForecaster\n",
        "from sktime.forecasting.base import ForecastingHorizon\n",
        "from sktime.split import ExpandingWindowSplitter\n",
        "from sktime.utils import plot_windows, plot_series\n",
        "from sktime.transformations.series.summarize import WindowSummarizer\n",
        "from sktime.transformations.series.func_transform import FunctionTransformer as ft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "LeoCBXAusCl5",
        "outputId": "753bb5a2-e21e-4f7c-e290-6b558648945d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "UNRAR 6.11 beta 1 freeware      Copyright (c) 1993-2022 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from drive/MyDrive/sweet-spot-donut-sales-forecasting.rar\n",
            "\n",
            "Extracting  functions_model.py                                           \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  functions_vis.py                                             \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  train_df.csv                                                 \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  test_df.csv                                                  \b\b\b\b100%\b\b\b\b\b  OK \n",
            "All OK\n"
          ]
        }
      ],
      "source": [
        "# for google colab\n",
        "#!unrar x drive/MyDrive/sweet-spot-donut-sales-forecasting.rar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Enabling notebook extension jupyter-js-widgets/extension...\n",
            "      - Validating: ok\n"
          ]
        }
      ],
      "source": [
        "! jupyter nbextension enable widgetsnbextension --py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NJh4XCwgoi6Q"
      },
      "outputs": [],
      "source": [
        "%run functions_model.py\n",
        "%run functions_vis.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "K5Th4bCJoi6S"
      },
      "outputs": [],
      "source": [
        "pd.set_option(\"display.max_columns\", None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdAhO38aoi6V"
      },
      "source": [
        "### Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Goy3_YPzoi6X"
      },
      "outputs": [],
      "source": [
        "d = pd.read_csv(\"data/train_df.csv\")\n",
        "d_test = pd.read_csv(\"data/test_df.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HbaM85-yoi6a"
      },
      "outputs": [],
      "source": [
        "d['date'] = pd.to_datetime(d['date'])\n",
        "d_test['date'] = pd.to_datetime(d_test['date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sx3k4q66oi6g"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mpKeEweoi6g"
      },
      "source": [
        "## Modelling\n",
        "\n",
        "#### Selecting features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1ZJnbG2oi6g"
      },
      "source": [
        "In order for the CatBoost algorithm to recognize categorical features, all variables are saved either as categorical or numerical. The date variable will serve as the index, while the lag features will only be used in the training and validation, but not the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fbnDqc_8oi6h"
      },
      "outputs": [],
      "source": [
        "date = [\"date\"]\n",
        "\n",
        "catfeat = [\"store_name\",\"item_category\",'box_deal', 'day', 'halloween', 'hol_pub', 'hol_school',\n",
        "       'month', 'nye', 'public_space', 'street_market', 'valentines_day','week_year', 'weekday', 'year']\n",
        "\n",
        "numfeat = [\"days_back\",\"temperature_2m_mean\",\"sunshine_duration\",\"precipitation_hours\"]\n",
        "\n",
        "lag = [\"lag1\",\"lag2\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qYhUpRooi6i"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbPrK3t5oi6i"
      },
      "source": [
        "Two types of sets were created:\n",
        "\n",
        "1. The first type of train, validation and test datasets contains all features at the day, store and product level.\n",
        "2. The second type contains all features only at the day and store level. The different product categories were removed and **only total daily sales** per store are kept."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "3uckxYISoi6i"
      },
      "outputs": [],
      "source": [
        "x_train = d[date + catfeat + numfeat + lag]\n",
        "x_train = x_train.set_index(\"date\")\n",
        "x_train_daily = x_train[(x_train[\"item_category\"] == \"daily total\")].drop(\"item_category\", axis = 1)\n",
        "y_train = d['total_amount']\n",
        "y_train_daily = d[(d[\"item_category\"] == \"daily total\")]['total_amount']\n",
        "\n",
        "#x_val = val[date + catfeat + numfeat + lag]\n",
        "#x_val = x_val.set_index(\"date\")\n",
        "#x_val_daily = x_val[(x_val[\"item_category\"] == \"daily total\")].drop(\"item_category\", axis = 1)\n",
        "#y_val = val['total_amount']\n",
        "#y_val_daily = val[(val[\"item_category\"] == \"daily total\") ]['total_amount']\n",
        "\n",
        "x_test = d_test[date + catfeat + numfeat]\n",
        "x_test = x_test.set_index(\"date\")\n",
        "x_test_daily = x_test[(x_test[\"item_category\"] == \"daily total\")].drop(\"item_category\", axis = 1)\n",
        "y_test = d_test['total_amount']\n",
        "y_test_daily = d_test[(d_test[\"item_category\"] == \"daily total\")]['total_amount']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7g1ngKHCoi6k"
      },
      "outputs": [],
      "source": [
        "#catfeat.remove(\"item_category\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhi1ERA9oi6l"
      },
      "source": [
        "#### Converting holiday features to integer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3yIzzsZFoi6l"
      },
      "outputs": [],
      "source": [
        "x_train[\"hol_pub\"] = x_train[\"hol_pub\"].apply(np.int64)\n",
        "x_train[\"hol_school\"] = x_train[\"hol_school\"].apply(np.int64)\n",
        "x_train_daily[\"hol_pub\"] = x_train_daily[\"hol_pub\"].apply(np.int64)\n",
        "x_train_daily[\"hol_school\"] = x_train_daily[\"hol_school\"].apply(np.int64)\n",
        "\n",
        "x_val[\"hol_pub\"] = x_val[\"hol_pub\"].apply(np.int64)\n",
        "x_val[\"hol_school\"] = x_val[\"hol_school\"].apply(np.int64)\n",
        "x_val_daily[\"hol_pub\"] = x_val_daily[\"hol_pub\"].apply(np.int64)\n",
        "x_val_daily[\"hol_school\"] = x_val_daily[\"hol_school\"].apply(np.int64)\n",
        "\n",
        "x_test[\"hol_pub\"] = x_test[\"hol_pub\"].apply(np.int64)\n",
        "x_test[\"hol_school\"] = x_test[\"hol_school\"].apply(np.int64)\n",
        "x_test_daily[\"hol_pub\"] = x_test_daily[\"hol_pub\"].apply(np.int64)\n",
        "x_test_daily[\"hol_school\"] = x_test_daily[\"hol_school\"].apply(np.int64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-b8ak7JYoi6m"
      },
      "source": [
        "The train and target variables are concatenated to obtain a train and test set at the daily sales level, without the individual product categories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "IF2h8-6zoi6m"
      },
      "outputs": [],
      "source": [
        "train_daily = pd.concat([x_train_daily.reset_index(), y_train_daily.reset_index(drop= True)], axis = 1)\n",
        "\n",
        "test_daily = pd.concat([x_test_daily.reset_index(), y_test_daily.reset_index(drop= True)], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFYa-1u0oi6m"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0f1X2-Uoi6p"
      },
      "source": [
        "### Hyperparameter Tuning with Cross-validation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlMaMNKDoi6q"
      },
      "source": [
        "Training tree-based algorithm often leads to overfitting. In order to create a generalizable model, it is necessary to \"prune\" the trees by putting constraints on how well they can learn from the data. The following hyperparameters are tuned in the step below:\n",
        "\n",
        "* Number of trees\n",
        "* Learning rate\n",
        "* L2 leaf regularization\n",
        "* Tree depth (number of levels)\n",
        "* Proportion of the sample used for each tree\n",
        "* Proportion of the features used for each tree\n",
        "* A minimum amount of datapoints in a leaf before a split can occur\n",
        "* Minimum child weight\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nnfCo15Aoi6s"
      },
      "outputs": [],
      "source": [
        "d2 = d[date + catfeat + numfeat]\n",
        "#d2 = d2[d2[\"item_category\"] != \"daily total\"]\n",
        "d2 = pd.concat([d2, d[\"total_amount\"]], axis = 1)\n",
        "\n",
        "d_test2 = d_test[date + catfeat + numfeat]\n",
        "#d_test2 = d_test2[d_test2[\"item_category\"] != \"daily total\"]\n",
        "d_test2 = pd.concat([d_test2, d_test[\"total_amount\"]], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "29aQRGg_oi6t"
      },
      "outputs": [],
      "source": [
        "agg_columns = d2.columns.difference(['date', 'store_name', 'item_category'] + [\"total_amount\"])\n",
        "agg_dict = {col: \"first\" for col in agg_columns}\n",
        "agg_dict[\"total_amount\"] = \"sum\"\n",
        "\n",
        "d2 = d2.groupby(['date', 'store_name', 'item_category']).agg(agg_dict).reset_index().sort_values(by = \"date\", ascending = False).reset_index(drop = True)\n",
        "d2[\"hol_pub\"] = d2[\"hol_pub\"].apply(np.int64)\n",
        "d2[\"hol_school\"] = d2[\"hol_school\"].apply(np.int64)\n",
        "\n",
        "d2 = d2.set_index([\"store_name\",\"item_category\",\"date\"]).sort_index()\n",
        "\n",
        "d_test2 = d_test2.groupby(['date', 'store_name', 'item_category']).agg(agg_dict).reset_index().sort_values(by = \"date\", ascending = False).reset_index(drop = True)\n",
        "d_test2[\"hol_pub\"] = d_test2[\"hol_pub\"].apply(np.int64)\n",
        "d_test2[\"hol_school\"] = d_test2[\"hol_school\"].apply(np.int64)\n",
        "\n",
        "d_test2 = d_test2.set_index([\"store_name\",\"item_category\",\"date\"]).sort_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "kwargs = {\"lag_feature\": {\n",
        "    \"lag\":[1,2,3],\n",
        "    \"mean\": [[1,7], [1, 15], [1,30]],\n",
        "    \"std\": [[1,4]]\n",
        "    },\n",
        "    \"target_cols\":[\"total_amount\"]}\n",
        "\n",
        "transformer = WindowSummarizer(**kwargs, n_jobs= -1)\n",
        "\n",
        "model = CatBoostRegressor(n_estimators = 2620, learning_rate = 0.0487,\n",
        " depth = 5, subsample = 0.21, colsample_bylevel = 0.2, min_data_in_leaf = 21)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "d2wind = transformer.fit_transform(d2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "d2wind = pd.concat([d2[\"total_amount\"], d2wind], axis = 1).dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 358,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\tlearn: 463.1739659\ttotal: 12.7ms\tremaining: 33.3s\n",
            "1:\tlearn: 447.6628938\ttotal: 29.1ms\tremaining: 38.1s\n",
            "2:\tlearn: 432.8616989\ttotal: 53.8ms\tremaining: 46.9s\n",
            "3:\tlearn: 418.4171371\ttotal: 64.9ms\tremaining: 42.4s\n",
            "4:\tlearn: 404.7011832\ttotal: 90.5ms\tremaining: 47.3s\n",
            "5:\tlearn: 392.4990144\ttotal: 118ms\tremaining: 51.5s\n",
            "6:\tlearn: 380.0322046\ttotal: 143ms\tremaining: 53.2s\n",
            "7:\tlearn: 368.3872075\ttotal: 166ms\tremaining: 54.3s\n",
            "8:\tlearn: 358.0401636\ttotal: 192ms\tremaining: 55.8s\n",
            "9:\tlearn: 348.2439300\ttotal: 222ms\tremaining: 57.9s\n",
            "10:\tlearn: 338.6413138\ttotal: 246ms\tremaining: 58.3s\n",
            "11:\tlearn: 329.8456769\ttotal: 267ms\tremaining: 58s\n",
            "12:\tlearn: 321.7016987\ttotal: 283ms\tremaining: 56.7s\n",
            "13:\tlearn: 314.2067543\ttotal: 302ms\tremaining: 56.2s\n",
            "14:\tlearn: 307.5952681\ttotal: 318ms\tremaining: 55.3s\n",
            "15:\tlearn: 298.9921798\ttotal: 348ms\tremaining: 56.6s\n",
            "16:\tlearn: 291.3927554\ttotal: 378ms\tremaining: 57.8s\n",
            "17:\tlearn: 283.6377462\ttotal: 413ms\tremaining: 59.7s\n",
            "18:\tlearn: 278.6122463\ttotal: 425ms\tremaining: 58.2s\n",
            "19:\tlearn: 271.4682857\ttotal: 458ms\tremaining: 59.5s\n",
            "20:\tlearn: 266.3209870\ttotal: 478ms\tremaining: 59.2s\n",
            "21:\tlearn: 260.9074551\ttotal: 499ms\tremaining: 58.9s\n",
            "22:\tlearn: 254.5714652\ttotal: 528ms\tremaining: 59.6s\n",
            "23:\tlearn: 254.5714444\ttotal: 531ms\tremaining: 57.4s\n",
            "24:\tlearn: 250.3311179\ttotal: 552ms\tremaining: 57.3s\n",
            "25:\tlearn: 245.1367934\ttotal: 574ms\tremaining: 57.3s\n",
            "26:\tlearn: 241.0877162\ttotal: 591ms\tremaining: 56.8s\n",
            "27:\tlearn: 236.1294302\ttotal: 617ms\tremaining: 57.1s\n",
            "28:\tlearn: 232.4049805\ttotal: 634ms\tremaining: 56.6s\n",
            "29:\tlearn: 228.8214738\ttotal: 653ms\tremaining: 56.4s\n",
            "30:\tlearn: 226.2723867\ttotal: 674ms\tremaining: 56.3s\n",
            "31:\tlearn: 223.7362236\ttotal: 701ms\tremaining: 56.7s\n",
            "32:\tlearn: 219.9423349\ttotal: 723ms\tremaining: 56.7s\n",
            "33:\tlearn: 216.3580777\ttotal: 743ms\tremaining: 56.5s\n",
            "34:\tlearn: 213.6611122\ttotal: 763ms\tremaining: 56.3s\n",
            "35:\tlearn: 210.3297219\ttotal: 783ms\tremaining: 56.2s\n",
            "36:\tlearn: 206.9902536\ttotal: 806ms\tremaining: 56.3s\n",
            "37:\tlearn: 204.8530154\ttotal: 829ms\tremaining: 56.3s\n",
            "38:\tlearn: 202.0667306\ttotal: 856ms\tremaining: 56.6s\n",
            "39:\tlearn: 199.5135993\ttotal: 880ms\tremaining: 56.8s\n",
            "40:\tlearn: 197.7087269\ttotal: 910ms\tremaining: 57.3s\n",
            "41:\tlearn: 196.1074879\ttotal: 942ms\tremaining: 57.8s\n",
            "42:\tlearn: 194.3536182\ttotal: 959ms\tremaining: 57.5s\n",
            "43:\tlearn: 192.0495981\ttotal: 983ms\tremaining: 57.6s\n",
            "44:\tlearn: 189.7328162\ttotal: 1.01s\tremaining: 57.8s\n",
            "45:\tlearn: 188.2926777\ttotal: 1.03s\tremaining: 57.9s\n",
            "46:\tlearn: 186.3157783\ttotal: 1.06s\tremaining: 58s\n",
            "47:\tlearn: 184.5593167\ttotal: 1.08s\tremaining: 58.2s\n",
            "48:\tlearn: 182.6268504\ttotal: 1.11s\tremaining: 58.4s\n",
            "49:\tlearn: 180.9254234\ttotal: 1.14s\tremaining: 58.5s\n",
            "50:\tlearn: 179.2668034\ttotal: 1.17s\tremaining: 58.9s\n",
            "51:\tlearn: 177.8689661\ttotal: 1.19s\tremaining: 59s\n",
            "52:\tlearn: 176.2806153\ttotal: 1.22s\tremaining: 59.2s\n",
            "53:\tlearn: 175.3168202\ttotal: 1.25s\tremaining: 59.2s\n",
            "54:\tlearn: 174.3090262\ttotal: 1.27s\tremaining: 59.1s\n",
            "55:\tlearn: 173.2487424\ttotal: 1.3s\tremaining: 59.5s\n",
            "56:\tlearn: 172.0654853\ttotal: 1.32s\tremaining: 59.6s\n",
            "57:\tlearn: 170.9083016\ttotal: 1.36s\tremaining: 59.9s\n",
            "58:\tlearn: 169.9368156\ttotal: 1.39s\tremaining: 1m\n",
            "59:\tlearn: 169.2816345\ttotal: 1.41s\tremaining: 1m\n",
            "60:\tlearn: 168.7982895\ttotal: 1.43s\tremaining: 60s\n",
            "61:\tlearn: 167.8393804\ttotal: 1.45s\tremaining: 1m\n",
            "62:\tlearn: 167.1403450\ttotal: 1.48s\tremaining: 1m\n",
            "63:\tlearn: 165.9802687\ttotal: 1.51s\tremaining: 1m\n",
            "64:\tlearn: 165.2018518\ttotal: 1.54s\tremaining: 1m\n",
            "65:\tlearn: 164.5143018\ttotal: 1.56s\tremaining: 1m\n",
            "66:\tlearn: 163.8231099\ttotal: 1.59s\tremaining: 1m\n",
            "67:\tlearn: 163.2600881\ttotal: 1.61s\tremaining: 1m\n",
            "68:\tlearn: 162.4805903\ttotal: 1.63s\tremaining: 1m\n",
            "69:\tlearn: 161.7714106\ttotal: 1.65s\tremaining: 1m\n",
            "70:\tlearn: 161.1192266\ttotal: 1.67s\tremaining: 59.8s\n",
            "71:\tlearn: 160.5824774\ttotal: 1.69s\tremaining: 59.9s\n",
            "72:\tlearn: 160.2914804\ttotal: 1.72s\tremaining: 60s\n",
            "73:\tlearn: 159.6013329\ttotal: 1.75s\tremaining: 1m\n",
            "74:\tlearn: 159.2212139\ttotal: 1.77s\tremaining: 1m\n",
            "75:\tlearn: 158.6757251\ttotal: 1.79s\tremaining: 60s\n",
            "76:\tlearn: 158.0202160\ttotal: 1.81s\tremaining: 60s\n",
            "77:\tlearn: 157.4832183\ttotal: 1.83s\tremaining: 59.7s\n",
            "78:\tlearn: 156.9415860\ttotal: 1.86s\tremaining: 59.7s\n",
            "79:\tlearn: 156.5012746\ttotal: 1.89s\tremaining: 60s\n",
            "80:\tlearn: 156.1227852\ttotal: 1.91s\tremaining: 59.8s\n",
            "81:\tlearn: 155.6369553\ttotal: 1.93s\tremaining: 59.7s\n",
            "82:\tlearn: 155.2981550\ttotal: 1.95s\tremaining: 59.7s\n",
            "83:\tlearn: 154.8409449\ttotal: 1.98s\tremaining: 59.6s\n",
            "84:\tlearn: 154.3458150\ttotal: 2s\tremaining: 59.5s\n",
            "85:\tlearn: 153.9420098\ttotal: 2.03s\tremaining: 59.7s\n",
            "86:\tlearn: 153.5997877\ttotal: 2.06s\tremaining: 59.8s\n",
            "87:\tlearn: 153.2252299\ttotal: 2.08s\tremaining: 59.8s\n",
            "88:\tlearn: 152.9589715\ttotal: 2.1s\tremaining: 59.7s\n",
            "89:\tlearn: 152.7058201\ttotal: 2.12s\tremaining: 59.6s\n",
            "90:\tlearn: 152.4126103\ttotal: 2.13s\tremaining: 59.3s\n",
            "91:\tlearn: 152.0020094\ttotal: 2.15s\tremaining: 59.2s\n",
            "92:\tlearn: 151.6504735\ttotal: 2.18s\tremaining: 59.2s\n",
            "93:\tlearn: 151.3499845\ttotal: 2.2s\tremaining: 59.1s\n",
            "94:\tlearn: 151.1284075\ttotal: 2.22s\tremaining: 59s\n",
            "95:\tlearn: 150.7163129\ttotal: 2.26s\tremaining: 59.5s\n",
            "96:\tlearn: 150.5251774\ttotal: 2.28s\tremaining: 59.3s\n",
            "97:\tlearn: 150.0881424\ttotal: 2.31s\tremaining: 59.4s\n",
            "98:\tlearn: 149.7938888\ttotal: 2.34s\tremaining: 59.5s\n",
            "99:\tlearn: 149.4949475\ttotal: 2.36s\tremaining: 59.5s\n",
            "100:\tlearn: 149.0585380\ttotal: 2.39s\tremaining: 59.5s\n",
            "101:\tlearn: 148.8330543\ttotal: 2.41s\tremaining: 59.6s\n",
            "102:\tlearn: 148.5747377\ttotal: 2.44s\tremaining: 59.6s\n",
            "103:\tlearn: 148.3615247\ttotal: 2.46s\tremaining: 59.6s\n",
            "104:\tlearn: 147.9960648\ttotal: 2.49s\tremaining: 59.7s\n",
            "105:\tlearn: 147.7644570\ttotal: 2.52s\tremaining: 59.7s\n",
            "106:\tlearn: 147.5308518\ttotal: 2.54s\tremaining: 59.6s\n",
            "107:\tlearn: 147.3224095\ttotal: 2.55s\tremaining: 59.4s\n",
            "108:\tlearn: 147.0911244\ttotal: 2.58s\tremaining: 59.5s\n",
            "109:\tlearn: 147.0589916\ttotal: 2.59s\tremaining: 59.1s\n",
            "110:\tlearn: 146.8482224\ttotal: 2.62s\tremaining: 59.1s\n",
            "111:\tlearn: 146.5899062\ttotal: 2.63s\tremaining: 58.9s\n",
            "112:\tlearn: 146.1622375\ttotal: 2.66s\tremaining: 59s\n",
            "113:\tlearn: 145.9819664\ttotal: 2.67s\tremaining: 58.7s\n",
            "114:\tlearn: 145.7746795\ttotal: 2.69s\tremaining: 58.6s\n",
            "115:\tlearn: 145.5359375\ttotal: 2.72s\tremaining: 58.6s\n",
            "116:\tlearn: 145.4002935\ttotal: 2.73s\tremaining: 58.4s\n",
            "117:\tlearn: 145.2317304\ttotal: 2.81s\tremaining: 59.5s\n",
            "118:\tlearn: 144.9159355\ttotal: 2.84s\tremaining: 59.6s\n",
            "119:\tlearn: 144.6328592\ttotal: 2.87s\tremaining: 59.8s\n",
            "120:\tlearn: 144.4908403\ttotal: 2.89s\tremaining: 59.8s\n",
            "121:\tlearn: 144.2677007\ttotal: 2.92s\tremaining: 59.8s\n",
            "122:\tlearn: 144.1080675\ttotal: 2.95s\tremaining: 59.9s\n",
            "123:\tlearn: 143.8965278\ttotal: 2.97s\tremaining: 59.9s\n",
            "124:\tlearn: 143.7309207\ttotal: 3s\tremaining: 59.9s\n",
            "125:\tlearn: 143.5839987\ttotal: 3.02s\tremaining: 59.8s\n",
            "126:\tlearn: 143.4236816\ttotal: 3.05s\tremaining: 59.8s\n",
            "127:\tlearn: 143.1980064\ttotal: 3.07s\tremaining: 59.8s\n",
            "128:\tlearn: 142.9975892\ttotal: 3.09s\tremaining: 59.7s\n",
            "129:\tlearn: 142.8167146\ttotal: 3.11s\tremaining: 59.6s\n",
            "130:\tlearn: 142.6477822\ttotal: 3.14s\tremaining: 59.7s\n",
            "131:\tlearn: 142.4931140\ttotal: 3.16s\tremaining: 59.6s\n",
            "132:\tlearn: 142.3223134\ttotal: 3.18s\tremaining: 59.5s\n",
            "133:\tlearn: 141.9745095\ttotal: 3.21s\tremaining: 59.5s\n",
            "134:\tlearn: 141.8139584\ttotal: 3.23s\tremaining: 59.4s\n",
            "135:\tlearn: 141.5950729\ttotal: 3.26s\tremaining: 59.5s\n",
            "136:\tlearn: 141.4556341\ttotal: 3.28s\tremaining: 59.5s\n",
            "137:\tlearn: 141.2925784\ttotal: 3.3s\tremaining: 59.4s\n",
            "138:\tlearn: 141.1056554\ttotal: 3.33s\tremaining: 59.4s\n",
            "139:\tlearn: 140.9997240\ttotal: 3.35s\tremaining: 59.4s\n",
            "140:\tlearn: 140.8360951\ttotal: 3.38s\tremaining: 59.4s\n",
            "141:\tlearn: 140.6883412\ttotal: 3.4s\tremaining: 59.3s\n",
            "142:\tlearn: 140.5576094\ttotal: 3.41s\tremaining: 59.1s\n",
            "143:\tlearn: 140.4165328\ttotal: 3.44s\tremaining: 59.2s\n",
            "144:\tlearn: 140.3345228\ttotal: 3.46s\tremaining: 59.1s\n",
            "145:\tlearn: 140.2514408\ttotal: 3.48s\tremaining: 59s\n",
            "146:\tlearn: 140.1256708\ttotal: 3.51s\tremaining: 59.1s\n",
            "147:\tlearn: 139.9802961\ttotal: 3.53s\tremaining: 58.9s\n",
            "148:\tlearn: 139.8257294\ttotal: 3.56s\tremaining: 59s\n",
            "149:\tlearn: 139.6928600\ttotal: 3.58s\tremaining: 59s\n",
            "150:\tlearn: 139.5768194\ttotal: 3.6s\tremaining: 58.9s\n",
            "151:\tlearn: 139.4414905\ttotal: 3.62s\tremaining: 58.8s\n",
            "152:\tlearn: 139.3521851\ttotal: 3.64s\tremaining: 58.6s\n",
            "153:\tlearn: 139.2531960\ttotal: 3.65s\tremaining: 58.5s\n",
            "154:\tlearn: 139.1370968\ttotal: 3.68s\tremaining: 58.5s\n",
            "155:\tlearn: 139.0095074\ttotal: 3.71s\tremaining: 58.5s\n",
            "156:\tlearn: 138.8834835\ttotal: 3.72s\tremaining: 58.4s\n",
            "157:\tlearn: 138.8251095\ttotal: 3.74s\tremaining: 58.3s\n",
            "158:\tlearn: 138.7218397\ttotal: 3.77s\tremaining: 58.3s\n",
            "159:\tlearn: 138.6289644\ttotal: 3.79s\tremaining: 58.3s\n",
            "160:\tlearn: 138.5308687\ttotal: 3.8s\tremaining: 58.1s\n",
            "161:\tlearn: 138.4537409\ttotal: 3.83s\tremaining: 58.1s\n",
            "162:\tlearn: 138.3127852\ttotal: 3.86s\tremaining: 58.1s\n",
            "163:\tlearn: 138.2116152\ttotal: 3.89s\tremaining: 58.2s\n",
            "164:\tlearn: 138.1002774\ttotal: 3.91s\tremaining: 58.2s\n",
            "165:\tlearn: 137.9931337\ttotal: 3.94s\tremaining: 58.2s\n",
            "166:\tlearn: 137.8854299\ttotal: 3.96s\tremaining: 58.2s\n",
            "167:\tlearn: 137.6522460\ttotal: 3.99s\tremaining: 58.2s\n",
            "168:\tlearn: 137.5194234\ttotal: 4.01s\tremaining: 58.1s\n",
            "169:\tlearn: 137.4633743\ttotal: 4.02s\tremaining: 58s\n",
            "170:\tlearn: 137.3855327\ttotal: 4.05s\tremaining: 58s\n",
            "171:\tlearn: 137.2621265\ttotal: 4.07s\tremaining: 57.9s\n",
            "172:\tlearn: 137.1711438\ttotal: 4.09s\tremaining: 57.9s\n",
            "173:\tlearn: 137.0323359\ttotal: 4.11s\tremaining: 57.8s\n",
            "174:\tlearn: 136.9639315\ttotal: 4.14s\tremaining: 57.8s\n",
            "175:\tlearn: 136.8992407\ttotal: 4.17s\tremaining: 57.9s\n",
            "176:\tlearn: 136.7613395\ttotal: 4.2s\tremaining: 57.9s\n",
            "177:\tlearn: 136.6320891\ttotal: 4.23s\tremaining: 58s\n",
            "178:\tlearn: 136.4373953\ttotal: 4.25s\tremaining: 58s\n",
            "179:\tlearn: 136.3361670\ttotal: 4.32s\tremaining: 58.6s\n",
            "180:\tlearn: 136.2621595\ttotal: 4.35s\tremaining: 58.6s\n",
            "181:\tlearn: 136.2017493\ttotal: 4.38s\tremaining: 58.7s\n",
            "182:\tlearn: 136.0271740\ttotal: 4.41s\tremaining: 58.7s\n",
            "183:\tlearn: 135.8608465\ttotal: 4.43s\tremaining: 58.6s\n",
            "184:\tlearn: 135.7619532\ttotal: 4.45s\tremaining: 58.6s\n",
            "185:\tlearn: 135.7293633\ttotal: 4.48s\tremaining: 58.6s\n",
            "186:\tlearn: 135.5588452\ttotal: 4.5s\tremaining: 58.5s\n",
            "187:\tlearn: 135.4553442\ttotal: 4.52s\tremaining: 58.5s\n",
            "188:\tlearn: 135.3197640\ttotal: 4.54s\tremaining: 58.4s\n",
            "189:\tlearn: 135.1885276\ttotal: 4.57s\tremaining: 58.4s\n",
            "190:\tlearn: 135.0657985\ttotal: 4.59s\tremaining: 58.4s\n",
            "191:\tlearn: 134.9024665\ttotal: 4.62s\tremaining: 58.4s\n",
            "192:\tlearn: 134.7447782\ttotal: 4.64s\tremaining: 58.3s\n",
            "193:\tlearn: 134.6410814\ttotal: 4.66s\tremaining: 58.3s\n",
            "194:\tlearn: 134.4847462\ttotal: 4.69s\tremaining: 58.3s\n",
            "195:\tlearn: 134.3569069\ttotal: 4.71s\tremaining: 58.3s\n",
            "196:\tlearn: 134.2455835\ttotal: 4.74s\tremaining: 58.3s\n",
            "197:\tlearn: 134.1197021\ttotal: 4.77s\tremaining: 58.4s\n",
            "198:\tlearn: 134.0337564\ttotal: 4.79s\tremaining: 58.3s\n",
            "199:\tlearn: 133.9430733\ttotal: 4.81s\tremaining: 58.2s\n",
            "200:\tlearn: 133.8923214\ttotal: 4.83s\tremaining: 58.2s\n",
            "201:\tlearn: 133.7821917\ttotal: 4.86s\tremaining: 58.2s\n",
            "202:\tlearn: 133.6790911\ttotal: 4.88s\tremaining: 58.1s\n",
            "203:\tlearn: 133.6160545\ttotal: 4.89s\tremaining: 58s\n",
            "204:\tlearn: 133.5130209\ttotal: 4.92s\tremaining: 57.9s\n",
            "205:\tlearn: 133.3714516\ttotal: 4.94s\tremaining: 57.9s\n",
            "206:\tlearn: 133.3115714\ttotal: 4.97s\tremaining: 57.9s\n",
            "207:\tlearn: 133.2219990\ttotal: 4.99s\tremaining: 57.9s\n",
            "208:\tlearn: 133.1506746\ttotal: 5s\tremaining: 57.7s\n",
            "209:\tlearn: 133.0216993\ttotal: 5.03s\tremaining: 57.8s\n",
            "210:\tlearn: 132.9611016\ttotal: 5.06s\tremaining: 57.7s\n",
            "211:\tlearn: 132.9079011\ttotal: 5.08s\tremaining: 57.7s\n",
            "212:\tlearn: 132.7562386\ttotal: 5.11s\tremaining: 57.8s\n",
            "213:\tlearn: 132.7180029\ttotal: 5.13s\tremaining: 57.6s\n",
            "214:\tlearn: 132.6555221\ttotal: 5.15s\tremaining: 57.6s\n",
            "215:\tlearn: 132.4927223\ttotal: 5.18s\tremaining: 57.7s\n",
            "216:\tlearn: 132.4010614\ttotal: 5.21s\tremaining: 57.7s\n",
            "217:\tlearn: 132.2015100\ttotal: 5.23s\tremaining: 57.7s\n",
            "218:\tlearn: 132.1492555\ttotal: 5.26s\tremaining: 57.6s\n",
            "219:\tlearn: 131.9285764\ttotal: 5.28s\tremaining: 57.6s\n",
            "220:\tlearn: 131.8066774\ttotal: 5.3s\tremaining: 57.5s\n",
            "221:\tlearn: 131.7232782\ttotal: 5.33s\tremaining: 57.5s\n",
            "222:\tlearn: 131.5415275\ttotal: 5.35s\tremaining: 57.5s\n",
            "223:\tlearn: 131.4098162\ttotal: 5.37s\tremaining: 57.5s\n",
            "224:\tlearn: 131.3541764\ttotal: 5.39s\tremaining: 57.4s\n",
            "225:\tlearn: 131.2359529\ttotal: 5.42s\tremaining: 57.4s\n",
            "226:\tlearn: 131.0940567\ttotal: 5.45s\tremaining: 57.5s\n",
            "227:\tlearn: 130.9536137\ttotal: 5.48s\tremaining: 57.5s\n",
            "228:\tlearn: 130.8494472\ttotal: 5.51s\tremaining: 57.5s\n",
            "229:\tlearn: 130.7841795\ttotal: 5.53s\tremaining: 57.5s\n",
            "230:\tlearn: 130.5890557\ttotal: 5.56s\tremaining: 57.5s\n",
            "231:\tlearn: 130.5000593\ttotal: 5.58s\tremaining: 57.4s\n",
            "232:\tlearn: 130.4245905\ttotal: 5.6s\tremaining: 57.3s\n",
            "233:\tlearn: 130.3385398\ttotal: 5.62s\tremaining: 57.3s\n",
            "234:\tlearn: 130.2169595\ttotal: 5.65s\tremaining: 57.3s\n",
            "235:\tlearn: 130.1526215\ttotal: 5.68s\tremaining: 57.4s\n",
            "236:\tlearn: 130.0820133\ttotal: 5.71s\tremaining: 57.4s\n",
            "237:\tlearn: 130.0125917\ttotal: 5.74s\tremaining: 57.4s\n",
            "238:\tlearn: 129.9295687\ttotal: 5.76s\tremaining: 57.4s\n",
            "239:\tlearn: 129.8413089\ttotal: 5.78s\tremaining: 57.4s\n",
            "240:\tlearn: 129.7775628\ttotal: 5.81s\tremaining: 57.3s\n",
            "241:\tlearn: 129.6773130\ttotal: 5.83s\tremaining: 57.3s\n",
            "242:\tlearn: 129.4063040\ttotal: 5.86s\tremaining: 57.3s\n",
            "243:\tlearn: 129.3158838\ttotal: 5.88s\tremaining: 57.3s\n",
            "244:\tlearn: 129.2221689\ttotal: 5.9s\tremaining: 57.2s\n",
            "245:\tlearn: 129.0820339\ttotal: 5.95s\tremaining: 57.4s\n",
            "246:\tlearn: 129.0394559\ttotal: 5.97s\tremaining: 57.4s\n",
            "247:\tlearn: 128.9523318\ttotal: 6s\tremaining: 57.4s\n",
            "248:\tlearn: 128.8977915\ttotal: 6.01s\tremaining: 57.3s\n",
            "249:\tlearn: 128.8342352\ttotal: 6.03s\tremaining: 57.2s\n",
            "250:\tlearn: 128.7205062\ttotal: 6.06s\tremaining: 57.2s\n",
            "251:\tlearn: 128.6317708\ttotal: 6.08s\tremaining: 57.2s\n",
            "252:\tlearn: 128.5661243\ttotal: 6.11s\tremaining: 57.1s\n",
            "253:\tlearn: 128.4974151\ttotal: 6.13s\tremaining: 57.1s\n",
            "254:\tlearn: 128.4261925\ttotal: 6.16s\tremaining: 57.1s\n",
            "255:\tlearn: 128.3268757\ttotal: 6.18s\tremaining: 57.1s\n",
            "256:\tlearn: 128.2837574\ttotal: 6.2s\tremaining: 57s\n",
            "257:\tlearn: 128.2015771\ttotal: 6.23s\tremaining: 57s\n",
            "258:\tlearn: 128.1232022\ttotal: 6.25s\tremaining: 57s\n",
            "259:\tlearn: 128.0477996\ttotal: 6.28s\tremaining: 57s\n",
            "260:\tlearn: 127.9774267\ttotal: 6.3s\tremaining: 56.9s\n",
            "261:\tlearn: 127.9319983\ttotal: 6.32s\tremaining: 56.9s\n",
            "262:\tlearn: 127.8932523\ttotal: 6.34s\tremaining: 56.8s\n",
            "263:\tlearn: 127.8183820\ttotal: 6.36s\tremaining: 56.8s\n",
            "264:\tlearn: 127.7624880\ttotal: 6.38s\tremaining: 56.7s\n",
            "265:\tlearn: 127.6809211\ttotal: 6.41s\tremaining: 56.7s\n",
            "266:\tlearn: 127.5836318\ttotal: 6.43s\tremaining: 56.7s\n",
            "267:\tlearn: 127.5544306\ttotal: 6.46s\tremaining: 56.7s\n",
            "268:\tlearn: 127.4811822\ttotal: 6.48s\tremaining: 56.6s\n",
            "269:\tlearn: 127.4151001\ttotal: 6.5s\tremaining: 56.6s\n",
            "270:\tlearn: 127.3582888\ttotal: 6.52s\tremaining: 56.5s\n",
            "271:\tlearn: 127.2186461\ttotal: 6.55s\tremaining: 56.5s\n",
            "272:\tlearn: 127.1208834\ttotal: 6.58s\tremaining: 56.5s\n",
            "273:\tlearn: 127.0967251\ttotal: 6.64s\tremaining: 56.8s\n",
            "274:\tlearn: 127.0192556\ttotal: 6.66s\tremaining: 56.8s\n",
            "275:\tlearn: 127.0192556\ttotal: 6.66s\tremaining: 56.6s\n",
            "276:\tlearn: 126.9524921\ttotal: 6.69s\tremaining: 56.6s\n",
            "277:\tlearn: 126.8819581\ttotal: 6.72s\tremaining: 56.6s\n",
            "278:\tlearn: 126.8518121\ttotal: 6.75s\tremaining: 56.6s\n",
            "279:\tlearn: 126.8051934\ttotal: 6.77s\tremaining: 56.5s\n",
            "280:\tlearn: 126.7321367\ttotal: 6.79s\tremaining: 56.5s\n",
            "281:\tlearn: 126.6696875\ttotal: 6.81s\tremaining: 56.5s\n",
            "282:\tlearn: 126.5790996\ttotal: 6.84s\tremaining: 56.5s\n",
            "283:\tlearn: 126.5359425\ttotal: 6.87s\tremaining: 56.5s\n",
            "284:\tlearn: 126.4948496\ttotal: 6.89s\tremaining: 56.4s\n",
            "285:\tlearn: 126.4351092\ttotal: 6.91s\tremaining: 56.4s\n",
            "286:\tlearn: 126.3031201\ttotal: 6.94s\tremaining: 56.4s\n",
            "287:\tlearn: 126.2344552\ttotal: 6.96s\tremaining: 56.4s\n",
            "288:\tlearn: 126.1876725\ttotal: 6.99s\tremaining: 56.4s\n",
            "289:\tlearn: 126.0901148\ttotal: 7.02s\tremaining: 56.4s\n",
            "290:\tlearn: 126.0413531\ttotal: 7.04s\tremaining: 56.3s\n",
            "291:\tlearn: 125.9562802\ttotal: 7.06s\tremaining: 56.3s\n",
            "292:\tlearn: 125.9149782\ttotal: 7.09s\tremaining: 56.3s\n",
            "293:\tlearn: 125.8717644\ttotal: 7.11s\tremaining: 56.3s\n",
            "294:\tlearn: 125.7838001\ttotal: 7.14s\tremaining: 56.3s\n",
            "295:\tlearn: 125.7415145\ttotal: 7.17s\tremaining: 56.3s\n",
            "296:\tlearn: 125.6751998\ttotal: 7.2s\tremaining: 56.3s\n",
            "297:\tlearn: 125.6300856\ttotal: 7.22s\tremaining: 56.2s\n",
            "298:\tlearn: 125.5812767\ttotal: 7.24s\tremaining: 56.2s\n",
            "299:\tlearn: 125.5241844\ttotal: 7.27s\tremaining: 56.2s\n",
            "300:\tlearn: 125.4719560\ttotal: 7.29s\tremaining: 56.2s\n",
            "301:\tlearn: 125.4236998\ttotal: 7.31s\tremaining: 56.1s\n",
            "302:\tlearn: 125.3798763\ttotal: 7.33s\tremaining: 56.1s\n",
            "303:\tlearn: 125.3451488\ttotal: 7.37s\tremaining: 56.1s\n",
            "304:\tlearn: 125.3051951\ttotal: 7.38s\tremaining: 56s\n",
            "305:\tlearn: 125.2869946\ttotal: 7.41s\tremaining: 56s\n",
            "306:\tlearn: 125.2277362\ttotal: 7.44s\tremaining: 56s\n",
            "307:\tlearn: 125.1292671\ttotal: 7.46s\tremaining: 56s\n",
            "308:\tlearn: 125.0782018\ttotal: 7.47s\tremaining: 55.9s\n",
            "309:\tlearn: 125.0346663\ttotal: 7.5s\tremaining: 55.9s\n",
            "310:\tlearn: 124.9829164\ttotal: 7.52s\tremaining: 55.8s\n",
            "311:\tlearn: 124.9278264\ttotal: 7.54s\tremaining: 55.8s\n",
            "312:\tlearn: 124.8988275\ttotal: 7.55s\tremaining: 55.7s\n",
            "313:\tlearn: 124.8695279\ttotal: 7.57s\tremaining: 55.6s\n",
            "314:\tlearn: 124.8290858\ttotal: 7.6s\tremaining: 55.6s\n",
            "315:\tlearn: 124.7687645\ttotal: 7.63s\tremaining: 55.6s\n",
            "316:\tlearn: 124.7336291\ttotal: 7.65s\tremaining: 55.6s\n",
            "317:\tlearn: 124.6743396\ttotal: 7.67s\tremaining: 55.5s\n",
            "318:\tlearn: 124.5238016\ttotal: 7.7s\tremaining: 55.5s\n",
            "319:\tlearn: 124.4898594\ttotal: 7.71s\tremaining: 55.5s\n",
            "320:\tlearn: 124.4447685\ttotal: 7.74s\tremaining: 55.5s\n",
            "321:\tlearn: 124.3836410\ttotal: 7.77s\tremaining: 55.4s\n",
            "322:\tlearn: 124.3386071\ttotal: 7.79s\tremaining: 55.4s\n",
            "323:\tlearn: 124.1821241\ttotal: 7.81s\tremaining: 55.3s\n",
            "324:\tlearn: 124.1616748\ttotal: 7.82s\tremaining: 55.2s\n",
            "325:\tlearn: 124.1365666\ttotal: 7.85s\tremaining: 55.3s\n",
            "326:\tlearn: 124.0393449\ttotal: 7.88s\tremaining: 55.2s\n",
            "327:\tlearn: 123.9774171\ttotal: 7.91s\tremaining: 55.3s\n",
            "328:\tlearn: 123.9576515\ttotal: 7.93s\tremaining: 55.2s\n",
            "329:\tlearn: 123.9079845\ttotal: 7.96s\tremaining: 55.2s\n",
            "330:\tlearn: 123.8217704\ttotal: 7.98s\tremaining: 55.2s\n",
            "331:\tlearn: 123.7541619\ttotal: 8s\tremaining: 55.1s\n",
            "332:\tlearn: 123.7062743\ttotal: 8.02s\tremaining: 55.1s\n",
            "333:\tlearn: 123.6766877\ttotal: 8.05s\tremaining: 55.1s\n",
            "334:\tlearn: 123.6276459\ttotal: 8.07s\tremaining: 55.1s\n",
            "335:\tlearn: 123.5754817\ttotal: 8.1s\tremaining: 55s\n",
            "336:\tlearn: 123.5528000\ttotal: 8.12s\tremaining: 55s\n",
            "337:\tlearn: 123.5028521\ttotal: 8.14s\tremaining: 55s\n",
            "338:\tlearn: 123.4631257\ttotal: 8.17s\tremaining: 54.9s\n",
            "339:\tlearn: 123.4137474\ttotal: 8.19s\tremaining: 54.9s\n",
            "340:\tlearn: 123.3950216\ttotal: 8.22s\tremaining: 54.9s\n",
            "341:\tlearn: 123.1953423\ttotal: 8.23s\tremaining: 54.8s\n",
            "342:\tlearn: 123.1592311\ttotal: 8.26s\tremaining: 54.9s\n",
            "343:\tlearn: 123.0877555\ttotal: 8.29s\tremaining: 54.9s\n",
            "344:\tlearn: 122.9831260\ttotal: 8.32s\tremaining: 54.9s\n",
            "345:\tlearn: 122.9508413\ttotal: 8.35s\tremaining: 54.9s\n",
            "346:\tlearn: 122.9110125\ttotal: 8.37s\tremaining: 54.8s\n",
            "347:\tlearn: 122.8707948\ttotal: 8.39s\tremaining: 54.8s\n",
            "348:\tlearn: 122.8430690\ttotal: 8.41s\tremaining: 54.7s\n",
            "349:\tlearn: 122.8063549\ttotal: 8.44s\tremaining: 54.7s\n",
            "350:\tlearn: 122.7363245\ttotal: 8.46s\tremaining: 54.7s\n",
            "351:\tlearn: 122.6312217\ttotal: 8.49s\tremaining: 54.7s\n",
            "352:\tlearn: 122.5805270\ttotal: 8.5s\tremaining: 54.6s\n",
            "353:\tlearn: 122.5266367\ttotal: 8.53s\tremaining: 54.6s\n",
            "354:\tlearn: 122.4570951\ttotal: 8.55s\tremaining: 54.6s\n",
            "355:\tlearn: 122.3594356\ttotal: 8.58s\tremaining: 54.6s\n",
            "356:\tlearn: 122.2609154\ttotal: 8.6s\tremaining: 54.5s\n",
            "357:\tlearn: 122.2609154\ttotal: 8.61s\tremaining: 54.4s\n",
            "358:\tlearn: 122.1673807\ttotal: 8.63s\tremaining: 54.4s\n",
            "359:\tlearn: 122.1203141\ttotal: 8.66s\tremaining: 54.3s\n",
            "360:\tlearn: 122.0412612\ttotal: 8.68s\tremaining: 54.3s\n",
            "361:\tlearn: 122.0159456\ttotal: 8.7s\tremaining: 54.2s\n",
            "362:\tlearn: 121.9152193\ttotal: 8.72s\tremaining: 54.2s\n",
            "363:\tlearn: 121.8519465\ttotal: 8.75s\tremaining: 54.2s\n",
            "364:\tlearn: 121.7892560\ttotal: 8.77s\tremaining: 54.2s\n",
            "365:\tlearn: 121.7705253\ttotal: 8.8s\tremaining: 54.2s\n",
            "366:\tlearn: 121.7416821\ttotal: 8.81s\tremaining: 54.1s\n",
            "367:\tlearn: 121.6767514\ttotal: 8.84s\tremaining: 54.1s\n",
            "368:\tlearn: 121.6430841\ttotal: 8.87s\tremaining: 54.1s\n",
            "369:\tlearn: 121.6011371\ttotal: 8.9s\tremaining: 54.1s\n",
            "370:\tlearn: 121.5721388\ttotal: 8.92s\tremaining: 54.1s\n",
            "371:\tlearn: 121.4670878\ttotal: 8.94s\tremaining: 54s\n",
            "372:\tlearn: 121.4309777\ttotal: 8.96s\tremaining: 54s\n",
            "373:\tlearn: 121.4121836\ttotal: 8.99s\tremaining: 54s\n",
            "374:\tlearn: 121.3683719\ttotal: 9.02s\tremaining: 54s\n",
            "375:\tlearn: 121.3177035\ttotal: 9.04s\tremaining: 54s\n",
            "376:\tlearn: 121.2881922\ttotal: 9.07s\tremaining: 54s\n",
            "377:\tlearn: 121.2530932\ttotal: 9.1s\tremaining: 54s\n",
            "378:\tlearn: 121.2153412\ttotal: 9.12s\tremaining: 53.9s\n",
            "379:\tlearn: 121.1453485\ttotal: 9.15s\tremaining: 54s\n",
            "380:\tlearn: 121.1122630\ttotal: 9.18s\tremaining: 54s\n",
            "381:\tlearn: 121.0830693\ttotal: 9.2s\tremaining: 53.9s\n",
            "382:\tlearn: 121.0624874\ttotal: 9.23s\tremaining: 53.9s\n",
            "383:\tlearn: 121.0151963\ttotal: 9.25s\tremaining: 53.9s\n",
            "384:\tlearn: 120.9365631\ttotal: 9.28s\tremaining: 53.9s\n",
            "385:\tlearn: 120.8884399\ttotal: 9.3s\tremaining: 53.8s\n",
            "386:\tlearn: 120.8114898\ttotal: 9.33s\tremaining: 53.8s\n",
            "387:\tlearn: 120.7817035\ttotal: 9.36s\tremaining: 53.8s\n",
            "388:\tlearn: 120.7535100\ttotal: 9.38s\tremaining: 53.8s\n",
            "389:\tlearn: 120.5440046\ttotal: 9.4s\tremaining: 53.8s\n",
            "390:\tlearn: 120.4715723\ttotal: 9.43s\tremaining: 53.8s\n",
            "391:\tlearn: 120.3811228\ttotal: 9.45s\tremaining: 53.7s\n",
            "392:\tlearn: 120.3356053\ttotal: 9.47s\tremaining: 53.7s\n",
            "393:\tlearn: 120.3254481\ttotal: 9.49s\tremaining: 53.6s\n",
            "394:\tlearn: 120.2990476\ttotal: 9.51s\tremaining: 53.5s\n",
            "395:\tlearn: 120.2857261\ttotal: 9.53s\tremaining: 53.5s\n",
            "396:\tlearn: 120.2553950\ttotal: 9.55s\tremaining: 53.5s\n",
            "397:\tlearn: 120.2215429\ttotal: 9.57s\tremaining: 53.4s\n",
            "398:\tlearn: 120.2008127\ttotal: 9.59s\tremaining: 53.4s\n",
            "399:\tlearn: 120.1850171\ttotal: 9.62s\tremaining: 53.4s\n",
            "400:\tlearn: 120.1364752\ttotal: 9.65s\tremaining: 53.4s\n",
            "401:\tlearn: 120.0792658\ttotal: 9.67s\tremaining: 53.4s\n",
            "402:\tlearn: 120.0488072\ttotal: 9.7s\tremaining: 53.4s\n",
            "403:\tlearn: 119.9814223\ttotal: 9.72s\tremaining: 53.3s\n",
            "404:\tlearn: 119.9814223\ttotal: 9.73s\tremaining: 53.2s\n",
            "405:\tlearn: 119.9234124\ttotal: 9.75s\tremaining: 53.2s\n",
            "406:\tlearn: 119.8987947\ttotal: 9.78s\tremaining: 53.2s\n",
            "407:\tlearn: 119.8523132\ttotal: 9.8s\tremaining: 53.1s\n",
            "408:\tlearn: 119.8042066\ttotal: 9.83s\tremaining: 53.2s\n",
            "409:\tlearn: 119.7544572\ttotal: 9.86s\tremaining: 53.2s\n",
            "410:\tlearn: 119.7172018\ttotal: 9.89s\tremaining: 53.1s\n",
            "411:\tlearn: 119.6793142\ttotal: 9.9s\tremaining: 53.1s\n",
            "412:\tlearn: 119.6361243\ttotal: 9.93s\tremaining: 53.1s\n",
            "413:\tlearn: 119.6232853\ttotal: 9.96s\tremaining: 53.1s\n",
            "414:\tlearn: 119.5759551\ttotal: 9.99s\tremaining: 53.1s\n",
            "415:\tlearn: 119.5423243\ttotal: 10s\tremaining: 53s\n",
            "416:\tlearn: 119.5423243\ttotal: 10s\tremaining: 52.9s\n",
            "417:\tlearn: 119.5014769\ttotal: 10s\tremaining: 52.9s\n",
            "418:\tlearn: 119.4824360\ttotal: 10.1s\tremaining: 52.8s\n",
            "419:\tlearn: 119.4520583\ttotal: 10.1s\tremaining: 52.8s\n",
            "420:\tlearn: 119.4365788\ttotal: 10.1s\tremaining: 52.7s\n",
            "421:\tlearn: 119.4365469\ttotal: 10.1s\tremaining: 52.6s\n",
            "422:\tlearn: 119.4227669\ttotal: 10.1s\tremaining: 52.6s\n",
            "423:\tlearn: 119.4106955\ttotal: 10.1s\tremaining: 52.5s\n",
            "424:\tlearn: 119.3725257\ttotal: 10.2s\tremaining: 52.5s\n",
            "425:\tlearn: 119.3134212\ttotal: 10.2s\tremaining: 52.5s\n",
            "426:\tlearn: 119.2860824\ttotal: 10.2s\tremaining: 52.4s\n",
            "427:\tlearn: 119.2085530\ttotal: 10.2s\tremaining: 52.4s\n",
            "428:\tlearn: 119.1759624\ttotal: 10.3s\tremaining: 52.4s\n",
            "429:\tlearn: 119.1358840\ttotal: 10.3s\tremaining: 52.3s\n",
            "430:\tlearn: 119.1165195\ttotal: 10.3s\tremaining: 52.3s\n",
            "431:\tlearn: 119.0835858\ttotal: 10.3s\tremaining: 52.3s\n",
            "432:\tlearn: 119.0233477\ttotal: 10.4s\tremaining: 52.3s\n",
            "433:\tlearn: 118.9828473\ttotal: 10.4s\tremaining: 52.2s\n",
            "434:\tlearn: 118.9364432\ttotal: 10.4s\tremaining: 52.2s\n",
            "435:\tlearn: 118.9241238\ttotal: 10.4s\tremaining: 52.2s\n",
            "436:\tlearn: 118.8990861\ttotal: 10.4s\tremaining: 52.2s\n",
            "437:\tlearn: 118.8112267\ttotal: 10.5s\tremaining: 52.2s\n",
            "438:\tlearn: 118.7896606\ttotal: 10.5s\tremaining: 52.1s\n",
            "439:\tlearn: 118.7625233\ttotal: 10.5s\tremaining: 52.1s\n",
            "440:\tlearn: 118.7394667\ttotal: 10.5s\tremaining: 52.1s\n",
            "441:\tlearn: 118.7210374\ttotal: 10.6s\tremaining: 52.1s\n",
            "442:\tlearn: 118.6544580\ttotal: 10.6s\tremaining: 52s\n",
            "443:\tlearn: 118.6257001\ttotal: 10.6s\tremaining: 52s\n",
            "444:\tlearn: 118.5765578\ttotal: 10.6s\tremaining: 52s\n",
            "445:\tlearn: 118.5218348\ttotal: 10.7s\tremaining: 52s\n",
            "446:\tlearn: 118.4687094\ttotal: 10.7s\tremaining: 52s\n",
            "447:\tlearn: 118.4538204\ttotal: 10.7s\tremaining: 51.9s\n",
            "448:\tlearn: 118.4385848\ttotal: 10.7s\tremaining: 51.9s\n",
            "449:\tlearn: 118.4096239\ttotal: 10.8s\tremaining: 51.8s\n",
            "450:\tlearn: 118.3852321\ttotal: 10.8s\tremaining: 51.8s\n",
            "451:\tlearn: 118.3564884\ttotal: 10.8s\tremaining: 51.8s\n",
            "452:\tlearn: 118.3560547\ttotal: 10.8s\tremaining: 51.7s\n",
            "453:\tlearn: 118.3289280\ttotal: 10.8s\tremaining: 51.6s\n",
            "454:\tlearn: 118.3032734\ttotal: 10.8s\tremaining: 51.6s\n",
            "455:\tlearn: 118.2732809\ttotal: 10.9s\tremaining: 51.6s\n",
            "456:\tlearn: 118.2184734\ttotal: 10.9s\tremaining: 51.5s\n",
            "457:\tlearn: 118.1964126\ttotal: 10.9s\tremaining: 51.5s\n",
            "458:\tlearn: 118.1617189\ttotal: 10.9s\tremaining: 51.4s\n",
            "459:\tlearn: 118.1318341\ttotal: 10.9s\tremaining: 51.4s\n",
            "460:\tlearn: 118.1196090\ttotal: 11s\tremaining: 51.4s\n",
            "461:\tlearn: 118.0805027\ttotal: 11s\tremaining: 51.4s\n",
            "462:\tlearn: 118.0300959\ttotal: 11s\tremaining: 51.3s\n",
            "463:\tlearn: 118.0094984\ttotal: 11s\tremaining: 51.3s\n",
            "464:\tlearn: 117.9719659\ttotal: 11.1s\tremaining: 51.3s\n",
            "465:\tlearn: 117.9541276\ttotal: 11.1s\tremaining: 51.3s\n",
            "466:\tlearn: 117.9359377\ttotal: 11.1s\tremaining: 51.3s\n",
            "467:\tlearn: 117.9073510\ttotal: 11.1s\tremaining: 51.3s\n",
            "468:\tlearn: 117.8732757\ttotal: 11.2s\tremaining: 51.2s\n",
            "469:\tlearn: 117.8484363\ttotal: 11.2s\tremaining: 51.2s\n",
            "470:\tlearn: 117.8115607\ttotal: 11.2s\tremaining: 51.1s\n",
            "471:\tlearn: 117.7888641\ttotal: 11.2s\tremaining: 51.1s\n",
            "472:\tlearn: 117.7609369\ttotal: 11.3s\tremaining: 51.1s\n",
            "473:\tlearn: 117.7167220\ttotal: 11.3s\tremaining: 51.1s\n",
            "474:\tlearn: 117.6908068\ttotal: 11.3s\tremaining: 51.1s\n",
            "475:\tlearn: 117.6678555\ttotal: 11.3s\tremaining: 51s\n",
            "476:\tlearn: 117.6469390\ttotal: 11.4s\tremaining: 51s\n",
            "477:\tlearn: 117.6192088\ttotal: 11.4s\tremaining: 51s\n",
            "478:\tlearn: 117.5813759\ttotal: 11.4s\tremaining: 50.9s\n",
            "479:\tlearn: 117.5580014\ttotal: 11.4s\tremaining: 50.9s\n",
            "480:\tlearn: 117.5189285\ttotal: 11.4s\tremaining: 50.8s\n",
            "481:\tlearn: 117.4750219\ttotal: 11.5s\tremaining: 50.8s\n",
            "482:\tlearn: 117.4275457\ttotal: 11.5s\tremaining: 50.8s\n",
            "483:\tlearn: 117.3684757\ttotal: 11.5s\tremaining: 50.8s\n",
            "484:\tlearn: 117.3487051\ttotal: 11.5s\tremaining: 50.8s\n",
            "485:\tlearn: 117.3159701\ttotal: 11.6s\tremaining: 50.8s\n",
            "486:\tlearn: 117.2875237\ttotal: 11.6s\tremaining: 50.8s\n",
            "487:\tlearn: 117.2588984\ttotal: 11.6s\tremaining: 50.8s\n",
            "488:\tlearn: 117.2199852\ttotal: 11.6s\tremaining: 50.7s\n",
            "489:\tlearn: 117.2028781\ttotal: 11.7s\tremaining: 50.7s\n",
            "490:\tlearn: 117.1899060\ttotal: 11.7s\tremaining: 50.6s\n",
            "491:\tlearn: 117.1591642\ttotal: 11.7s\tremaining: 50.6s\n",
            "492:\tlearn: 117.1369055\ttotal: 11.7s\tremaining: 50.6s\n",
            "493:\tlearn: 117.1168407\ttotal: 11.8s\tremaining: 50.6s\n",
            "494:\tlearn: 117.0854565\ttotal: 11.8s\tremaining: 50.5s\n",
            "495:\tlearn: 117.0675839\ttotal: 11.8s\tremaining: 50.6s\n",
            "496:\tlearn: 117.0536075\ttotal: 11.8s\tremaining: 50.5s\n",
            "497:\tlearn: 117.0386230\ttotal: 11.9s\tremaining: 50.5s\n",
            "498:\tlearn: 117.0031826\ttotal: 11.9s\tremaining: 50.5s\n",
            "499:\tlearn: 116.9802309\ttotal: 11.9s\tremaining: 50.4s\n",
            "500:\tlearn: 116.9334924\ttotal: 11.9s\tremaining: 50.4s\n",
            "501:\tlearn: 116.9112180\ttotal: 11.9s\tremaining: 50.4s\n",
            "502:\tlearn: 116.8935808\ttotal: 12s\tremaining: 50.3s\n",
            "503:\tlearn: 116.8442747\ttotal: 12s\tremaining: 50.3s\n",
            "504:\tlearn: 116.8196227\ttotal: 12s\tremaining: 50.2s\n",
            "505:\tlearn: 116.8108015\ttotal: 12s\tremaining: 50.2s\n",
            "506:\tlearn: 116.7772229\ttotal: 12s\tremaining: 50.2s\n",
            "507:\tlearn: 116.7364161\ttotal: 12.1s\tremaining: 50.2s\n",
            "508:\tlearn: 116.7032364\ttotal: 12.1s\tremaining: 50.2s\n",
            "509:\tlearn: 116.6904136\ttotal: 12.1s\tremaining: 50.2s\n",
            "510:\tlearn: 116.6505722\ttotal: 12.1s\tremaining: 50.1s\n",
            "511:\tlearn: 116.6273666\ttotal: 12.2s\tremaining: 50.1s\n",
            "512:\tlearn: 116.5973967\ttotal: 12.2s\tremaining: 50.1s\n",
            "513:\tlearn: 116.5552602\ttotal: 12.2s\tremaining: 50.1s\n",
            "514:\tlearn: 116.5437581\ttotal: 12.3s\tremaining: 50.1s\n",
            "515:\tlearn: 116.5193322\ttotal: 12.3s\tremaining: 50s\n",
            "516:\tlearn: 116.5121905\ttotal: 12.3s\tremaining: 50s\n",
            "517:\tlearn: 116.4949737\ttotal: 12.3s\tremaining: 50s\n",
            "518:\tlearn: 116.4665771\ttotal: 12.3s\tremaining: 49.9s\n",
            "519:\tlearn: 116.4360814\ttotal: 12.4s\tremaining: 49.9s\n",
            "520:\tlearn: 116.3792379\ttotal: 12.4s\tremaining: 49.9s\n",
            "521:\tlearn: 116.3576513\ttotal: 12.4s\tremaining: 49.9s\n",
            "522:\tlearn: 116.2858343\ttotal: 12.4s\tremaining: 49.9s\n",
            "523:\tlearn: 116.2651808\ttotal: 12.5s\tremaining: 49.9s\n",
            "524:\tlearn: 116.2476698\ttotal: 12.5s\tremaining: 49.9s\n",
            "525:\tlearn: 116.2264513\ttotal: 12.5s\tremaining: 49.8s\n",
            "526:\tlearn: 116.2110484\ttotal: 12.5s\tremaining: 49.8s\n",
            "527:\tlearn: 116.1873245\ttotal: 12.6s\tremaining: 49.8s\n",
            "528:\tlearn: 116.1077503\ttotal: 12.6s\tremaining: 49.8s\n",
            "529:\tlearn: 116.0428142\ttotal: 12.6s\tremaining: 49.7s\n",
            "530:\tlearn: 115.9939471\ttotal: 12.6s\tremaining: 49.7s\n",
            "531:\tlearn: 115.9580567\ttotal: 12.7s\tremaining: 49.7s\n",
            "532:\tlearn: 115.9112045\ttotal: 12.7s\tremaining: 49.7s\n",
            "533:\tlearn: 115.8652148\ttotal: 12.7s\tremaining: 49.7s\n",
            "534:\tlearn: 115.8339122\ttotal: 12.7s\tremaining: 49.6s\n",
            "535:\tlearn: 115.8228528\ttotal: 12.8s\tremaining: 49.6s\n",
            "536:\tlearn: 115.8064657\ttotal: 12.8s\tremaining: 49.6s\n",
            "537:\tlearn: 115.7917249\ttotal: 12.8s\tremaining: 49.5s\n",
            "538:\tlearn: 115.7783668\ttotal: 12.8s\tremaining: 49.5s\n",
            "539:\tlearn: 115.7599542\ttotal: 12.8s\tremaining: 49.5s\n",
            "540:\tlearn: 115.7055041\ttotal: 12.9s\tremaining: 49.5s\n",
            "541:\tlearn: 115.6748204\ttotal: 12.9s\tremaining: 49.4s\n",
            "542:\tlearn: 115.6302767\ttotal: 12.9s\tremaining: 49.4s\n",
            "543:\tlearn: 115.6184114\ttotal: 12.9s\tremaining: 49.4s\n",
            "544:\tlearn: 115.5614668\ttotal: 13s\tremaining: 49.3s\n",
            "545:\tlearn: 115.5307650\ttotal: 13s\tremaining: 49.3s\n",
            "546:\tlearn: 115.5160218\ttotal: 13s\tremaining: 49.2s\n",
            "547:\tlearn: 115.4668024\ttotal: 13s\tremaining: 49.2s\n",
            "548:\tlearn: 115.4479925\ttotal: 13s\tremaining: 49.2s\n",
            "549:\tlearn: 115.4224463\ttotal: 13.1s\tremaining: 49.2s\n",
            "550:\tlearn: 115.3664605\ttotal: 13.1s\tremaining: 49.2s\n",
            "551:\tlearn: 115.3491751\ttotal: 13.1s\tremaining: 49.2s\n",
            "552:\tlearn: 115.3300478\ttotal: 13.1s\tremaining: 49.1s\n",
            "553:\tlearn: 115.3002675\ttotal: 13.2s\tremaining: 49.1s\n",
            "554:\tlearn: 115.2895097\ttotal: 13.2s\tremaining: 49.1s\n",
            "555:\tlearn: 115.2486436\ttotal: 13.2s\tremaining: 49.1s\n",
            "556:\tlearn: 115.2251708\ttotal: 13.2s\tremaining: 49.1s\n",
            "557:\tlearn: 115.1972711\ttotal: 13.3s\tremaining: 49.1s\n",
            "558:\tlearn: 115.1876015\ttotal: 13.3s\tremaining: 49s\n",
            "559:\tlearn: 115.1876015\ttotal: 13.3s\tremaining: 48.9s\n",
            "560:\tlearn: 115.1709977\ttotal: 13.3s\tremaining: 48.9s\n",
            "561:\tlearn: 115.1598883\ttotal: 13.4s\tremaining: 48.9s\n",
            "562:\tlearn: 115.1382975\ttotal: 13.4s\tremaining: 48.9s\n",
            "563:\tlearn: 115.1156408\ttotal: 13.4s\tremaining: 48.9s\n",
            "564:\tlearn: 115.0976290\ttotal: 13.4s\tremaining: 48.9s\n",
            "565:\tlearn: 115.0656800\ttotal: 13.5s\tremaining: 48.8s\n",
            "566:\tlearn: 114.9998259\ttotal: 13.5s\tremaining: 48.8s\n",
            "567:\tlearn: 114.9752438\ttotal: 13.5s\tremaining: 48.8s\n",
            "568:\tlearn: 114.9498428\ttotal: 13.5s\tremaining: 48.7s\n",
            "569:\tlearn: 114.9061608\ttotal: 13.6s\tremaining: 48.7s\n",
            "570:\tlearn: 114.9006689\ttotal: 13.6s\tremaining: 48.7s\n",
            "571:\tlearn: 114.8771082\ttotal: 13.6s\tremaining: 48.7s\n",
            "572:\tlearn: 114.8428611\ttotal: 13.6s\tremaining: 48.6s\n",
            "573:\tlearn: 114.8260199\ttotal: 13.6s\tremaining: 48.6s\n",
            "574:\tlearn: 114.7983403\ttotal: 13.7s\tremaining: 48.6s\n",
            "575:\tlearn: 114.7910092\ttotal: 13.7s\tremaining: 48.6s\n",
            "576:\tlearn: 114.7746580\ttotal: 13.7s\tremaining: 48.6s\n",
            "577:\tlearn: 114.7274082\ttotal: 13.7s\tremaining: 48.6s\n",
            "578:\tlearn: 114.6878090\ttotal: 13.8s\tremaining: 48.5s\n",
            "579:\tlearn: 114.6683075\ttotal: 13.8s\tremaining: 48.5s\n",
            "580:\tlearn: 114.6252457\ttotal: 13.8s\tremaining: 48.5s\n",
            "581:\tlearn: 114.5777056\ttotal: 13.8s\tremaining: 48.5s\n",
            "582:\tlearn: 114.5458018\ttotal: 13.9s\tremaining: 48.4s\n",
            "583:\tlearn: 114.4957169\ttotal: 13.9s\tremaining: 48.4s\n",
            "584:\tlearn: 114.4689100\ttotal: 13.9s\tremaining: 48.4s\n",
            "585:\tlearn: 114.4489973\ttotal: 13.9s\tremaining: 48.4s\n",
            "586:\tlearn: 114.4268114\ttotal: 14s\tremaining: 48.3s\n",
            "587:\tlearn: 114.3924324\ttotal: 14s\tremaining: 48.3s\n",
            "588:\tlearn: 114.3380214\ttotal: 14s\tremaining: 48.3s\n",
            "589:\tlearn: 114.3267047\ttotal: 14s\tremaining: 48.3s\n",
            "590:\tlearn: 114.2678843\ttotal: 14.1s\tremaining: 48.3s\n",
            "591:\tlearn: 114.2521323\ttotal: 14.1s\tremaining: 48.3s\n",
            "592:\tlearn: 114.2126383\ttotal: 14.1s\tremaining: 48.2s\n",
            "593:\tlearn: 114.1942477\ttotal: 14.2s\tremaining: 48.3s\n",
            "594:\tlearn: 114.1807685\ttotal: 14.2s\tremaining: 48.3s\n",
            "595:\tlearn: 114.1648787\ttotal: 14.2s\tremaining: 48.2s\n",
            "596:\tlearn: 114.1452955\ttotal: 14.2s\tremaining: 48.2s\n",
            "597:\tlearn: 114.1269620\ttotal: 14.3s\tremaining: 48.2s\n",
            "598:\tlearn: 114.1269620\ttotal: 14.3s\tremaining: 48.1s\n",
            "599:\tlearn: 114.0816998\ttotal: 14.3s\tremaining: 48.1s\n",
            "600:\tlearn: 114.0610905\ttotal: 14.3s\tremaining: 48.1s\n",
            "601:\tlearn: 114.0492559\ttotal: 14.3s\tremaining: 48s\n",
            "602:\tlearn: 113.9890318\ttotal: 14.4s\tremaining: 48s\n",
            "603:\tlearn: 113.9371658\ttotal: 14.4s\tremaining: 48s\n",
            "604:\tlearn: 113.9156180\ttotal: 14.4s\tremaining: 48s\n",
            "605:\tlearn: 113.8898731\ttotal: 14.4s\tremaining: 48s\n",
            "606:\tlearn: 113.8784595\ttotal: 14.5s\tremaining: 47.9s\n",
            "607:\tlearn: 113.8097419\ttotal: 14.5s\tremaining: 47.9s\n",
            "608:\tlearn: 113.7981172\ttotal: 14.5s\tremaining: 47.9s\n",
            "609:\tlearn: 113.7950626\ttotal: 14.5s\tremaining: 47.9s\n",
            "610:\tlearn: 113.7789494\ttotal: 14.6s\tremaining: 47.9s\n",
            "611:\tlearn: 113.7352533\ttotal: 14.6s\tremaining: 47.8s\n",
            "612:\tlearn: 113.7190050\ttotal: 14.6s\tremaining: 47.8s\n",
            "613:\tlearn: 113.6939259\ttotal: 14.6s\tremaining: 47.8s\n",
            "614:\tlearn: 113.6593626\ttotal: 14.7s\tremaining: 47.8s\n",
            "615:\tlearn: 113.6255971\ttotal: 14.7s\tremaining: 47.8s\n",
            "616:\tlearn: 113.6210709\ttotal: 14.7s\tremaining: 47.7s\n",
            "617:\tlearn: 113.6064300\ttotal: 14.7s\tremaining: 47.7s\n",
            "618:\tlearn: 113.5519997\ttotal: 14.7s\tremaining: 47.7s\n",
            "619:\tlearn: 113.5091674\ttotal: 14.8s\tremaining: 47.6s\n",
            "620:\tlearn: 113.4785837\ttotal: 14.8s\tremaining: 47.6s\n",
            "621:\tlearn: 113.4471820\ttotal: 14.8s\tremaining: 47.6s\n",
            "622:\tlearn: 113.4468249\ttotal: 14.9s\tremaining: 47.6s\n",
            "623:\tlearn: 113.4037821\ttotal: 14.9s\tremaining: 47.6s\n",
            "624:\tlearn: 113.3792567\ttotal: 14.9s\tremaining: 47.5s\n",
            "625:\tlearn: 113.3669626\ttotal: 14.9s\tremaining: 47.5s\n",
            "626:\tlearn: 113.3232873\ttotal: 14.9s\tremaining: 47.5s\n",
            "627:\tlearn: 113.2890023\ttotal: 15s\tremaining: 47.5s\n",
            "628:\tlearn: 113.2688090\ttotal: 15s\tremaining: 47.5s\n",
            "629:\tlearn: 113.2517573\ttotal: 15s\tremaining: 47.4s\n",
            "630:\tlearn: 113.2331148\ttotal: 15s\tremaining: 47.4s\n",
            "631:\tlearn: 113.2130371\ttotal: 15.1s\tremaining: 47.4s\n",
            "632:\tlearn: 113.1929826\ttotal: 15.1s\tremaining: 47.4s\n",
            "633:\tlearn: 113.1499574\ttotal: 15.1s\tremaining: 47.4s\n",
            "634:\tlearn: 113.1184614\ttotal: 15.2s\tremaining: 47.4s\n",
            "635:\tlearn: 113.1000326\ttotal: 15.2s\tremaining: 47.3s\n",
            "636:\tlearn: 113.0897013\ttotal: 15.2s\tremaining: 47.3s\n",
            "637:\tlearn: 113.0474113\ttotal: 15.2s\tremaining: 47.3s\n",
            "638:\tlearn: 113.0122720\ttotal: 15.2s\tremaining: 47.2s\n",
            "639:\tlearn: 112.9795007\ttotal: 15.3s\tremaining: 47.2s\n",
            "640:\tlearn: 112.9486659\ttotal: 15.3s\tremaining: 47.2s\n",
            "641:\tlearn: 112.9241589\ttotal: 15.3s\tremaining: 47.2s\n",
            "642:\tlearn: 112.9064419\ttotal: 15.3s\tremaining: 47.2s\n",
            "643:\tlearn: 112.8880722\ttotal: 15.4s\tremaining: 47.1s\n",
            "644:\tlearn: 112.8588444\ttotal: 15.4s\tremaining: 47.1s\n",
            "645:\tlearn: 112.8326023\ttotal: 15.4s\tremaining: 47.1s\n",
            "646:\tlearn: 112.8131345\ttotal: 15.4s\tremaining: 47.1s\n",
            "647:\tlearn: 112.7871487\ttotal: 15.4s\tremaining: 47s\n",
            "648:\tlearn: 112.7759003\ttotal: 15.5s\tremaining: 47s\n",
            "649:\tlearn: 112.7530116\ttotal: 15.5s\tremaining: 47s\n",
            "650:\tlearn: 112.7311319\ttotal: 15.5s\tremaining: 46.9s\n",
            "651:\tlearn: 112.7256290\ttotal: 15.5s\tremaining: 46.9s\n",
            "652:\tlearn: 112.7037642\ttotal: 15.6s\tremaining: 46.9s\n",
            "653:\tlearn: 112.6546672\ttotal: 15.6s\tremaining: 46.9s\n",
            "654:\tlearn: 112.6463699\ttotal: 15.6s\tremaining: 46.9s\n",
            "655:\tlearn: 112.6155012\ttotal: 15.6s\tremaining: 46.9s\n",
            "656:\tlearn: 112.5623618\ttotal: 15.7s\tremaining: 46.8s\n",
            "657:\tlearn: 112.5263865\ttotal: 15.7s\tremaining: 46.8s\n",
            "658:\tlearn: 112.4501712\ttotal: 15.7s\tremaining: 46.8s\n",
            "659:\tlearn: 112.4353175\ttotal: 15.7s\tremaining: 46.8s\n",
            "660:\tlearn: 112.4042576\ttotal: 15.8s\tremaining: 46.8s\n",
            "661:\tlearn: 112.3941508\ttotal: 15.8s\tremaining: 46.7s\n",
            "662:\tlearn: 112.3941508\ttotal: 15.8s\tremaining: 46.6s\n",
            "663:\tlearn: 112.3733520\ttotal: 15.8s\tremaining: 46.6s\n",
            "664:\tlearn: 112.3536352\ttotal: 15.8s\tremaining: 46.6s\n",
            "665:\tlearn: 112.3348355\ttotal: 15.9s\tremaining: 46.6s\n",
            "666:\tlearn: 112.3139758\ttotal: 15.9s\tremaining: 46.6s\n",
            "667:\tlearn: 112.2710135\ttotal: 15.9s\tremaining: 46.6s\n",
            "668:\tlearn: 112.2499006\ttotal: 15.9s\tremaining: 46.5s\n",
            "669:\tlearn: 112.2355563\ttotal: 16s\tremaining: 46.5s\n",
            "670:\tlearn: 112.2249755\ttotal: 16s\tremaining: 46.5s\n",
            "671:\tlearn: 112.2151820\ttotal: 16s\tremaining: 46.5s\n",
            "672:\tlearn: 112.1854449\ttotal: 16s\tremaining: 46.4s\n",
            "673:\tlearn: 112.1598246\ttotal: 16.1s\tremaining: 46.4s\n",
            "674:\tlearn: 112.1086540\ttotal: 16.1s\tremaining: 46.4s\n",
            "675:\tlearn: 112.0872870\ttotal: 16.1s\tremaining: 46.4s\n",
            "676:\tlearn: 112.0708678\ttotal: 16.2s\tremaining: 46.4s\n",
            "677:\tlearn: 112.0663571\ttotal: 16.2s\tremaining: 46.3s\n",
            "678:\tlearn: 112.0365864\ttotal: 16.2s\tremaining: 46.3s\n",
            "679:\tlearn: 112.0117166\ttotal: 16.2s\tremaining: 46.3s\n",
            "680:\tlearn: 112.0051476\ttotal: 16.3s\tremaining: 46.3s\n",
            "681:\tlearn: 112.0048139\ttotal: 16.3s\tremaining: 46.3s\n",
            "682:\tlearn: 111.9779664\ttotal: 16.3s\tremaining: 46.2s\n",
            "683:\tlearn: 111.9499297\ttotal: 16.3s\tremaining: 46.2s\n",
            "684:\tlearn: 111.9204461\ttotal: 16.4s\tremaining: 46.2s\n",
            "685:\tlearn: 111.8990817\ttotal: 16.4s\tremaining: 46.2s\n",
            "686:\tlearn: 111.8722279\ttotal: 16.4s\tremaining: 46.2s\n",
            "687:\tlearn: 111.8446257\ttotal: 16.4s\tremaining: 46.1s\n",
            "688:\tlearn: 111.8117044\ttotal: 16.5s\tremaining: 46.1s\n",
            "689:\tlearn: 111.7944373\ttotal: 16.5s\tremaining: 46.1s\n",
            "690:\tlearn: 111.7811954\ttotal: 16.5s\tremaining: 46s\n",
            "691:\tlearn: 111.7450964\ttotal: 16.5s\tremaining: 46s\n",
            "692:\tlearn: 111.7396181\ttotal: 16.5s\tremaining: 46s\n",
            "693:\tlearn: 111.7162385\ttotal: 16.6s\tremaining: 45.9s\n",
            "694:\tlearn: 111.6872281\ttotal: 16.6s\tremaining: 45.9s\n",
            "695:\tlearn: 111.6505631\ttotal: 16.6s\tremaining: 45.9s\n",
            "696:\tlearn: 111.6215374\ttotal: 16.6s\tremaining: 45.8s\n",
            "697:\tlearn: 111.5866631\ttotal: 16.6s\tremaining: 45.8s\n",
            "698:\tlearn: 111.5709433\ttotal: 16.7s\tremaining: 45.8s\n",
            "699:\tlearn: 111.5636159\ttotal: 16.7s\tremaining: 45.8s\n",
            "700:\tlearn: 111.5476132\ttotal: 16.7s\tremaining: 45.8s\n",
            "701:\tlearn: 111.5046099\ttotal: 16.8s\tremaining: 45.8s\n",
            "702:\tlearn: 111.4857770\ttotal: 16.8s\tremaining: 45.7s\n",
            "703:\tlearn: 111.4238947\ttotal: 16.8s\tremaining: 45.7s\n",
            "704:\tlearn: 111.4174004\ttotal: 16.8s\tremaining: 45.7s\n",
            "705:\tlearn: 111.3816481\ttotal: 16.8s\tremaining: 45.7s\n",
            "706:\tlearn: 111.3651258\ttotal: 16.9s\tremaining: 45.7s\n",
            "707:\tlearn: 111.3442397\ttotal: 16.9s\tremaining: 45.6s\n",
            "708:\tlearn: 111.3105912\ttotal: 16.9s\tremaining: 45.6s\n",
            "709:\tlearn: 111.2966616\ttotal: 17s\tremaining: 45.6s\n",
            "710:\tlearn: 111.2827855\ttotal: 17s\tremaining: 45.6s\n",
            "711:\tlearn: 111.2604179\ttotal: 17s\tremaining: 45.6s\n",
            "712:\tlearn: 111.2250609\ttotal: 17s\tremaining: 45.5s\n",
            "713:\tlearn: 111.2208200\ttotal: 17.1s\tremaining: 45.5s\n",
            "714:\tlearn: 111.1947570\ttotal: 17.1s\tremaining: 45.5s\n",
            "715:\tlearn: 111.1417893\ttotal: 17.1s\tremaining: 45.5s\n",
            "716:\tlearn: 111.1382384\ttotal: 17.1s\tremaining: 45.5s\n",
            "717:\tlearn: 111.1369944\ttotal: 17.2s\tremaining: 45.4s\n",
            "718:\tlearn: 111.1151223\ttotal: 17.2s\tremaining: 45.4s\n",
            "719:\tlearn: 111.0930777\ttotal: 17.2s\tremaining: 45.4s\n",
            "720:\tlearn: 111.0599338\ttotal: 17.2s\tremaining: 45.4s\n",
            "721:\tlearn: 111.0440139\ttotal: 17.3s\tremaining: 45.4s\n",
            "722:\tlearn: 111.0144758\ttotal: 17.3s\tremaining: 45.3s\n",
            "723:\tlearn: 110.9860596\ttotal: 17.3s\tremaining: 45.3s\n",
            "724:\tlearn: 110.9662362\ttotal: 17.3s\tremaining: 45.3s\n",
            "725:\tlearn: 110.9554616\ttotal: 17.3s\tremaining: 45.3s\n",
            "726:\tlearn: 110.9406584\ttotal: 17.4s\tremaining: 45.2s\n",
            "727:\tlearn: 110.9345806\ttotal: 17.4s\tremaining: 45.2s\n",
            "728:\tlearn: 110.9256343\ttotal: 17.4s\tremaining: 45.2s\n",
            "729:\tlearn: 110.8754373\ttotal: 17.4s\tremaining: 45.1s\n",
            "730:\tlearn: 110.8500670\ttotal: 17.5s\tremaining: 45.1s\n",
            "731:\tlearn: 110.8297939\ttotal: 17.5s\tremaining: 45.1s\n",
            "732:\tlearn: 110.8080559\ttotal: 17.5s\tremaining: 45.1s\n",
            "733:\tlearn: 110.7799220\ttotal: 17.5s\tremaining: 45s\n",
            "734:\tlearn: 110.7673365\ttotal: 17.5s\tremaining: 45s\n",
            "735:\tlearn: 110.7554561\ttotal: 17.6s\tremaining: 45s\n",
            "736:\tlearn: 110.7440950\ttotal: 17.6s\tremaining: 44.9s\n",
            "737:\tlearn: 110.7339218\ttotal: 17.6s\tremaining: 44.9s\n",
            "738:\tlearn: 110.7127341\ttotal: 17.6s\tremaining: 44.9s\n",
            "739:\tlearn: 110.6932493\ttotal: 17.7s\tremaining: 44.8s\n",
            "740:\tlearn: 110.6739602\ttotal: 17.7s\tremaining: 44.8s\n",
            "741:\tlearn: 110.6502183\ttotal: 17.7s\tremaining: 44.8s\n",
            "742:\tlearn: 110.6022947\ttotal: 17.7s\tremaining: 44.8s\n",
            "743:\tlearn: 110.5702343\ttotal: 17.8s\tremaining: 44.8s\n",
            "744:\tlearn: 110.5614977\ttotal: 17.8s\tremaining: 44.7s\n",
            "745:\tlearn: 110.5449014\ttotal: 17.8s\tremaining: 44.7s\n",
            "746:\tlearn: 110.5221343\ttotal: 17.8s\tremaining: 44.7s\n",
            "747:\tlearn: 110.5071143\ttotal: 17.9s\tremaining: 44.7s\n",
            "748:\tlearn: 110.4879765\ttotal: 17.9s\tremaining: 44.7s\n",
            "749:\tlearn: 110.4674759\ttotal: 17.9s\tremaining: 44.6s\n",
            "750:\tlearn: 110.4417538\ttotal: 17.9s\tremaining: 44.6s\n",
            "751:\tlearn: 110.4322454\ttotal: 17.9s\tremaining: 44.6s\n",
            "752:\tlearn: 110.4200040\ttotal: 18s\tremaining: 44.6s\n",
            "753:\tlearn: 110.4141545\ttotal: 18s\tremaining: 44.5s\n",
            "754:\tlearn: 110.4030459\ttotal: 18s\tremaining: 44.5s\n",
            "755:\tlearn: 110.3487539\ttotal: 18s\tremaining: 44.5s\n",
            "756:\tlearn: 110.3436677\ttotal: 18.1s\tremaining: 44.5s\n",
            "757:\tlearn: 110.3300169\ttotal: 18.1s\tremaining: 44.4s\n",
            "758:\tlearn: 110.3212091\ttotal: 18.1s\tremaining: 44.4s\n",
            "759:\tlearn: 110.2927226\ttotal: 18.1s\tremaining: 44.3s\n",
            "760:\tlearn: 110.2783867\ttotal: 18.1s\tremaining: 44.3s\n",
            "761:\tlearn: 110.2255731\ttotal: 18.2s\tremaining: 44.3s\n",
            "762:\tlearn: 110.2101217\ttotal: 18.2s\tremaining: 44.3s\n",
            "763:\tlearn: 110.1811551\ttotal: 18.2s\tremaining: 44.2s\n",
            "764:\tlearn: 110.1560275\ttotal: 18.2s\tremaining: 44.2s\n",
            "765:\tlearn: 110.1446644\ttotal: 18.3s\tremaining: 44.2s\n",
            "766:\tlearn: 110.1261130\ttotal: 18.3s\tremaining: 44.2s\n",
            "767:\tlearn: 110.1059154\ttotal: 18.3s\tremaining: 44.1s\n",
            "768:\tlearn: 110.0908150\ttotal: 18.3s\tremaining: 44.1s\n",
            "769:\tlearn: 110.0724989\ttotal: 18.4s\tremaining: 44.1s\n",
            "770:\tlearn: 110.0660815\ttotal: 18.4s\tremaining: 44.1s\n",
            "771:\tlearn: 110.0541277\ttotal: 18.4s\tremaining: 44.1s\n",
            "772:\tlearn: 110.0466727\ttotal: 18.4s\tremaining: 44s\n",
            "773:\tlearn: 110.0339539\ttotal: 18.5s\tremaining: 44s\n",
            "774:\tlearn: 110.0010467\ttotal: 18.5s\tremaining: 44s\n",
            "775:\tlearn: 109.9837338\ttotal: 18.5s\tremaining: 44s\n",
            "776:\tlearn: 109.9591071\ttotal: 18.5s\tremaining: 44s\n",
            "777:\tlearn: 109.9073916\ttotal: 18.6s\tremaining: 44s\n",
            "778:\tlearn: 109.8985556\ttotal: 18.6s\tremaining: 44s\n",
            "779:\tlearn: 109.8896312\ttotal: 18.6s\tremaining: 43.9s\n",
            "780:\tlearn: 109.8761686\ttotal: 18.6s\tremaining: 43.9s\n",
            "781:\tlearn: 109.8473471\ttotal: 18.7s\tremaining: 43.9s\n",
            "782:\tlearn: 109.8361593\ttotal: 18.7s\tremaining: 43.8s\n",
            "783:\tlearn: 109.8186001\ttotal: 18.7s\tremaining: 43.8s\n",
            "784:\tlearn: 109.7826305\ttotal: 18.7s\tremaining: 43.8s\n",
            "785:\tlearn: 109.7758858\ttotal: 18.8s\tremaining: 43.8s\n",
            "786:\tlearn: 109.7276590\ttotal: 18.8s\tremaining: 43.7s\n",
            "787:\tlearn: 109.7046559\ttotal: 18.8s\tremaining: 43.7s\n",
            "788:\tlearn: 109.6959551\ttotal: 18.8s\tremaining: 43.7s\n",
            "789:\tlearn: 109.6735845\ttotal: 18.9s\tremaining: 43.7s\n",
            "790:\tlearn: 109.6519561\ttotal: 18.9s\tremaining: 43.7s\n",
            "791:\tlearn: 109.6392937\ttotal: 18.9s\tremaining: 43.7s\n",
            "792:\tlearn: 109.6311403\ttotal: 18.9s\tremaining: 43.6s\n",
            "793:\tlearn: 109.6240743\ttotal: 19s\tremaining: 43.6s\n",
            "794:\tlearn: 109.6069983\ttotal: 19s\tremaining: 43.6s\n",
            "795:\tlearn: 109.5921188\ttotal: 19s\tremaining: 43.5s\n",
            "796:\tlearn: 109.5752809\ttotal: 19s\tremaining: 43.5s\n",
            "797:\tlearn: 109.5602580\ttotal: 19s\tremaining: 43.5s\n",
            "798:\tlearn: 109.5281690\ttotal: 19.1s\tremaining: 43.5s\n",
            "799:\tlearn: 109.5093399\ttotal: 19.1s\tremaining: 43.4s\n",
            "800:\tlearn: 109.4761115\ttotal: 19.1s\tremaining: 43.4s\n",
            "801:\tlearn: 109.4686640\ttotal: 19.1s\tremaining: 43.4s\n",
            "802:\tlearn: 109.4548657\ttotal: 19.2s\tremaining: 43.4s\n",
            "803:\tlearn: 109.4509097\ttotal: 19.2s\tremaining: 43.4s\n",
            "804:\tlearn: 109.4250060\ttotal: 19.2s\tremaining: 43.3s\n",
            "805:\tlearn: 109.4102986\ttotal: 19.3s\tremaining: 43.3s\n",
            "806:\tlearn: 109.4026401\ttotal: 19.3s\tremaining: 43.3s\n",
            "807:\tlearn: 109.3924548\ttotal: 19.3s\tremaining: 43.3s\n",
            "808:\tlearn: 109.3434675\ttotal: 19.3s\tremaining: 43.3s\n",
            "809:\tlearn: 109.3181207\ttotal: 19.4s\tremaining: 43.3s\n",
            "810:\tlearn: 109.3040252\ttotal: 19.4s\tremaining: 43.2s\n",
            "811:\tlearn: 109.2937614\ttotal: 19.4s\tremaining: 43.2s\n",
            "812:\tlearn: 109.2784268\ttotal: 19.4s\tremaining: 43.2s\n",
            "813:\tlearn: 109.2496159\ttotal: 19.5s\tremaining: 43.2s\n",
            "814:\tlearn: 109.2207730\ttotal: 19.5s\tremaining: 43.2s\n",
            "815:\tlearn: 109.2101717\ttotal: 19.5s\tremaining: 43.1s\n",
            "816:\tlearn: 109.1913685\ttotal: 19.5s\tremaining: 43.1s\n",
            "817:\tlearn: 109.1720927\ttotal: 19.6s\tremaining: 43.1s\n",
            "818:\tlearn: 109.1592219\ttotal: 19.6s\tremaining: 43.1s\n",
            "819:\tlearn: 109.1231676\ttotal: 19.6s\tremaining: 43s\n",
            "820:\tlearn: 109.1057092\ttotal: 19.6s\tremaining: 43s\n",
            "821:\tlearn: 109.0918145\ttotal: 19.7s\tremaining: 43s\n",
            "822:\tlearn: 109.0639851\ttotal: 19.7s\tremaining: 43s\n",
            "823:\tlearn: 109.0450193\ttotal: 19.7s\tremaining: 42.9s\n",
            "824:\tlearn: 109.0375793\ttotal: 19.7s\tremaining: 42.9s\n",
            "825:\tlearn: 109.0375793\ttotal: 19.7s\tremaining: 42.8s\n",
            "826:\tlearn: 109.0138383\ttotal: 19.8s\tremaining: 42.8s\n",
            "827:\tlearn: 108.9842349\ttotal: 19.8s\tremaining: 42.8s\n",
            "828:\tlearn: 108.9594204\ttotal: 19.8s\tremaining: 42.8s\n",
            "829:\tlearn: 108.9419428\ttotal: 19.8s\tremaining: 42.8s\n",
            "830:\tlearn: 108.9320380\ttotal: 19.9s\tremaining: 42.7s\n",
            "831:\tlearn: 108.9259063\ttotal: 19.9s\tremaining: 42.7s\n",
            "832:\tlearn: 108.8984885\ttotal: 19.9s\tremaining: 42.7s\n",
            "833:\tlearn: 108.8764669\ttotal: 19.9s\tremaining: 42.7s\n",
            "834:\tlearn: 108.8432489\ttotal: 20s\tremaining: 42.7s\n",
            "835:\tlearn: 108.8147834\ttotal: 20s\tremaining: 42.6s\n",
            "836:\tlearn: 108.7957456\ttotal: 20s\tremaining: 42.6s\n",
            "837:\tlearn: 108.7781301\ttotal: 20s\tremaining: 42.6s\n",
            "838:\tlearn: 108.7639987\ttotal: 20s\tremaining: 42.5s\n",
            "839:\tlearn: 108.7405780\ttotal: 20.1s\tremaining: 42.5s\n",
            "840:\tlearn: 108.7326393\ttotal: 20.1s\tremaining: 42.5s\n",
            "841:\tlearn: 108.7126437\ttotal: 20.1s\tremaining: 42.4s\n",
            "842:\tlearn: 108.6642673\ttotal: 20.1s\tremaining: 42.4s\n",
            "843:\tlearn: 108.6495585\ttotal: 20.1s\tremaining: 42.4s\n",
            "844:\tlearn: 108.6226056\ttotal: 20.2s\tremaining: 42.4s\n",
            "845:\tlearn: 108.6044463\ttotal: 20.2s\tremaining: 42.3s\n",
            "846:\tlearn: 108.5835673\ttotal: 20.2s\tremaining: 42.3s\n",
            "847:\tlearn: 108.5689427\ttotal: 20.2s\tremaining: 42.3s\n",
            "848:\tlearn: 108.5466611\ttotal: 20.3s\tremaining: 42.3s\n",
            "849:\tlearn: 108.5033572\ttotal: 20.3s\tremaining: 42.3s\n",
            "850:\tlearn: 108.4903963\ttotal: 20.3s\tremaining: 42.2s\n",
            "851:\tlearn: 108.4797641\ttotal: 20.4s\tremaining: 42.2s\n",
            "852:\tlearn: 108.4682882\ttotal: 20.4s\tremaining: 42.2s\n",
            "853:\tlearn: 108.4458755\ttotal: 20.4s\tremaining: 42.2s\n",
            "854:\tlearn: 108.4356781\ttotal: 20.4s\tremaining: 42.1s\n",
            "855:\tlearn: 108.4183059\ttotal: 20.4s\tremaining: 42.1s\n",
            "856:\tlearn: 108.4100342\ttotal: 20.5s\tremaining: 42.1s\n",
            "857:\tlearn: 108.4018277\ttotal: 20.5s\tremaining: 42s\n",
            "858:\tlearn: 108.3850155\ttotal: 20.5s\tremaining: 42s\n",
            "859:\tlearn: 108.3682999\ttotal: 20.5s\tremaining: 42s\n",
            "860:\tlearn: 108.3497262\ttotal: 20.6s\tremaining: 42s\n",
            "861:\tlearn: 108.3422834\ttotal: 20.6s\tremaining: 42s\n",
            "862:\tlearn: 108.3355284\ttotal: 20.6s\tremaining: 41.9s\n",
            "863:\tlearn: 108.3194173\ttotal: 20.6s\tremaining: 41.9s\n",
            "864:\tlearn: 108.2839943\ttotal: 20.6s\tremaining: 41.9s\n",
            "865:\tlearn: 108.2828059\ttotal: 20.7s\tremaining: 41.9s\n",
            "866:\tlearn: 108.2600923\ttotal: 20.7s\tremaining: 41.8s\n",
            "867:\tlearn: 108.2546249\ttotal: 20.7s\tremaining: 41.8s\n",
            "868:\tlearn: 108.2498144\ttotal: 20.7s\tremaining: 41.8s\n",
            "869:\tlearn: 108.2175608\ttotal: 20.8s\tremaining: 41.8s\n",
            "870:\tlearn: 108.1574175\ttotal: 20.8s\tremaining: 41.7s\n",
            "871:\tlearn: 108.1280401\ttotal: 20.8s\tremaining: 41.7s\n",
            "872:\tlearn: 108.1166203\ttotal: 20.8s\tremaining: 41.7s\n",
            "873:\tlearn: 108.0826832\ttotal: 20.9s\tremaining: 41.7s\n",
            "874:\tlearn: 108.0706979\ttotal: 20.9s\tremaining: 41.7s\n",
            "875:\tlearn: 108.0596299\ttotal: 20.9s\tremaining: 41.6s\n",
            "876:\tlearn: 108.0445894\ttotal: 20.9s\tremaining: 41.6s\n",
            "877:\tlearn: 108.0399258\ttotal: 21s\tremaining: 41.6s\n",
            "878:\tlearn: 108.0334685\ttotal: 21s\tremaining: 41.6s\n",
            "879:\tlearn: 108.0175718\ttotal: 21s\tremaining: 41.5s\n",
            "880:\tlearn: 108.0096430\ttotal: 21s\tremaining: 41.5s\n",
            "881:\tlearn: 107.9896578\ttotal: 21s\tremaining: 41.5s\n",
            "882:\tlearn: 107.9806444\ttotal: 21.1s\tremaining: 41.4s\n",
            "883:\tlearn: 107.9684043\ttotal: 21.1s\tremaining: 41.4s\n",
            "884:\tlearn: 107.9405511\ttotal: 21.1s\tremaining: 41.4s\n",
            "885:\tlearn: 107.9256434\ttotal: 21.1s\tremaining: 41.4s\n",
            "886:\tlearn: 107.9218863\ttotal: 21.2s\tremaining: 41.3s\n",
            "887:\tlearn: 107.8957148\ttotal: 21.2s\tremaining: 41.3s\n",
            "888:\tlearn: 107.8924047\ttotal: 21.2s\tremaining: 41.3s\n",
            "889:\tlearn: 107.8690278\ttotal: 21.2s\tremaining: 41.3s\n",
            "890:\tlearn: 107.8564815\ttotal: 21.3s\tremaining: 41.3s\n",
            "891:\tlearn: 107.8514563\ttotal: 21.3s\tremaining: 41.3s\n",
            "892:\tlearn: 107.8294426\ttotal: 21.4s\tremaining: 41.3s\n",
            "893:\tlearn: 107.8254282\ttotal: 21.4s\tremaining: 41.3s\n",
            "894:\tlearn: 107.8100871\ttotal: 21.4s\tremaining: 41.3s\n",
            "895:\tlearn: 107.7748105\ttotal: 21.4s\tremaining: 41.3s\n",
            "896:\tlearn: 107.7624911\ttotal: 21.5s\tremaining: 41.2s\n",
            "897:\tlearn: 107.7396613\ttotal: 21.5s\tremaining: 41.2s\n",
            "898:\tlearn: 107.7336752\ttotal: 21.5s\tremaining: 41.2s\n",
            "899:\tlearn: 107.7256153\ttotal: 21.5s\tremaining: 41.2s\n",
            "900:\tlearn: 107.7057727\ttotal: 21.6s\tremaining: 41.2s\n",
            "901:\tlearn: 107.6936290\ttotal: 21.6s\tremaining: 41.2s\n",
            "902:\tlearn: 107.6810355\ttotal: 21.6s\tremaining: 41.1s\n",
            "903:\tlearn: 107.6697332\ttotal: 21.7s\tremaining: 41.1s\n",
            "904:\tlearn: 107.6495725\ttotal: 21.7s\tremaining: 41.1s\n",
            "905:\tlearn: 107.6420708\ttotal: 21.7s\tremaining: 41.1s\n",
            "906:\tlearn: 107.6167308\ttotal: 21.7s\tremaining: 41s\n",
            "907:\tlearn: 107.5825088\ttotal: 21.8s\tremaining: 41s\n",
            "908:\tlearn: 107.5706583\ttotal: 21.8s\tremaining: 41s\n",
            "909:\tlearn: 107.5706583\ttotal: 21.8s\tremaining: 40.9s\n",
            "910:\tlearn: 107.5701300\ttotal: 21.8s\tremaining: 40.9s\n",
            "911:\tlearn: 107.5462683\ttotal: 21.8s\tremaining: 40.9s\n",
            "912:\tlearn: 107.5351285\ttotal: 21.9s\tremaining: 40.9s\n",
            "913:\tlearn: 107.5296566\ttotal: 21.9s\tremaining: 40.9s\n",
            "914:\tlearn: 107.5196684\ttotal: 21.9s\tremaining: 40.8s\n",
            "915:\tlearn: 107.4912559\ttotal: 21.9s\tremaining: 40.8s\n",
            "916:\tlearn: 107.4789436\ttotal: 22s\tremaining: 40.8s\n",
            "917:\tlearn: 107.4732931\ttotal: 22s\tremaining: 40.8s\n",
            "918:\tlearn: 107.4611267\ttotal: 22s\tremaining: 40.8s\n",
            "919:\tlearn: 107.4466761\ttotal: 22s\tremaining: 40.7s\n",
            "920:\tlearn: 107.4384476\ttotal: 22.1s\tremaining: 40.7s\n",
            "921:\tlearn: 107.4294572\ttotal: 22.1s\tremaining: 40.7s\n",
            "922:\tlearn: 107.4067763\ttotal: 22.1s\tremaining: 40.7s\n",
            "923:\tlearn: 107.3819886\ttotal: 22.1s\tremaining: 40.6s\n",
            "924:\tlearn: 107.3577249\ttotal: 22.2s\tremaining: 40.6s\n",
            "925:\tlearn: 107.3446310\ttotal: 22.2s\tremaining: 40.6s\n",
            "926:\tlearn: 107.3271080\ttotal: 22.2s\tremaining: 40.6s\n",
            "927:\tlearn: 107.3161048\ttotal: 22.2s\tremaining: 40.6s\n",
            "928:\tlearn: 107.2799417\ttotal: 22.3s\tremaining: 40.5s\n",
            "929:\tlearn: 107.2692237\ttotal: 22.3s\tremaining: 40.5s\n",
            "930:\tlearn: 107.2542698\ttotal: 22.3s\tremaining: 40.5s\n",
            "931:\tlearn: 107.2336721\ttotal: 22.3s\tremaining: 40.5s\n",
            "932:\tlearn: 107.2236228\ttotal: 22.4s\tremaining: 40.4s\n",
            "933:\tlearn: 107.1909079\ttotal: 22.4s\tremaining: 40.4s\n",
            "934:\tlearn: 107.1706834\ttotal: 22.4s\tremaining: 40.4s\n",
            "935:\tlearn: 107.1646396\ttotal: 22.4s\tremaining: 40.3s\n",
            "936:\tlearn: 107.1568085\ttotal: 22.4s\tremaining: 40.3s\n",
            "937:\tlearn: 107.1408719\ttotal: 22.5s\tremaining: 40.3s\n",
            "938:\tlearn: 107.1243388\ttotal: 22.5s\tremaining: 40.3s\n",
            "939:\tlearn: 107.0808410\ttotal: 22.5s\tremaining: 40.2s\n",
            "940:\tlearn: 107.0674940\ttotal: 22.5s\tremaining: 40.2s\n",
            "941:\tlearn: 107.0423276\ttotal: 22.6s\tremaining: 40.2s\n",
            "942:\tlearn: 107.0378858\ttotal: 22.6s\tremaining: 40.2s\n",
            "943:\tlearn: 107.0150142\ttotal: 22.6s\tremaining: 40.1s\n",
            "944:\tlearn: 107.0044840\ttotal: 22.6s\tremaining: 40.1s\n",
            "945:\tlearn: 106.9808113\ttotal: 22.7s\tremaining: 40.1s\n",
            "946:\tlearn: 106.9775213\ttotal: 22.7s\tremaining: 40.1s\n",
            "947:\tlearn: 106.9666517\ttotal: 22.7s\tremaining: 40.1s\n",
            "948:\tlearn: 106.9535685\ttotal: 22.7s\tremaining: 40s\n",
            "949:\tlearn: 106.9382825\ttotal: 22.8s\tremaining: 40s\n",
            "950:\tlearn: 106.9172869\ttotal: 22.8s\tremaining: 40s\n",
            "951:\tlearn: 106.9090154\ttotal: 22.8s\tremaining: 40s\n",
            "952:\tlearn: 106.8942999\ttotal: 22.8s\tremaining: 40s\n",
            "953:\tlearn: 106.8751179\ttotal: 22.9s\tremaining: 39.9s\n",
            "954:\tlearn: 106.8686046\ttotal: 22.9s\tremaining: 39.9s\n",
            "955:\tlearn: 106.8583592\ttotal: 22.9s\tremaining: 39.9s\n",
            "956:\tlearn: 106.8486795\ttotal: 22.9s\tremaining: 39.9s\n",
            "957:\tlearn: 106.8381643\ttotal: 23s\tremaining: 39.8s\n",
            "958:\tlearn: 106.8316842\ttotal: 23s\tremaining: 39.8s\n",
            "959:\tlearn: 106.8273913\ttotal: 23s\tremaining: 39.8s\n",
            "960:\tlearn: 106.7926832\ttotal: 23s\tremaining: 39.8s\n",
            "961:\tlearn: 106.7782794\ttotal: 23.1s\tremaining: 39.7s\n",
            "962:\tlearn: 106.7529410\ttotal: 23.1s\tremaining: 39.7s\n",
            "963:\tlearn: 106.7430142\ttotal: 23.1s\tremaining: 39.7s\n",
            "964:\tlearn: 106.7343097\ttotal: 23.1s\tremaining: 39.7s\n",
            "965:\tlearn: 106.7182656\ttotal: 23.2s\tremaining: 39.7s\n",
            "966:\tlearn: 106.7096992\ttotal: 23.2s\tremaining: 39.6s\n",
            "967:\tlearn: 106.6859720\ttotal: 23.2s\tremaining: 39.6s\n",
            "968:\tlearn: 106.6762827\ttotal: 23.2s\tremaining: 39.6s\n",
            "969:\tlearn: 106.6561433\ttotal: 23.3s\tremaining: 39.6s\n",
            "970:\tlearn: 106.6429493\ttotal: 23.3s\tremaining: 39.5s\n",
            "971:\tlearn: 106.6226395\ttotal: 23.3s\tremaining: 39.5s\n",
            "972:\tlearn: 106.6185321\ttotal: 23.3s\tremaining: 39.5s\n",
            "973:\tlearn: 106.5869854\ttotal: 23.3s\tremaining: 39.5s\n",
            "974:\tlearn: 106.5783473\ttotal: 23.4s\tremaining: 39.4s\n",
            "975:\tlearn: 106.5665923\ttotal: 23.4s\tremaining: 39.4s\n",
            "976:\tlearn: 106.5499431\ttotal: 23.4s\tremaining: 39.4s\n",
            "977:\tlearn: 106.5294013\ttotal: 23.4s\tremaining: 39.4s\n",
            "978:\tlearn: 106.5032186\ttotal: 23.5s\tremaining: 39.3s\n",
            "979:\tlearn: 106.4937861\ttotal: 23.5s\tremaining: 39.3s\n",
            "980:\tlearn: 106.4809515\ttotal: 23.5s\tremaining: 39.3s\n",
            "981:\tlearn: 106.4567045\ttotal: 23.5s\tremaining: 39.2s\n",
            "982:\tlearn: 106.4452730\ttotal: 23.6s\tremaining: 39.2s\n",
            "983:\tlearn: 106.4316565\ttotal: 23.6s\tremaining: 39.2s\n",
            "984:\tlearn: 106.4236106\ttotal: 23.6s\tremaining: 39.2s\n",
            "985:\tlearn: 106.4211121\ttotal: 23.7s\tremaining: 39.2s\n",
            "986:\tlearn: 106.4148413\ttotal: 23.7s\tremaining: 39.2s\n",
            "987:\tlearn: 106.3797737\ttotal: 23.7s\tremaining: 39.2s\n",
            "988:\tlearn: 106.3609111\ttotal: 23.7s\tremaining: 39.1s\n",
            "989:\tlearn: 106.3385076\ttotal: 23.8s\tremaining: 39.1s\n",
            "990:\tlearn: 106.3236488\ttotal: 23.8s\tremaining: 39.1s\n",
            "991:\tlearn: 106.3202643\ttotal: 23.8s\tremaining: 39.1s\n",
            "992:\tlearn: 106.3148619\ttotal: 23.8s\tremaining: 39.1s\n",
            "993:\tlearn: 106.3086041\ttotal: 23.9s\tremaining: 39s\n",
            "994:\tlearn: 106.2768234\ttotal: 23.9s\tremaining: 39s\n",
            "995:\tlearn: 106.2708820\ttotal: 23.9s\tremaining: 39s\n",
            "996:\tlearn: 106.2498355\ttotal: 23.9s\tremaining: 39s\n",
            "997:\tlearn: 106.2433047\ttotal: 24s\tremaining: 39s\n",
            "998:\tlearn: 106.2312676\ttotal: 24s\tremaining: 38.9s\n",
            "999:\tlearn: 106.2116938\ttotal: 24s\tremaining: 38.9s\n",
            "1000:\tlearn: 106.1917678\ttotal: 24s\tremaining: 38.9s\n",
            "1001:\tlearn: 106.1711476\ttotal: 24.1s\tremaining: 38.9s\n",
            "1002:\tlearn: 106.1606394\ttotal: 24.1s\tremaining: 38.9s\n",
            "1003:\tlearn: 106.1371284\ttotal: 24.1s\tremaining: 38.8s\n",
            "1004:\tlearn: 106.1230990\ttotal: 24.2s\tremaining: 38.8s\n",
            "1005:\tlearn: 106.1048003\ttotal: 24.2s\tremaining: 38.8s\n",
            "1006:\tlearn: 106.0900227\ttotal: 24.2s\tremaining: 38.8s\n",
            "1007:\tlearn: 106.0840790\ttotal: 24.2s\tremaining: 38.7s\n",
            "1008:\tlearn: 106.0785460\ttotal: 24.3s\tremaining: 38.7s\n",
            "1009:\tlearn: 106.0648961\ttotal: 24.3s\tremaining: 38.7s\n",
            "1010:\tlearn: 106.0397383\ttotal: 24.3s\tremaining: 38.7s\n",
            "1011:\tlearn: 106.0264724\ttotal: 24.3s\tremaining: 38.6s\n",
            "1012:\tlearn: 106.0120102\ttotal: 24.3s\tremaining: 38.6s\n",
            "1013:\tlearn: 105.9969476\ttotal: 24.4s\tremaining: 38.6s\n",
            "1014:\tlearn: 105.9812965\ttotal: 24.4s\tremaining: 38.6s\n",
            "1015:\tlearn: 105.9615591\ttotal: 24.4s\tremaining: 38.6s\n",
            "1016:\tlearn: 105.9573465\ttotal: 24.4s\tremaining: 38.5s\n",
            "1017:\tlearn: 105.9328332\ttotal: 24.5s\tremaining: 38.5s\n",
            "1018:\tlearn: 105.9192794\ttotal: 24.5s\tremaining: 38.5s\n",
            "1019:\tlearn: 105.9007647\ttotal: 24.5s\tremaining: 38.5s\n",
            "1020:\tlearn: 105.8981540\ttotal: 24.5s\tremaining: 38.4s\n",
            "1021:\tlearn: 105.8744930\ttotal: 24.6s\tremaining: 38.4s\n",
            "1022:\tlearn: 105.8511138\ttotal: 24.6s\tremaining: 38.4s\n",
            "1023:\tlearn: 105.8262234\ttotal: 24.6s\tremaining: 38.4s\n",
            "1024:\tlearn: 105.7578950\ttotal: 24.7s\tremaining: 38.4s\n",
            "1025:\tlearn: 105.7516538\ttotal: 24.7s\tremaining: 38.4s\n",
            "1026:\tlearn: 105.7443308\ttotal: 24.7s\tremaining: 38.3s\n",
            "1027:\tlearn: 105.7391798\ttotal: 24.7s\tremaining: 38.3s\n",
            "1028:\tlearn: 105.7298887\ttotal: 24.8s\tremaining: 38.3s\n",
            "1029:\tlearn: 105.6981046\ttotal: 24.8s\tremaining: 38.3s\n",
            "1030:\tlearn: 105.6935826\ttotal: 24.8s\tremaining: 38.2s\n",
            "1031:\tlearn: 105.6828601\ttotal: 24.8s\tremaining: 38.2s\n",
            "1032:\tlearn: 105.6778704\ttotal: 24.9s\tremaining: 38.2s\n",
            "1033:\tlearn: 105.6669137\ttotal: 24.9s\tremaining: 38.2s\n",
            "1034:\tlearn: 105.6462499\ttotal: 24.9s\tremaining: 38.1s\n",
            "1035:\tlearn: 105.6298724\ttotal: 24.9s\tremaining: 38.1s\n",
            "1036:\tlearn: 105.6176577\ttotal: 25s\tremaining: 38.1s\n",
            "1037:\tlearn: 105.6074999\ttotal: 25s\tremaining: 38.1s\n",
            "1038:\tlearn: 105.6024037\ttotal: 25s\tremaining: 38s\n",
            "1039:\tlearn: 105.5950391\ttotal: 25s\tremaining: 38s\n",
            "1040:\tlearn: 105.5885099\ttotal: 25.1s\tremaining: 38s\n",
            "1041:\tlearn: 105.5842474\ttotal: 25.1s\tremaining: 38s\n",
            "1042:\tlearn: 105.5629545\ttotal: 25.1s\tremaining: 38s\n",
            "1043:\tlearn: 105.5468746\ttotal: 25.1s\tremaining: 37.9s\n",
            "1044:\tlearn: 105.5192991\ttotal: 25.1s\tremaining: 37.9s\n",
            "1045:\tlearn: 105.5083425\ttotal: 25.2s\tremaining: 37.9s\n",
            "1046:\tlearn: 105.5015376\ttotal: 25.2s\tremaining: 37.9s\n",
            "1047:\tlearn: 105.4965899\ttotal: 25.2s\tremaining: 37.8s\n",
            "1048:\tlearn: 105.4807473\ttotal: 25.3s\tremaining: 37.8s\n",
            "1049:\tlearn: 105.4622254\ttotal: 25.3s\tremaining: 37.8s\n",
            "1050:\tlearn: 105.4542009\ttotal: 25.3s\tremaining: 37.8s\n",
            "1051:\tlearn: 105.4242277\ttotal: 25.3s\tremaining: 37.7s\n",
            "1052:\tlearn: 105.4115061\ttotal: 25.3s\tremaining: 37.7s\n",
            "1053:\tlearn: 105.4033959\ttotal: 25.4s\tremaining: 37.7s\n",
            "1054:\tlearn: 105.3920907\ttotal: 25.4s\tremaining: 37.7s\n",
            "1055:\tlearn: 105.3618536\ttotal: 25.4s\tremaining: 37.6s\n",
            "1056:\tlearn: 105.3023715\ttotal: 25.4s\tremaining: 37.6s\n",
            "1057:\tlearn: 105.2837774\ttotal: 25.4s\tremaining: 37.6s\n",
            "1058:\tlearn: 105.2758231\ttotal: 25.5s\tremaining: 37.5s\n",
            "1059:\tlearn: 105.2729949\ttotal: 25.5s\tremaining: 37.5s\n",
            "1060:\tlearn: 105.2689614\ttotal: 25.5s\tremaining: 37.5s\n",
            "1061:\tlearn: 105.2414580\ttotal: 25.6s\tremaining: 37.5s\n",
            "1062:\tlearn: 105.2252024\ttotal: 25.6s\tremaining: 37.5s\n",
            "1063:\tlearn: 105.2040071\ttotal: 25.6s\tremaining: 37.4s\n",
            "1064:\tlearn: 105.1783739\ttotal: 25.6s\tremaining: 37.4s\n",
            "1065:\tlearn: 105.1714088\ttotal: 25.7s\tremaining: 37.4s\n",
            "1066:\tlearn: 105.1584060\ttotal: 25.7s\tremaining: 37.4s\n",
            "1067:\tlearn: 105.1454841\ttotal: 25.7s\tremaining: 37.4s\n",
            "1068:\tlearn: 105.1245421\ttotal: 25.7s\tremaining: 37.3s\n",
            "1069:\tlearn: 105.1003246\ttotal: 25.8s\tremaining: 37.3s\n",
            "1070:\tlearn: 105.0927150\ttotal: 25.8s\tremaining: 37.3s\n",
            "1071:\tlearn: 105.0811415\ttotal: 25.8s\tremaining: 37.3s\n",
            "1072:\tlearn: 105.0762047\ttotal: 25.8s\tremaining: 37.2s\n",
            "1073:\tlearn: 105.0721725\ttotal: 25.8s\tremaining: 37.2s\n",
            "1074:\tlearn: 105.0607375\ttotal: 25.9s\tremaining: 37.2s\n",
            "1075:\tlearn: 105.0515444\ttotal: 25.9s\tremaining: 37.2s\n",
            "1076:\tlearn: 105.0350961\ttotal: 25.9s\tremaining: 37.1s\n",
            "1077:\tlearn: 105.0201146\ttotal: 25.9s\tremaining: 37.1s\n",
            "1078:\tlearn: 104.9922641\ttotal: 26s\tremaining: 37.1s\n",
            "1079:\tlearn: 104.9845688\ttotal: 26s\tremaining: 37.1s\n",
            "1080:\tlearn: 104.9651143\ttotal: 26s\tremaining: 37s\n",
            "1081:\tlearn: 104.9578426\ttotal: 26s\tremaining: 37s\n",
            "1082:\tlearn: 104.9391471\ttotal: 26.1s\tremaining: 37s\n",
            "1083:\tlearn: 104.9239970\ttotal: 26.1s\tremaining: 37s\n",
            "1084:\tlearn: 104.9167667\ttotal: 26.1s\tremaining: 36.9s\n",
            "1085:\tlearn: 104.8934787\ttotal: 26.1s\tremaining: 36.9s\n",
            "1086:\tlearn: 104.8760475\ttotal: 26.1s\tremaining: 36.8s\n",
            "1087:\tlearn: 104.8640188\ttotal: 26.2s\tremaining: 36.8s\n",
            "1088:\tlearn: 104.8551663\ttotal: 26.2s\tremaining: 36.8s\n",
            "1089:\tlearn: 104.8341428\ttotal: 26.2s\tremaining: 36.8s\n",
            "1090:\tlearn: 104.8181105\ttotal: 26.2s\tremaining: 36.8s\n",
            "1091:\tlearn: 104.8181105\ttotal: 26.2s\tremaining: 36.7s\n",
            "1092:\tlearn: 104.8079182\ttotal: 26.3s\tremaining: 36.7s\n",
            "1093:\tlearn: 104.8006540\ttotal: 26.3s\tremaining: 36.7s\n",
            "1094:\tlearn: 104.7986732\ttotal: 26.3s\tremaining: 36.6s\n",
            "1095:\tlearn: 104.7839497\ttotal: 26.3s\tremaining: 36.6s\n",
            "1096:\tlearn: 104.7658358\ttotal: 26.4s\tremaining: 36.6s\n",
            "1097:\tlearn: 104.7486031\ttotal: 26.4s\tremaining: 36.6s\n",
            "1098:\tlearn: 104.7258173\ttotal: 26.4s\tremaining: 36.5s\n",
            "1099:\tlearn: 104.7029642\ttotal: 26.4s\tremaining: 36.5s\n",
            "1100:\tlearn: 104.6935468\ttotal: 26.4s\tremaining: 36.5s\n",
            "1101:\tlearn: 104.6762618\ttotal: 26.5s\tremaining: 36.5s\n",
            "1102:\tlearn: 104.6591857\ttotal: 26.5s\tremaining: 36.4s\n",
            "1103:\tlearn: 104.6441141\ttotal: 26.5s\tremaining: 36.4s\n",
            "1104:\tlearn: 104.6234276\ttotal: 26.5s\tremaining: 36.4s\n",
            "1105:\tlearn: 104.6138806\ttotal: 26.6s\tremaining: 36.4s\n",
            "1106:\tlearn: 104.6094812\ttotal: 26.6s\tremaining: 36.3s\n",
            "1107:\tlearn: 104.5980017\ttotal: 26.6s\tremaining: 36.3s\n",
            "1108:\tlearn: 104.5810979\ttotal: 26.6s\tremaining: 36.3s\n",
            "1109:\tlearn: 104.5627484\ttotal: 26.7s\tremaining: 36.3s\n",
            "1110:\tlearn: 104.5444042\ttotal: 26.7s\tremaining: 36.3s\n",
            "1111:\tlearn: 104.5357762\ttotal: 26.7s\tremaining: 36.2s\n",
            "1112:\tlearn: 104.5265229\ttotal: 26.7s\tremaining: 36.2s\n",
            "1113:\tlearn: 104.5178732\ttotal: 26.8s\tremaining: 36.2s\n",
            "1114:\tlearn: 104.5049240\ttotal: 26.8s\tremaining: 36.1s\n",
            "1115:\tlearn: 104.4952120\ttotal: 26.8s\tremaining: 36.1s\n",
            "1116:\tlearn: 104.4837341\ttotal: 26.8s\tremaining: 36.1s\n",
            "1117:\tlearn: 104.4790337\ttotal: 26.9s\tremaining: 36.1s\n",
            "1118:\tlearn: 104.4709737\ttotal: 26.9s\tremaining: 36.1s\n",
            "1119:\tlearn: 104.4604332\ttotal: 26.9s\tremaining: 36s\n",
            "1120:\tlearn: 104.4357632\ttotal: 26.9s\tremaining: 36s\n",
            "1121:\tlearn: 104.4231078\ttotal: 27s\tremaining: 36s\n",
            "1122:\tlearn: 104.4021048\ttotal: 27s\tremaining: 36s\n",
            "1123:\tlearn: 104.3838005\ttotal: 27s\tremaining: 36s\n",
            "1124:\tlearn: 104.3737059\ttotal: 27s\tremaining: 35.9s\n",
            "1125:\tlearn: 104.3445019\ttotal: 27.1s\tremaining: 35.9s\n",
            "1126:\tlearn: 104.3391886\ttotal: 27.1s\tremaining: 35.9s\n",
            "1127:\tlearn: 104.3290494\ttotal: 27.1s\tremaining: 35.9s\n",
            "1128:\tlearn: 104.3017187\ttotal: 27.1s\tremaining: 35.8s\n",
            "1129:\tlearn: 104.2742684\ttotal: 27.2s\tremaining: 35.8s\n",
            "1130:\tlearn: 104.2378212\ttotal: 27.2s\tremaining: 35.8s\n",
            "1131:\tlearn: 104.2180039\ttotal: 27.2s\tremaining: 35.8s\n",
            "1132:\tlearn: 104.1985632\ttotal: 27.2s\tremaining: 35.8s\n",
            "1133:\tlearn: 104.1856711\ttotal: 27.3s\tremaining: 35.7s\n",
            "1134:\tlearn: 104.1688715\ttotal: 27.3s\tremaining: 35.7s\n",
            "1135:\tlearn: 104.1590874\ttotal: 27.3s\tremaining: 35.7s\n",
            "1136:\tlearn: 104.1463367\ttotal: 27.3s\tremaining: 35.6s\n",
            "1137:\tlearn: 104.1233864\ttotal: 27.3s\tremaining: 35.6s\n",
            "1138:\tlearn: 104.1106357\ttotal: 27.4s\tremaining: 35.6s\n",
            "1139:\tlearn: 104.1008968\ttotal: 27.4s\tremaining: 35.6s\n",
            "1140:\tlearn: 104.0816242\ttotal: 27.4s\tremaining: 35.5s\n",
            "1141:\tlearn: 104.0594184\ttotal: 27.4s\tremaining: 35.5s\n",
            "1142:\tlearn: 104.0457802\ttotal: 27.5s\tremaining: 35.5s\n",
            "1143:\tlearn: 104.0288002\ttotal: 27.5s\tremaining: 35.5s\n",
            "1144:\tlearn: 104.0115911\ttotal: 27.5s\tremaining: 35.5s\n",
            "1145:\tlearn: 104.0030063\ttotal: 27.5s\tremaining: 35.4s\n",
            "1146:\tlearn: 103.9854831\ttotal: 27.6s\tremaining: 35.4s\n",
            "1147:\tlearn: 103.9644354\ttotal: 27.6s\tremaining: 35.4s\n",
            "1148:\tlearn: 103.9527053\ttotal: 27.6s\tremaining: 35.3s\n",
            "1149:\tlearn: 103.9338974\ttotal: 27.6s\tremaining: 35.3s\n",
            "1150:\tlearn: 103.9103005\ttotal: 27.6s\tremaining: 35.3s\n",
            "1151:\tlearn: 103.8794174\ttotal: 27.7s\tremaining: 35.3s\n",
            "1152:\tlearn: 103.8642269\ttotal: 27.7s\tremaining: 35.2s\n",
            "1153:\tlearn: 103.8519084\ttotal: 27.7s\tremaining: 35.2s\n",
            "1154:\tlearn: 103.8475511\ttotal: 27.7s\tremaining: 35.2s\n",
            "1155:\tlearn: 103.8385580\ttotal: 27.8s\tremaining: 35.1s\n",
            "1156:\tlearn: 103.8141743\ttotal: 27.8s\tremaining: 35.1s\n",
            "1157:\tlearn: 103.8039083\ttotal: 27.8s\tremaining: 35.1s\n",
            "1158:\tlearn: 103.7770141\ttotal: 27.8s\tremaining: 35.1s\n",
            "1159:\tlearn: 103.7731167\ttotal: 27.8s\tremaining: 35s\n",
            "1160:\tlearn: 103.7626195\ttotal: 27.9s\tremaining: 35s\n",
            "1161:\tlearn: 103.7442288\ttotal: 27.9s\tremaining: 35s\n",
            "1162:\tlearn: 103.7337971\ttotal: 27.9s\tremaining: 35s\n",
            "1163:\tlearn: 103.7214625\ttotal: 28s\tremaining: 35s\n",
            "1164:\tlearn: 103.7054942\ttotal: 28s\tremaining: 34.9s\n",
            "1165:\tlearn: 103.6981271\ttotal: 28s\tremaining: 34.9s\n",
            "1166:\tlearn: 103.6819668\ttotal: 28s\tremaining: 34.9s\n",
            "1167:\tlearn: 103.6699040\ttotal: 28s\tremaining: 34.9s\n",
            "1168:\tlearn: 103.6644708\ttotal: 28.1s\tremaining: 34.8s\n",
            "1169:\tlearn: 103.6598144\ttotal: 28.1s\tremaining: 34.8s\n",
            "1170:\tlearn: 103.6423072\ttotal: 28.1s\tremaining: 34.8s\n",
            "1171:\tlearn: 103.6336922\ttotal: 28.1s\tremaining: 34.8s\n",
            "1172:\tlearn: 103.6060423\ttotal: 28.2s\tremaining: 34.8s\n",
            "1173:\tlearn: 103.6001895\ttotal: 28.2s\tremaining: 34.7s\n",
            "1174:\tlearn: 103.5887832\ttotal: 28.2s\tremaining: 34.7s\n",
            "1175:\tlearn: 103.5822152\ttotal: 28.3s\tremaining: 34.7s\n",
            "1176:\tlearn: 103.5544282\ttotal: 28.3s\tremaining: 34.7s\n",
            "1177:\tlearn: 103.5302770\ttotal: 28.3s\tremaining: 34.6s\n",
            "1178:\tlearn: 103.5208962\ttotal: 28.3s\tremaining: 34.6s\n",
            "1179:\tlearn: 103.5171265\ttotal: 28.4s\tremaining: 34.6s\n",
            "1180:\tlearn: 103.4949545\ttotal: 28.4s\tremaining: 34.6s\n",
            "1181:\tlearn: 103.4852582\ttotal: 28.4s\tremaining: 34.6s\n",
            "1182:\tlearn: 103.4844242\ttotal: 28.4s\tremaining: 34.5s\n",
            "1183:\tlearn: 103.4715374\ttotal: 28.5s\tremaining: 34.5s\n",
            "1184:\tlearn: 103.4394998\ttotal: 28.5s\tremaining: 34.5s\n",
            "1185:\tlearn: 103.4032445\ttotal: 28.5s\tremaining: 34.5s\n",
            "1186:\tlearn: 103.3976320\ttotal: 28.5s\tremaining: 34.4s\n",
            "1187:\tlearn: 103.3956034\ttotal: 28.5s\tremaining: 34.4s\n",
            "1188:\tlearn: 103.3822131\ttotal: 28.6s\tremaining: 34.4s\n",
            "1189:\tlearn: 103.3698080\ttotal: 28.6s\tremaining: 34.4s\n",
            "1190:\tlearn: 103.3651805\ttotal: 28.6s\tremaining: 34.3s\n",
            "1191:\tlearn: 103.3484526\ttotal: 28.6s\tremaining: 34.3s\n",
            "1192:\tlearn: 103.3432858\ttotal: 28.7s\tremaining: 34.3s\n",
            "1193:\tlearn: 103.3354532\ttotal: 28.7s\tremaining: 34.3s\n",
            "1194:\tlearn: 103.3220671\ttotal: 28.7s\tremaining: 34.3s\n",
            "1195:\tlearn: 103.2845231\ttotal: 28.8s\tremaining: 34.2s\n",
            "1196:\tlearn: 103.2630641\ttotal: 28.8s\tremaining: 34.2s\n",
            "1197:\tlearn: 103.2489665\ttotal: 28.8s\tremaining: 34.2s\n",
            "1198:\tlearn: 103.2399537\ttotal: 28.8s\tremaining: 34.2s\n",
            "1199:\tlearn: 103.2186160\ttotal: 28.9s\tremaining: 34.2s\n",
            "1200:\tlearn: 103.2022339\ttotal: 28.9s\tremaining: 34.1s\n",
            "1201:\tlearn: 103.1886083\ttotal: 28.9s\tremaining: 34.1s\n",
            "1202:\tlearn: 103.1804485\ttotal: 28.9s\tremaining: 34.1s\n",
            "1203:\tlearn: 103.1396433\ttotal: 29s\tremaining: 34.1s\n",
            "1204:\tlearn: 103.1155101\ttotal: 29s\tremaining: 34s\n",
            "1205:\tlearn: 103.0627086\ttotal: 29s\tremaining: 34s\n",
            "1206:\tlearn: 103.0474663\ttotal: 29s\tremaining: 34s\n",
            "1207:\tlearn: 103.0101702\ttotal: 29.1s\tremaining: 34s\n",
            "1208:\tlearn: 102.9955414\ttotal: 29.1s\tremaining: 34s\n",
            "1209:\tlearn: 102.9816571\ttotal: 29.1s\tremaining: 33.9s\n",
            "1210:\tlearn: 102.9553144\ttotal: 29.1s\tremaining: 33.9s\n",
            "1211:\tlearn: 102.9446993\ttotal: 29.2s\tremaining: 33.9s\n",
            "1212:\tlearn: 102.9368332\ttotal: 29.2s\tremaining: 33.8s\n",
            "1213:\tlearn: 102.9294896\ttotal: 29.2s\tremaining: 33.8s\n",
            "1214:\tlearn: 102.9063562\ttotal: 29.2s\tremaining: 33.8s\n",
            "1215:\tlearn: 102.8711298\ttotal: 29.2s\tremaining: 33.8s\n",
            "1216:\tlearn: 102.8600236\ttotal: 29.3s\tremaining: 33.7s\n",
            "1217:\tlearn: 102.8552721\ttotal: 29.3s\tremaining: 33.7s\n",
            "1218:\tlearn: 102.8385270\ttotal: 29.3s\tremaining: 33.7s\n",
            "1219:\tlearn: 102.8293015\ttotal: 29.3s\tremaining: 33.7s\n",
            "1220:\tlearn: 102.8150468\ttotal: 29.4s\tremaining: 33.7s\n",
            "1221:\tlearn: 102.8081106\ttotal: 29.4s\tremaining: 33.6s\n",
            "1222:\tlearn: 102.8054457\ttotal: 29.4s\tremaining: 33.6s\n",
            "1223:\tlearn: 102.7892809\ttotal: 29.4s\tremaining: 33.6s\n",
            "1224:\tlearn: 102.7793318\ttotal: 29.5s\tremaining: 33.6s\n",
            "1225:\tlearn: 102.7623991\ttotal: 29.5s\tremaining: 33.5s\n",
            "1226:\tlearn: 102.7563459\ttotal: 29.5s\tremaining: 33.5s\n",
            "1227:\tlearn: 102.7446884\ttotal: 29.5s\tremaining: 33.5s\n",
            "1228:\tlearn: 102.7354163\ttotal: 29.5s\tremaining: 33.4s\n",
            "1229:\tlearn: 102.7194436\ttotal: 29.6s\tremaining: 33.4s\n",
            "1230:\tlearn: 102.7074407\ttotal: 29.6s\tremaining: 33.4s\n",
            "1231:\tlearn: 102.6859091\ttotal: 29.6s\tremaining: 33.4s\n",
            "1232:\tlearn: 102.6791788\ttotal: 29.6s\tremaining: 33.3s\n",
            "1233:\tlearn: 102.6695837\ttotal: 29.7s\tremaining: 33.3s\n",
            "1234:\tlearn: 102.6556810\ttotal: 29.7s\tremaining: 33.3s\n",
            "1235:\tlearn: 102.6484678\ttotal: 29.7s\tremaining: 33.3s\n",
            "1236:\tlearn: 102.6344306\ttotal: 29.7s\tremaining: 33.2s\n",
            "1237:\tlearn: 102.6289974\ttotal: 29.8s\tremaining: 33.2s\n",
            "1238:\tlearn: 102.6203165\ttotal: 29.8s\tremaining: 33.2s\n",
            "1239:\tlearn: 102.6012728\ttotal: 29.8s\tremaining: 33.2s\n",
            "1240:\tlearn: 102.5945776\ttotal: 29.8s\tremaining: 33.2s\n",
            "1241:\tlearn: 102.5942330\ttotal: 29.9s\tremaining: 33.1s\n",
            "1242:\tlearn: 102.5832288\ttotal: 29.9s\tremaining: 33.1s\n",
            "1243:\tlearn: 102.5789718\ttotal: 29.9s\tremaining: 33.1s\n",
            "1244:\tlearn: 102.5565908\ttotal: 29.9s\tremaining: 33.1s\n",
            "1245:\tlearn: 102.5419529\ttotal: 29.9s\tremaining: 33s\n",
            "1246:\tlearn: 102.5243439\ttotal: 30s\tremaining: 33s\n",
            "1247:\tlearn: 102.5223743\ttotal: 30s\tremaining: 33s\n",
            "1248:\tlearn: 102.4962319\ttotal: 30s\tremaining: 33s\n",
            "1249:\tlearn: 102.4889348\ttotal: 30.1s\tremaining: 32.9s\n",
            "1250:\tlearn: 102.4801660\ttotal: 30.1s\tremaining: 32.9s\n",
            "1251:\tlearn: 102.4719771\ttotal: 30.1s\tremaining: 32.9s\n",
            "1252:\tlearn: 102.4605797\ttotal: 30.1s\tremaining: 32.9s\n",
            "1253:\tlearn: 102.4543900\ttotal: 30.1s\tremaining: 32.8s\n",
            "1254:\tlearn: 102.4424282\ttotal: 30.2s\tremaining: 32.8s\n",
            "1255:\tlearn: 102.4342137\ttotal: 30.2s\tremaining: 32.8s\n",
            "1256:\tlearn: 102.4251600\ttotal: 30.2s\tremaining: 32.8s\n",
            "1257:\tlearn: 102.4016937\ttotal: 30.2s\tremaining: 32.7s\n",
            "1258:\tlearn: 102.3906347\ttotal: 30.3s\tremaining: 32.7s\n",
            "1259:\tlearn: 102.3489996\ttotal: 30.3s\tremaining: 32.7s\n",
            "1260:\tlearn: 102.3201797\ttotal: 30.3s\tremaining: 32.7s\n",
            "1261:\tlearn: 102.3073308\ttotal: 30.3s\tremaining: 32.6s\n",
            "1262:\tlearn: 102.2907181\ttotal: 30.4s\tremaining: 32.6s\n",
            "1263:\tlearn: 102.2765915\ttotal: 30.4s\tremaining: 32.6s\n",
            "1264:\tlearn: 102.2650928\ttotal: 30.4s\tremaining: 32.6s\n",
            "1265:\tlearn: 102.2564296\ttotal: 30.4s\tremaining: 32.5s\n",
            "1266:\tlearn: 102.2372897\ttotal: 30.4s\tremaining: 32.5s\n",
            "1267:\tlearn: 102.2212326\ttotal: 30.5s\tremaining: 32.5s\n",
            "1268:\tlearn: 102.2171428\ttotal: 30.5s\tremaining: 32.5s\n",
            "1269:\tlearn: 102.1988377\ttotal: 30.5s\tremaining: 32.4s\n",
            "1270:\tlearn: 102.1845911\ttotal: 30.5s\tremaining: 32.4s\n",
            "1271:\tlearn: 102.1812112\ttotal: 30.6s\tremaining: 32.4s\n",
            "1272:\tlearn: 102.1717791\ttotal: 30.6s\tremaining: 32.4s\n",
            "1273:\tlearn: 102.1582552\ttotal: 30.6s\tremaining: 32.4s\n",
            "1274:\tlearn: 102.1468768\ttotal: 30.7s\tremaining: 32.3s\n",
            "1275:\tlearn: 102.1377582\ttotal: 30.7s\tremaining: 32.3s\n",
            "1276:\tlearn: 102.1228585\ttotal: 30.7s\tremaining: 32.3s\n",
            "1277:\tlearn: 102.0997871\ttotal: 30.7s\tremaining: 32.3s\n",
            "1278:\tlearn: 102.0900412\ttotal: 30.7s\tremaining: 32.2s\n",
            "1279:\tlearn: 102.0852550\ttotal: 30.8s\tremaining: 32.2s\n",
            "1280:\tlearn: 102.0748002\ttotal: 30.8s\tremaining: 32.2s\n",
            "1281:\tlearn: 102.0610372\ttotal: 30.8s\tremaining: 32.2s\n",
            "1282:\tlearn: 102.0369628\ttotal: 30.8s\tremaining: 32.1s\n",
            "1283:\tlearn: 102.0291106\ttotal: 30.9s\tremaining: 32.1s\n",
            "1284:\tlearn: 102.0207969\ttotal: 30.9s\tremaining: 32.1s\n",
            "1285:\tlearn: 102.0193634\ttotal: 30.9s\tremaining: 32.1s\n",
            "1286:\tlearn: 102.0112259\ttotal: 30.9s\tremaining: 32s\n",
            "1287:\tlearn: 102.0103381\ttotal: 31s\tremaining: 32s\n",
            "1288:\tlearn: 102.0017159\ttotal: 31s\tremaining: 32s\n",
            "1289:\tlearn: 101.9850946\ttotal: 31s\tremaining: 32s\n",
            "1290:\tlearn: 101.9696844\ttotal: 31.1s\tremaining: 32s\n",
            "1291:\tlearn: 101.9435504\ttotal: 31.1s\tremaining: 31.9s\n",
            "1292:\tlearn: 101.9310668\ttotal: 31.1s\tremaining: 31.9s\n",
            "1293:\tlearn: 101.9288507\ttotal: 31.1s\tremaining: 31.9s\n",
            "1294:\tlearn: 101.9173649\ttotal: 31.2s\tremaining: 31.9s\n",
            "1295:\tlearn: 101.9030309\ttotal: 31.2s\tremaining: 31.9s\n",
            "1296:\tlearn: 101.8835129\ttotal: 31.2s\tremaining: 31.8s\n",
            "1297:\tlearn: 101.8791385\ttotal: 31.2s\tremaining: 31.8s\n",
            "1298:\tlearn: 101.8639729\ttotal: 31.2s\tremaining: 31.8s\n",
            "1299:\tlearn: 101.8512100\ttotal: 31.3s\tremaining: 31.8s\n",
            "1300:\tlearn: 101.8480095\ttotal: 31.3s\tremaining: 31.7s\n",
            "1301:\tlearn: 101.8428488\ttotal: 31.3s\tremaining: 31.7s\n",
            "1302:\tlearn: 101.8333205\ttotal: 31.3s\tremaining: 31.7s\n",
            "1303:\tlearn: 101.8158818\ttotal: 31.4s\tremaining: 31.7s\n",
            "1304:\tlearn: 101.8083856\ttotal: 31.4s\tremaining: 31.6s\n",
            "1305:\tlearn: 101.7992341\ttotal: 31.4s\tremaining: 31.6s\n",
            "1306:\tlearn: 101.7805912\ttotal: 31.4s\tremaining: 31.6s\n",
            "1307:\tlearn: 101.7553289\ttotal: 31.5s\tremaining: 31.6s\n",
            "1308:\tlearn: 101.7390807\ttotal: 31.5s\tremaining: 31.5s\n",
            "1309:\tlearn: 101.7137011\ttotal: 31.5s\tremaining: 31.5s\n",
            "1310:\tlearn: 101.7044724\ttotal: 31.5s\tremaining: 31.5s\n",
            "1311:\tlearn: 101.6946852\ttotal: 31.6s\tremaining: 31.5s\n",
            "1312:\tlearn: 101.6667369\ttotal: 31.6s\tremaining: 31.4s\n",
            "1313:\tlearn: 101.6549131\ttotal: 31.6s\tremaining: 31.4s\n",
            "1314:\tlearn: 101.6407499\ttotal: 31.6s\tremaining: 31.4s\n",
            "1315:\tlearn: 101.6377839\ttotal: 31.7s\tremaining: 31.4s\n",
            "1316:\tlearn: 101.6217575\ttotal: 31.7s\tremaining: 31.4s\n",
            "1317:\tlearn: 101.6081347\ttotal: 31.7s\tremaining: 31.3s\n",
            "1318:\tlearn: 101.5903882\ttotal: 31.7s\tremaining: 31.3s\n",
            "1319:\tlearn: 101.5830339\ttotal: 31.8s\tremaining: 31.3s\n",
            "1320:\tlearn: 101.5706337\ttotal: 31.8s\tremaining: 31.2s\n",
            "1321:\tlearn: 101.5612818\ttotal: 31.8s\tremaining: 31.2s\n",
            "1322:\tlearn: 101.5392755\ttotal: 31.8s\tremaining: 31.2s\n",
            "1323:\tlearn: 101.5353638\ttotal: 31.8s\tremaining: 31.2s\n",
            "1324:\tlearn: 101.5278710\ttotal: 31.9s\tremaining: 31.1s\n",
            "1325:\tlearn: 101.5137187\ttotal: 31.9s\tremaining: 31.1s\n",
            "1326:\tlearn: 101.5012919\ttotal: 31.9s\tremaining: 31.1s\n",
            "1327:\tlearn: 101.4934960\ttotal: 31.9s\tremaining: 31.1s\n",
            "1328:\tlearn: 101.4788000\ttotal: 32s\tremaining: 31.1s\n",
            "1329:\tlearn: 101.4696376\ttotal: 32s\tremaining: 31s\n",
            "1330:\tlearn: 101.4675821\ttotal: 32s\tremaining: 31s\n",
            "1331:\tlearn: 101.4564444\ttotal: 32s\tremaining: 31s\n",
            "1332:\tlearn: 101.4343348\ttotal: 32.1s\tremaining: 31s\n",
            "1333:\tlearn: 101.4317053\ttotal: 32.1s\tremaining: 30.9s\n",
            "1334:\tlearn: 101.4125927\ttotal: 32.1s\tremaining: 30.9s\n",
            "1335:\tlearn: 101.4014619\ttotal: 32.1s\tremaining: 30.9s\n",
            "1336:\tlearn: 101.3947422\ttotal: 32.2s\tremaining: 30.9s\n",
            "1337:\tlearn: 101.3789686\ttotal: 32.2s\tremaining: 30.8s\n",
            "1338:\tlearn: 101.3744077\ttotal: 32.2s\tremaining: 30.8s\n",
            "1339:\tlearn: 101.3620622\ttotal: 32.2s\tremaining: 30.8s\n",
            "1340:\tlearn: 101.3401352\ttotal: 32.2s\tremaining: 30.8s\n",
            "1341:\tlearn: 101.3221086\ttotal: 32.3s\tremaining: 30.7s\n",
            "1342:\tlearn: 101.3166151\ttotal: 32.3s\tremaining: 30.7s\n",
            "1343:\tlearn: 101.3078536\ttotal: 32.3s\tremaining: 30.7s\n",
            "1344:\tlearn: 101.2929061\ttotal: 32.4s\tremaining: 30.7s\n",
            "1345:\tlearn: 101.2875762\ttotal: 32.4s\tremaining: 30.7s\n",
            "1346:\tlearn: 101.2614550\ttotal: 32.4s\tremaining: 30.6s\n",
            "1347:\tlearn: 101.2485262\ttotal: 32.4s\tremaining: 30.6s\n",
            "1348:\tlearn: 101.2413169\ttotal: 32.4s\tremaining: 30.6s\n",
            "1349:\tlearn: 101.2304061\ttotal: 32.5s\tremaining: 30.6s\n",
            "1350:\tlearn: 101.2198192\ttotal: 32.5s\tremaining: 30.5s\n",
            "1351:\tlearn: 101.2021287\ttotal: 32.5s\tremaining: 30.5s\n",
            "1352:\tlearn: 101.1876065\ttotal: 32.5s\tremaining: 30.5s\n",
            "1353:\tlearn: 101.1796768\ttotal: 32.6s\tremaining: 30.4s\n",
            "1354:\tlearn: 101.1679677\ttotal: 32.6s\tremaining: 30.4s\n",
            "1355:\tlearn: 101.1601300\ttotal: 32.6s\tremaining: 30.4s\n",
            "1356:\tlearn: 101.1561728\ttotal: 32.6s\tremaining: 30.4s\n",
            "1357:\tlearn: 101.1408401\ttotal: 32.6s\tremaining: 30.3s\n",
            "1358:\tlearn: 101.1214159\ttotal: 32.7s\tremaining: 30.3s\n",
            "1359:\tlearn: 101.1050197\ttotal: 32.7s\tremaining: 30.3s\n",
            "1360:\tlearn: 101.1029573\ttotal: 32.7s\tremaining: 30.3s\n",
            "1361:\tlearn: 101.1015457\ttotal: 32.8s\tremaining: 30.3s\n",
            "1362:\tlearn: 101.0856648\ttotal: 32.8s\tremaining: 30.2s\n",
            "1363:\tlearn: 101.0516785\ttotal: 32.8s\tremaining: 30.2s\n",
            "1364:\tlearn: 101.0494194\ttotal: 32.8s\tremaining: 30.2s\n",
            "1365:\tlearn: 101.0442423\ttotal: 32.9s\tremaining: 30.2s\n",
            "1366:\tlearn: 101.0416226\ttotal: 32.9s\tremaining: 30.1s\n",
            "1367:\tlearn: 101.0325672\ttotal: 32.9s\tremaining: 30.1s\n",
            "1368:\tlearn: 101.0308028\ttotal: 32.9s\tremaining: 30.1s\n",
            "1369:\tlearn: 101.0280950\ttotal: 33s\tremaining: 30.1s\n",
            "1370:\tlearn: 101.0190691\ttotal: 33s\tremaining: 30.1s\n",
            "1371:\tlearn: 101.0033869\ttotal: 33s\tremaining: 30s\n",
            "1372:\tlearn: 100.9932088\ttotal: 33s\tremaining: 30s\n",
            "1373:\tlearn: 100.9924314\ttotal: 33.1s\tremaining: 30s\n",
            "1374:\tlearn: 100.9836397\ttotal: 33.1s\tremaining: 30s\n",
            "1375:\tlearn: 100.9734519\ttotal: 33.1s\tremaining: 29.9s\n",
            "1376:\tlearn: 100.9667168\ttotal: 33.1s\tremaining: 29.9s\n",
            "1377:\tlearn: 100.9615840\ttotal: 33.1s\tremaining: 29.9s\n",
            "1378:\tlearn: 100.9473480\ttotal: 33.2s\tremaining: 29.8s\n",
            "1379:\tlearn: 100.9401988\ttotal: 33.2s\tremaining: 29.8s\n",
            "1380:\tlearn: 100.9333300\ttotal: 33.2s\tremaining: 29.8s\n",
            "1381:\tlearn: 100.9213094\ttotal: 33.2s\tremaining: 29.8s\n",
            "1382:\tlearn: 100.9060147\ttotal: 33.3s\tremaining: 29.8s\n",
            "1383:\tlearn: 100.8878123\ttotal: 33.3s\tremaining: 29.7s\n",
            "1384:\tlearn: 100.8619278\ttotal: 33.3s\tremaining: 29.7s\n",
            "1385:\tlearn: 100.8547199\ttotal: 33.3s\tremaining: 29.7s\n",
            "1386:\tlearn: 100.8427095\ttotal: 33.4s\tremaining: 29.7s\n",
            "1387:\tlearn: 100.8235063\ttotal: 33.4s\tremaining: 29.6s\n",
            "1388:\tlearn: 100.8108548\ttotal: 33.4s\tremaining: 29.6s\n",
            "1389:\tlearn: 100.8042144\ttotal: 33.4s\tremaining: 29.6s\n",
            "1390:\tlearn: 100.7773509\ttotal: 33.5s\tremaining: 29.6s\n",
            "1391:\tlearn: 100.7639486\ttotal: 33.5s\tremaining: 29.5s\n",
            "1392:\tlearn: 100.7419218\ttotal: 33.5s\tremaining: 29.5s\n",
            "1393:\tlearn: 100.7384747\ttotal: 33.5s\tremaining: 29.5s\n",
            "1394:\tlearn: 100.7266754\ttotal: 33.6s\tremaining: 29.5s\n",
            "1395:\tlearn: 100.7162461\ttotal: 33.6s\tremaining: 29.5s\n",
            "1396:\tlearn: 100.7125913\ttotal: 33.6s\tremaining: 29.4s\n",
            "1397:\tlearn: 100.7035920\ttotal: 33.6s\tremaining: 29.4s\n",
            "1398:\tlearn: 100.7025216\ttotal: 33.7s\tremaining: 29.4s\n",
            "1399:\tlearn: 100.6929075\ttotal: 33.7s\tremaining: 29.4s\n",
            "1400:\tlearn: 100.6929010\ttotal: 33.7s\tremaining: 29.3s\n",
            "1401:\tlearn: 100.6761696\ttotal: 33.7s\tremaining: 29.3s\n",
            "1402:\tlearn: 100.6579142\ttotal: 33.8s\tremaining: 29.3s\n",
            "1403:\tlearn: 100.6404620\ttotal: 33.8s\tremaining: 29.3s\n",
            "1404:\tlearn: 100.6373890\ttotal: 33.8s\tremaining: 29.2s\n",
            "1405:\tlearn: 100.6155892\ttotal: 33.8s\tremaining: 29.2s\n",
            "1406:\tlearn: 100.6091735\ttotal: 33.8s\tremaining: 29.2s\n",
            "1407:\tlearn: 100.5828593\ttotal: 33.9s\tremaining: 29.2s\n",
            "1408:\tlearn: 100.5748541\ttotal: 33.9s\tremaining: 29.1s\n",
            "1409:\tlearn: 100.5694101\ttotal: 33.9s\tremaining: 29.1s\n",
            "1410:\tlearn: 100.5593313\ttotal: 34s\tremaining: 29.1s\n",
            "1411:\tlearn: 100.5502911\ttotal: 34s\tremaining: 29.1s\n",
            "1412:\tlearn: 100.5268824\ttotal: 34s\tremaining: 29.1s\n",
            "1413:\tlearn: 100.5108131\ttotal: 34s\tremaining: 29s\n",
            "1414:\tlearn: 100.4999026\ttotal: 34.1s\tremaining: 29s\n",
            "1415:\tlearn: 100.4864306\ttotal: 34.1s\tremaining: 29s\n",
            "1416:\tlearn: 100.4645330\ttotal: 34.1s\tremaining: 29s\n",
            "1417:\tlearn: 100.4447885\ttotal: 34.1s\tremaining: 28.9s\n",
            "1418:\tlearn: 100.4315568\ttotal: 34.2s\tremaining: 28.9s\n",
            "1419:\tlearn: 100.4179824\ttotal: 34.2s\tremaining: 28.9s\n",
            "1420:\tlearn: 100.4052201\ttotal: 34.2s\tremaining: 28.9s\n",
            "1421:\tlearn: 100.3936154\ttotal: 34.3s\tremaining: 28.9s\n",
            "1422:\tlearn: 100.3918982\ttotal: 34.3s\tremaining: 28.8s\n",
            "1423:\tlearn: 100.3725701\ttotal: 34.3s\tremaining: 28.8s\n",
            "1424:\tlearn: 100.3628947\ttotal: 34.3s\tremaining: 28.8s\n",
            "1425:\tlearn: 100.3551279\ttotal: 34.3s\tremaining: 28.8s\n",
            "1426:\tlearn: 100.3491729\ttotal: 34.4s\tremaining: 28.7s\n",
            "1427:\tlearn: 100.3439076\ttotal: 34.4s\tremaining: 28.7s\n",
            "1428:\tlearn: 100.3420290\ttotal: 34.4s\tremaining: 28.7s\n",
            "1429:\tlearn: 100.3347873\ttotal: 34.4s\tremaining: 28.7s\n",
            "1430:\tlearn: 100.3200741\ttotal: 34.5s\tremaining: 28.6s\n",
            "1431:\tlearn: 100.3134009\ttotal: 34.5s\tremaining: 28.6s\n",
            "1432:\tlearn: 100.3085217\ttotal: 34.5s\tremaining: 28.6s\n",
            "1433:\tlearn: 100.3041307\ttotal: 34.5s\tremaining: 28.6s\n",
            "1434:\tlearn: 100.2729262\ttotal: 34.5s\tremaining: 28.5s\n",
            "1435:\tlearn: 100.2624254\ttotal: 34.6s\tremaining: 28.5s\n",
            "1436:\tlearn: 100.2572221\ttotal: 34.6s\tremaining: 28.5s\n",
            "1437:\tlearn: 100.2405182\ttotal: 34.6s\tremaining: 28.4s\n",
            "1438:\tlearn: 100.2220584\ttotal: 34.6s\tremaining: 28.4s\n",
            "1439:\tlearn: 100.2156118\ttotal: 34.7s\tremaining: 28.4s\n",
            "1440:\tlearn: 100.2132965\ttotal: 34.7s\tremaining: 28.4s\n",
            "1441:\tlearn: 100.2088924\ttotal: 34.7s\tremaining: 28.4s\n",
            "1442:\tlearn: 100.1968715\ttotal: 34.7s\tremaining: 28.3s\n",
            "1443:\tlearn: 100.1921905\ttotal: 34.7s\tremaining: 28.3s\n",
            "1444:\tlearn: 100.1823118\ttotal: 34.8s\tremaining: 28.3s\n",
            "1445:\tlearn: 100.1785991\ttotal: 34.8s\tremaining: 28.3s\n",
            "1446:\tlearn: 100.1777205\ttotal: 34.8s\tremaining: 28.2s\n",
            "1447:\tlearn: 100.1697178\ttotal: 34.9s\tremaining: 28.2s\n",
            "1448:\tlearn: 100.1639958\ttotal: 34.9s\tremaining: 28.2s\n",
            "1449:\tlearn: 100.1533631\ttotal: 34.9s\tremaining: 28.2s\n",
            "1450:\tlearn: 100.1399044\ttotal: 34.9s\tremaining: 28.1s\n",
            "1451:\tlearn: 100.1158806\ttotal: 34.9s\tremaining: 28.1s\n",
            "1452:\tlearn: 100.1132915\ttotal: 35s\tremaining: 28.1s\n",
            "1453:\tlearn: 100.0994326\ttotal: 35s\tremaining: 28.1s\n",
            "1454:\tlearn: 100.0878045\ttotal: 35s\tremaining: 28s\n",
            "1455:\tlearn: 100.0847041\ttotal: 35s\tremaining: 28s\n",
            "1456:\tlearn: 100.0745484\ttotal: 35.1s\tremaining: 28s\n",
            "1457:\tlearn: 100.0732389\ttotal: 35.1s\tremaining: 28s\n",
            "1458:\tlearn: 100.0586422\ttotal: 35.1s\tremaining: 27.9s\n",
            "1459:\tlearn: 100.0475537\ttotal: 35.1s\tremaining: 27.9s\n",
            "1460:\tlearn: 100.0353498\ttotal: 35.2s\tremaining: 27.9s\n",
            "1461:\tlearn: 100.0331456\ttotal: 35.2s\tremaining: 27.9s\n",
            "1462:\tlearn: 100.0216420\ttotal: 35.2s\tremaining: 27.9s\n",
            "1463:\tlearn: 100.0111399\ttotal: 35.3s\tremaining: 27.8s\n",
            "1464:\tlearn: 99.9984903\ttotal: 35.3s\tremaining: 27.8s\n",
            "1465:\tlearn: 99.9960582\ttotal: 35.3s\tremaining: 27.8s\n",
            "1466:\tlearn: 99.9692838\ttotal: 35.3s\tremaining: 27.8s\n",
            "1467:\tlearn: 99.9541072\ttotal: 35.4s\tremaining: 27.7s\n",
            "1468:\tlearn: 99.9406088\ttotal: 35.4s\tremaining: 27.7s\n",
            "1469:\tlearn: 99.9372086\ttotal: 35.4s\tremaining: 27.7s\n",
            "1470:\tlearn: 99.9253269\ttotal: 35.4s\tremaining: 27.7s\n",
            "1471:\tlearn: 99.9060477\ttotal: 35.4s\tremaining: 27.6s\n",
            "1472:\tlearn: 99.9018450\ttotal: 35.5s\tremaining: 27.6s\n",
            "1473:\tlearn: 99.8986372\ttotal: 35.5s\tremaining: 27.6s\n",
            "1474:\tlearn: 99.8907226\ttotal: 35.5s\tremaining: 27.6s\n",
            "1475:\tlearn: 99.8833458\ttotal: 35.5s\tremaining: 27.5s\n",
            "1476:\tlearn: 99.8771726\ttotal: 35.6s\tremaining: 27.5s\n",
            "1477:\tlearn: 99.8722670\ttotal: 35.6s\tremaining: 27.5s\n",
            "1478:\tlearn: 99.8425801\ttotal: 35.6s\tremaining: 27.5s\n",
            "1479:\tlearn: 99.8394698\ttotal: 35.6s\tremaining: 27.4s\n",
            "1480:\tlearn: 99.8155093\ttotal: 35.7s\tremaining: 27.4s\n",
            "1481:\tlearn: 99.8112236\ttotal: 35.7s\tremaining: 27.4s\n",
            "1482:\tlearn: 99.8064627\ttotal: 35.7s\tremaining: 27.4s\n",
            "1483:\tlearn: 99.7998257\ttotal: 35.7s\tremaining: 27.4s\n",
            "1484:\tlearn: 99.7928305\ttotal: 35.8s\tremaining: 27.3s\n",
            "1485:\tlearn: 99.7799746\ttotal: 35.8s\tremaining: 27.3s\n",
            "1486:\tlearn: 99.7785723\ttotal: 35.8s\tremaining: 27.3s\n",
            "1487:\tlearn: 99.7729582\ttotal: 35.9s\tremaining: 27.3s\n",
            "1488:\tlearn: 99.7687045\ttotal: 35.9s\tremaining: 27.3s\n",
            "1489:\tlearn: 99.7529301\ttotal: 35.9s\tremaining: 27.2s\n",
            "1490:\tlearn: 99.7366723\ttotal: 35.9s\tremaining: 27.2s\n",
            "1491:\tlearn: 99.7191361\ttotal: 36s\tremaining: 27.2s\n",
            "1492:\tlearn: 99.7142823\ttotal: 36s\tremaining: 27.2s\n",
            "1493:\tlearn: 99.6862121\ttotal: 36s\tremaining: 27.1s\n",
            "1494:\tlearn: 99.6794840\ttotal: 36s\tremaining: 27.1s\n",
            "1495:\tlearn: 99.6741063\ttotal: 36.1s\tremaining: 27.1s\n",
            "1496:\tlearn: 99.6688412\ttotal: 36.1s\tremaining: 27.1s\n",
            "1497:\tlearn: 99.6655960\ttotal: 36.1s\tremaining: 27.1s\n",
            "1498:\tlearn: 99.6510511\ttotal: 36.1s\tremaining: 27s\n",
            "1499:\tlearn: 99.6378661\ttotal: 36.2s\tremaining: 27s\n",
            "1500:\tlearn: 99.6293715\ttotal: 36.2s\tremaining: 27s\n",
            "1501:\tlearn: 99.6052144\ttotal: 36.2s\tremaining: 26.9s\n",
            "1502:\tlearn: 99.5929886\ttotal: 36.2s\tremaining: 26.9s\n",
            "1503:\tlearn: 99.5862222\ttotal: 36.2s\tremaining: 26.9s\n",
            "1504:\tlearn: 99.5723066\ttotal: 36.3s\tremaining: 26.9s\n",
            "1505:\tlearn: 99.5582962\ttotal: 36.3s\tremaining: 26.8s\n",
            "1506:\tlearn: 99.5434960\ttotal: 36.3s\tremaining: 26.8s\n",
            "1507:\tlearn: 99.5319165\ttotal: 36.3s\tremaining: 26.8s\n",
            "1508:\tlearn: 99.5140842\ttotal: 36.4s\tremaining: 26.8s\n",
            "1509:\tlearn: 99.5118826\ttotal: 36.4s\tremaining: 26.8s\n",
            "1510:\tlearn: 99.5024066\ttotal: 36.4s\tremaining: 26.7s\n",
            "1511:\tlearn: 99.4812807\ttotal: 36.4s\tremaining: 26.7s\n",
            "1512:\tlearn: 99.4717267\ttotal: 36.5s\tremaining: 26.7s\n",
            "1513:\tlearn: 99.4647727\ttotal: 36.5s\tremaining: 26.7s\n",
            "1514:\tlearn: 99.4583177\ttotal: 36.5s\tremaining: 26.6s\n",
            "1515:\tlearn: 99.4474503\ttotal: 36.5s\tremaining: 26.6s\n",
            "1516:\tlearn: 99.4322445\ttotal: 36.6s\tremaining: 26.6s\n",
            "1517:\tlearn: 99.4168179\ttotal: 36.6s\tremaining: 26.6s\n",
            "1518:\tlearn: 99.4072620\ttotal: 36.6s\tremaining: 26.5s\n",
            "1519:\tlearn: 99.4065547\ttotal: 36.6s\tremaining: 26.5s\n",
            "1520:\tlearn: 99.4024070\ttotal: 36.7s\tremaining: 26.5s\n",
            "1521:\tlearn: 99.3929147\ttotal: 36.7s\tremaining: 26.5s\n",
            "1522:\tlearn: 99.3877047\ttotal: 36.7s\tremaining: 26.5s\n",
            "1523:\tlearn: 99.3877047\ttotal: 36.7s\tremaining: 26.4s\n",
            "1524:\tlearn: 99.3755600\ttotal: 36.8s\tremaining: 26.4s\n",
            "1525:\tlearn: 99.3682063\ttotal: 36.8s\tremaining: 26.4s\n",
            "1526:\tlearn: 99.3598541\ttotal: 36.8s\tremaining: 26.3s\n",
            "1527:\tlearn: 99.3566219\ttotal: 36.8s\tremaining: 26.3s\n",
            "1528:\tlearn: 99.3288447\ttotal: 36.8s\tremaining: 26.3s\n",
            "1529:\tlearn: 99.3203071\ttotal: 36.9s\tremaining: 26.3s\n",
            "1530:\tlearn: 99.3160531\ttotal: 36.9s\tremaining: 26.2s\n",
            "1531:\tlearn: 99.3112121\ttotal: 36.9s\tremaining: 26.2s\n",
            "1532:\tlearn: 99.2977520\ttotal: 36.9s\tremaining: 26.2s\n",
            "1533:\tlearn: 99.2849965\ttotal: 37s\tremaining: 26.2s\n",
            "1534:\tlearn: 99.2698710\ttotal: 37s\tremaining: 26.1s\n",
            "1535:\tlearn: 99.2652000\ttotal: 37s\tremaining: 26.1s\n",
            "1536:\tlearn: 99.2538392\ttotal: 37s\tremaining: 26.1s\n",
            "1537:\tlearn: 99.2417987\ttotal: 37s\tremaining: 26.1s\n",
            "1538:\tlearn: 99.2298856\ttotal: 37.1s\tremaining: 26s\n",
            "1539:\tlearn: 99.2240022\ttotal: 37.1s\tremaining: 26s\n",
            "1540:\tlearn: 99.2223667\ttotal: 37.1s\tremaining: 26s\n",
            "1541:\tlearn: 99.2097246\ttotal: 37.1s\tremaining: 26s\n",
            "1542:\tlearn: 99.2055180\ttotal: 37.1s\tremaining: 25.9s\n",
            "1543:\tlearn: 99.1994707\ttotal: 37.2s\tremaining: 25.9s\n",
            "1544:\tlearn: 99.1900573\ttotal: 37.2s\tremaining: 25.9s\n",
            "1545:\tlearn: 99.1846326\ttotal: 37.2s\tremaining: 25.9s\n",
            "1546:\tlearn: 99.1802417\ttotal: 37.3s\tremaining: 25.8s\n",
            "1547:\tlearn: 99.1639328\ttotal: 37.3s\tremaining: 25.8s\n",
            "1548:\tlearn: 99.1497827\ttotal: 37.3s\tremaining: 25.8s\n",
            "1549:\tlearn: 99.1322160\ttotal: 37.3s\tremaining: 25.8s\n",
            "1550:\tlearn: 99.1295495\ttotal: 37.4s\tremaining: 25.8s\n",
            "1551:\tlearn: 99.1251535\ttotal: 37.4s\tremaining: 25.7s\n",
            "1552:\tlearn: 99.1125419\ttotal: 37.4s\tremaining: 25.7s\n",
            "1553:\tlearn: 99.1020471\ttotal: 37.4s\tremaining: 25.7s\n",
            "1554:\tlearn: 99.0876519\ttotal: 37.5s\tremaining: 25.7s\n",
            "1555:\tlearn: 99.0817229\ttotal: 37.5s\tremaining: 25.6s\n",
            "1556:\tlearn: 99.0793890\ttotal: 37.5s\tremaining: 25.6s\n",
            "1557:\tlearn: 99.0714079\ttotal: 37.5s\tremaining: 25.6s\n",
            "1558:\tlearn: 99.0656892\ttotal: 37.6s\tremaining: 25.6s\n",
            "1559:\tlearn: 99.0581770\ttotal: 37.6s\tremaining: 25.6s\n",
            "1560:\tlearn: 99.0428531\ttotal: 37.6s\tremaining: 25.5s\n",
            "1561:\tlearn: 99.0368009\ttotal: 37.6s\tremaining: 25.5s\n",
            "1562:\tlearn: 99.0317541\ttotal: 37.7s\tremaining: 25.5s\n",
            "1563:\tlearn: 99.0183977\ttotal: 37.7s\tremaining: 25.4s\n",
            "1564:\tlearn: 99.0110841\ttotal: 37.7s\tremaining: 25.4s\n",
            "1565:\tlearn: 99.0036612\ttotal: 37.7s\tremaining: 25.4s\n",
            "1566:\tlearn: 98.9873717\ttotal: 37.7s\tremaining: 25.4s\n",
            "1567:\tlearn: 98.9647684\ttotal: 37.8s\tremaining: 25.3s\n",
            "1568:\tlearn: 98.9597482\ttotal: 37.8s\tremaining: 25.3s\n",
            "1569:\tlearn: 98.9423952\ttotal: 37.8s\tremaining: 25.3s\n",
            "1570:\tlearn: 98.9363121\ttotal: 37.8s\tremaining: 25.3s\n",
            "1571:\tlearn: 98.9311689\ttotal: 37.9s\tremaining: 25.2s\n",
            "1572:\tlearn: 98.9138974\ttotal: 37.9s\tremaining: 25.2s\n",
            "1573:\tlearn: 98.8984334\ttotal: 37.9s\tremaining: 25.2s\n",
            "1574:\tlearn: 98.8803220\ttotal: 37.9s\tremaining: 25.2s\n",
            "1575:\tlearn: 98.8713883\ttotal: 37.9s\tremaining: 25.1s\n",
            "1576:\tlearn: 98.8706957\ttotal: 38s\tremaining: 25.1s\n",
            "1577:\tlearn: 98.8647677\ttotal: 38.1s\tremaining: 25.1s\n",
            "1578:\tlearn: 98.8500879\ttotal: 38.1s\tremaining: 25.1s\n",
            "1579:\tlearn: 98.8461196\ttotal: 38.1s\tremaining: 25.1s\n",
            "1580:\tlearn: 98.8424920\ttotal: 38.1s\tremaining: 25.1s\n",
            "1581:\tlearn: 98.8253062\ttotal: 38.2s\tremaining: 25s\n",
            "1582:\tlearn: 98.8122092\ttotal: 38.2s\tremaining: 25s\n",
            "1583:\tlearn: 98.7968553\ttotal: 38.2s\tremaining: 25s\n",
            "1584:\tlearn: 98.7937208\ttotal: 38.2s\tremaining: 25s\n",
            "1585:\tlearn: 98.7882850\ttotal: 38.3s\tremaining: 24.9s\n",
            "1586:\tlearn: 98.7841282\ttotal: 38.3s\tremaining: 24.9s\n",
            "1587:\tlearn: 98.7676938\ttotal: 38.3s\tremaining: 24.9s\n",
            "1588:\tlearn: 98.7600899\ttotal: 38.3s\tremaining: 24.9s\n",
            "1589:\tlearn: 98.7519977\ttotal: 38.4s\tremaining: 24.9s\n",
            "1590:\tlearn: 98.7493513\ttotal: 38.4s\tremaining: 24.8s\n",
            "1591:\tlearn: 98.7387263\ttotal: 38.4s\tremaining: 24.8s\n",
            "1592:\tlearn: 98.7236265\ttotal: 38.4s\tremaining: 24.8s\n",
            "1593:\tlearn: 98.6959391\ttotal: 38.5s\tremaining: 24.8s\n",
            "1594:\tlearn: 98.6883711\ttotal: 38.5s\tremaining: 24.7s\n",
            "1595:\tlearn: 98.6857929\ttotal: 38.5s\tremaining: 24.7s\n",
            "1596:\tlearn: 98.6785710\ttotal: 38.5s\tremaining: 24.7s\n",
            "1597:\tlearn: 98.6643083\ttotal: 38.5s\tremaining: 24.6s\n",
            "1598:\tlearn: 98.6553877\ttotal: 38.6s\tremaining: 24.6s\n",
            "1599:\tlearn: 98.6417162\ttotal: 38.6s\tremaining: 24.6s\n",
            "1600:\tlearn: 98.6302271\ttotal: 38.6s\tremaining: 24.6s\n",
            "1601:\tlearn: 98.6209152\ttotal: 38.6s\tremaining: 24.6s\n",
            "1602:\tlearn: 98.6116350\ttotal: 38.7s\tremaining: 24.5s\n",
            "1603:\tlearn: 98.6075023\ttotal: 38.7s\tremaining: 24.5s\n",
            "1604:\tlearn: 98.5994610\ttotal: 38.7s\tremaining: 24.5s\n",
            "1605:\tlearn: 98.5871130\ttotal: 38.7s\tremaining: 24.5s\n",
            "1606:\tlearn: 98.5784315\ttotal: 38.8s\tremaining: 24.4s\n",
            "1607:\tlearn: 98.5720145\ttotal: 38.8s\tremaining: 24.4s\n",
            "1608:\tlearn: 98.5506620\ttotal: 38.8s\tremaining: 24.4s\n",
            "1609:\tlearn: 98.5397102\ttotal: 38.8s\tremaining: 24.3s\n",
            "1610:\tlearn: 98.5321904\ttotal: 38.8s\tremaining: 24.3s\n",
            "1611:\tlearn: 98.5283232\ttotal: 38.9s\tremaining: 24.3s\n",
            "1612:\tlearn: 98.5197669\ttotal: 38.9s\tremaining: 24.3s\n",
            "1613:\tlearn: 98.5048071\ttotal: 38.9s\tremaining: 24.2s\n",
            "1614:\tlearn: 98.4974375\ttotal: 38.9s\tremaining: 24.2s\n",
            "1615:\tlearn: 98.4824727\ttotal: 39s\tremaining: 24.2s\n",
            "1616:\tlearn: 98.4681293\ttotal: 39s\tremaining: 24.2s\n",
            "1617:\tlearn: 98.4570304\ttotal: 39s\tremaining: 24.1s\n",
            "1618:\tlearn: 98.4492252\ttotal: 39s\tremaining: 24.1s\n",
            "1619:\tlearn: 98.4422868\ttotal: 39s\tremaining: 24.1s\n",
            "1620:\tlearn: 98.4303083\ttotal: 39.1s\tremaining: 24.1s\n",
            "1621:\tlearn: 98.4216189\ttotal: 39.1s\tremaining: 24.1s\n",
            "1622:\tlearn: 98.4162313\ttotal: 39.1s\tremaining: 24s\n",
            "1623:\tlearn: 98.4083780\ttotal: 39.2s\tremaining: 24s\n",
            "1624:\tlearn: 98.4050302\ttotal: 39.2s\tremaining: 24s\n",
            "1625:\tlearn: 98.4002663\ttotal: 39.2s\tremaining: 24s\n",
            "1626:\tlearn: 98.3978675\ttotal: 39.2s\tremaining: 23.9s\n",
            "1627:\tlearn: 98.3784307\ttotal: 39.3s\tremaining: 23.9s\n",
            "1628:\tlearn: 98.3650296\ttotal: 39.3s\tremaining: 23.9s\n",
            "1629:\tlearn: 98.3466283\ttotal: 39.3s\tremaining: 23.9s\n",
            "1630:\tlearn: 98.3389017\ttotal: 39.3s\tremaining: 23.8s\n",
            "1631:\tlearn: 98.3293820\ttotal: 39.3s\tremaining: 23.8s\n",
            "1632:\tlearn: 98.3215551\ttotal: 39.4s\tremaining: 23.8s\n",
            "1633:\tlearn: 98.3070625\ttotal: 39.4s\tremaining: 23.8s\n",
            "1634:\tlearn: 98.3049394\ttotal: 39.4s\tremaining: 23.7s\n",
            "1635:\tlearn: 98.2939872\ttotal: 39.4s\tremaining: 23.7s\n",
            "1636:\tlearn: 98.2868348\ttotal: 39.5s\tremaining: 23.7s\n",
            "1637:\tlearn: 98.2841898\ttotal: 39.5s\tremaining: 23.7s\n",
            "1638:\tlearn: 98.2770499\ttotal: 39.5s\tremaining: 23.6s\n",
            "1639:\tlearn: 98.2620708\ttotal: 39.5s\tremaining: 23.6s\n",
            "1640:\tlearn: 98.2479191\ttotal: 39.6s\tremaining: 23.6s\n",
            "1641:\tlearn: 98.2353390\ttotal: 39.6s\tremaining: 23.6s\n",
            "1642:\tlearn: 98.2202250\ttotal: 39.6s\tremaining: 23.5s\n",
            "1643:\tlearn: 98.2096361\ttotal: 39.6s\tremaining: 23.5s\n",
            "1644:\tlearn: 98.2029871\ttotal: 39.6s\tremaining: 23.5s\n",
            "1645:\tlearn: 98.1951704\ttotal: 39.7s\tremaining: 23.5s\n",
            "1646:\tlearn: 98.1924629\ttotal: 39.7s\tremaining: 23.5s\n",
            "1647:\tlearn: 98.1848500\ttotal: 39.7s\tremaining: 23.4s\n",
            "1648:\tlearn: 98.1771181\ttotal: 39.8s\tremaining: 23.4s\n",
            "1649:\tlearn: 98.1656588\ttotal: 39.8s\tremaining: 23.4s\n",
            "1650:\tlearn: 98.1627522\ttotal: 39.8s\tremaining: 23.4s\n",
            "1651:\tlearn: 98.1553131\ttotal: 39.8s\tremaining: 23.3s\n",
            "1652:\tlearn: 98.1486881\ttotal: 39.9s\tremaining: 23.3s\n",
            "1653:\tlearn: 98.1413892\ttotal: 39.9s\tremaining: 23.3s\n",
            "1654:\tlearn: 98.1409831\ttotal: 39.9s\tremaining: 23.3s\n",
            "1655:\tlearn: 98.1331760\ttotal: 39.9s\tremaining: 23.2s\n",
            "1656:\tlearn: 98.1273274\ttotal: 40s\tremaining: 23.2s\n",
            "1657:\tlearn: 98.1199908\ttotal: 40s\tremaining: 23.2s\n",
            "1658:\tlearn: 98.1052603\ttotal: 40s\tremaining: 23.2s\n",
            "1659:\tlearn: 98.0890070\ttotal: 40s\tremaining: 23.1s\n",
            "1660:\tlearn: 98.0870335\ttotal: 40s\tremaining: 23.1s\n",
            "1661:\tlearn: 98.0737498\ttotal: 40.1s\tremaining: 23.1s\n",
            "1662:\tlearn: 98.0716531\ttotal: 40.1s\tremaining: 23.1s\n",
            "1663:\tlearn: 98.0472634\ttotal: 40.1s\tremaining: 23.1s\n",
            "1664:\tlearn: 98.0409321\ttotal: 40.1s\tremaining: 23s\n",
            "1665:\tlearn: 98.0304500\ttotal: 40.2s\tremaining: 23s\n",
            "1666:\tlearn: 98.0236971\ttotal: 40.2s\tremaining: 23s\n",
            "1667:\tlearn: 98.0176065\ttotal: 40.2s\tremaining: 22.9s\n",
            "1668:\tlearn: 98.0029182\ttotal: 40.2s\tremaining: 22.9s\n",
            "1669:\tlearn: 97.9957631\ttotal: 40.3s\tremaining: 22.9s\n",
            "1670:\tlearn: 97.9861132\ttotal: 40.3s\tremaining: 22.9s\n",
            "1671:\tlearn: 97.9779832\ttotal: 40.3s\tremaining: 22.9s\n",
            "1672:\tlearn: 97.9684829\ttotal: 40.3s\tremaining: 22.8s\n",
            "1673:\tlearn: 97.9626618\ttotal: 40.4s\tremaining: 22.8s\n",
            "1674:\tlearn: 97.9554146\ttotal: 40.4s\tremaining: 22.8s\n",
            "1675:\tlearn: 97.9443478\ttotal: 40.4s\tremaining: 22.8s\n",
            "1676:\tlearn: 97.9418146\ttotal: 40.4s\tremaining: 22.7s\n",
            "1677:\tlearn: 97.9371909\ttotal: 40.5s\tremaining: 22.7s\n",
            "1678:\tlearn: 97.9300914\ttotal: 40.5s\tremaining: 22.7s\n",
            "1679:\tlearn: 97.9194281\ttotal: 40.5s\tremaining: 22.7s\n",
            "1680:\tlearn: 97.9105656\ttotal: 40.6s\tremaining: 22.7s\n",
            "1681:\tlearn: 97.8917680\ttotal: 40.6s\tremaining: 22.6s\n",
            "1682:\tlearn: 97.8861840\ttotal: 40.6s\tremaining: 22.6s\n",
            "1683:\tlearn: 97.8719286\ttotal: 40.6s\tremaining: 22.6s\n",
            "1684:\tlearn: 97.8595804\ttotal: 40.7s\tremaining: 22.6s\n",
            "1685:\tlearn: 97.8566409\ttotal: 40.7s\tremaining: 22.5s\n",
            "1686:\tlearn: 97.8542055\ttotal: 40.7s\tremaining: 22.5s\n",
            "1687:\tlearn: 97.8489039\ttotal: 40.7s\tremaining: 22.5s\n",
            "1688:\tlearn: 97.8373109\ttotal: 40.8s\tremaining: 22.5s\n",
            "1689:\tlearn: 97.8291826\ttotal: 40.8s\tremaining: 22.4s\n",
            "1690:\tlearn: 97.8165698\ttotal: 40.8s\tremaining: 22.4s\n",
            "1691:\tlearn: 97.8096927\ttotal: 40.8s\tremaining: 22.4s\n",
            "1692:\tlearn: 97.7871403\ttotal: 40.9s\tremaining: 22.4s\n",
            "1693:\tlearn: 97.7729638\ttotal: 40.9s\tremaining: 22.3s\n",
            "1694:\tlearn: 97.7614010\ttotal: 40.9s\tremaining: 22.3s\n",
            "1695:\tlearn: 97.7496868\ttotal: 40.9s\tremaining: 22.3s\n",
            "1696:\tlearn: 97.7368720\ttotal: 40.9s\tremaining: 22.3s\n",
            "1697:\tlearn: 97.7271078\ttotal: 41s\tremaining: 22.2s\n",
            "1698:\tlearn: 97.7192262\ttotal: 41s\tremaining: 22.2s\n",
            "1699:\tlearn: 97.7124595\ttotal: 41s\tremaining: 22.2s\n",
            "1700:\tlearn: 97.6973540\ttotal: 41.1s\tremaining: 22.2s\n",
            "1701:\tlearn: 97.6869234\ttotal: 41.1s\tremaining: 22.2s\n",
            "1702:\tlearn: 97.6779291\ttotal: 41.1s\tremaining: 22.1s\n",
            "1703:\tlearn: 97.6770515\ttotal: 41.1s\tremaining: 22.1s\n",
            "1704:\tlearn: 97.6616504\ttotal: 41.1s\tremaining: 22.1s\n",
            "1705:\tlearn: 97.6522931\ttotal: 41.2s\tremaining: 22.1s\n",
            "1706:\tlearn: 97.6457215\ttotal: 41.2s\tremaining: 22s\n",
            "1707:\tlearn: 97.6331347\ttotal: 41.2s\tremaining: 22s\n",
            "1708:\tlearn: 97.6263818\ttotal: 41.2s\tremaining: 22s\n",
            "1709:\tlearn: 97.6234117\ttotal: 41.3s\tremaining: 22s\n",
            "1710:\tlearn: 97.6193346\ttotal: 41.3s\tremaining: 21.9s\n",
            "1711:\tlearn: 97.6038129\ttotal: 41.3s\tremaining: 21.9s\n",
            "1712:\tlearn: 97.5924869\ttotal: 41.3s\tremaining: 21.9s\n",
            "1713:\tlearn: 97.5812729\ttotal: 41.4s\tremaining: 21.9s\n",
            "1714:\tlearn: 97.5753892\ttotal: 41.4s\tremaining: 21.8s\n",
            "1715:\tlearn: 97.5680912\ttotal: 41.4s\tremaining: 21.8s\n",
            "1716:\tlearn: 97.5558501\ttotal: 41.4s\tremaining: 21.8s\n",
            "1717:\tlearn: 97.5493301\ttotal: 41.5s\tremaining: 21.8s\n",
            "1718:\tlearn: 97.5380966\ttotal: 41.5s\tremaining: 21.7s\n",
            "1719:\tlearn: 97.5326994\ttotal: 41.5s\tremaining: 21.7s\n",
            "1720:\tlearn: 97.5151871\ttotal: 41.5s\tremaining: 21.7s\n",
            "1721:\tlearn: 97.5131301\ttotal: 41.5s\tremaining: 21.7s\n",
            "1722:\tlearn: 97.5043214\ttotal: 41.6s\tremaining: 21.6s\n",
            "1723:\tlearn: 97.5023062\ttotal: 41.6s\tremaining: 21.6s\n",
            "1724:\tlearn: 97.4951716\ttotal: 41.6s\tremaining: 21.6s\n",
            "1725:\tlearn: 97.4894772\ttotal: 41.6s\tremaining: 21.6s\n",
            "1726:\tlearn: 97.4814534\ttotal: 41.6s\tremaining: 21.5s\n",
            "1727:\tlearn: 97.4733135\ttotal: 41.7s\tremaining: 21.5s\n",
            "1728:\tlearn: 97.4656361\ttotal: 41.7s\tremaining: 21.5s\n",
            "1729:\tlearn: 97.4523548\ttotal: 41.7s\tremaining: 21.5s\n",
            "1730:\tlearn: 97.4458582\ttotal: 41.7s\tremaining: 21.4s\n",
            "1731:\tlearn: 97.4428764\ttotal: 41.8s\tremaining: 21.4s\n",
            "1732:\tlearn: 97.4344323\ttotal: 41.8s\tremaining: 21.4s\n",
            "1733:\tlearn: 97.4293718\ttotal: 41.8s\tremaining: 21.4s\n",
            "1734:\tlearn: 97.4155404\ttotal: 41.8s\tremaining: 21.3s\n",
            "1735:\tlearn: 97.4021308\ttotal: 41.9s\tremaining: 21.3s\n",
            "1736:\tlearn: 97.3974089\ttotal: 41.9s\tremaining: 21.3s\n",
            "1737:\tlearn: 97.3947100\ttotal: 41.9s\tremaining: 21.3s\n",
            "1738:\tlearn: 97.3904073\ttotal: 42s\tremaining: 21.3s\n",
            "1739:\tlearn: 97.3787280\ttotal: 42s\tremaining: 21.2s\n",
            "1740:\tlearn: 97.3712678\ttotal: 42s\tremaining: 21.2s\n",
            "1741:\tlearn: 97.3665007\ttotal: 42s\tremaining: 21.2s\n",
            "1742:\tlearn: 97.3630706\ttotal: 42.1s\tremaining: 21.2s\n",
            "1743:\tlearn: 97.3486207\ttotal: 42.1s\tremaining: 21.1s\n",
            "1744:\tlearn: 97.3382818\ttotal: 42.1s\tremaining: 21.1s\n",
            "1745:\tlearn: 97.3302076\ttotal: 42.1s\tremaining: 21.1s\n",
            "1746:\tlearn: 97.3268506\ttotal: 42.2s\tremaining: 21.1s\n",
            "1747:\tlearn: 97.3144240\ttotal: 42.2s\tremaining: 21s\n",
            "1748:\tlearn: 97.3055673\ttotal: 42.2s\tremaining: 21s\n",
            "1749:\tlearn: 97.2950735\ttotal: 42.2s\tremaining: 21s\n",
            "1750:\tlearn: 97.2812604\ttotal: 42.3s\tremaining: 21s\n",
            "1751:\tlearn: 97.2681865\ttotal: 42.3s\tremaining: 20.9s\n",
            "1752:\tlearn: 97.2596786\ttotal: 42.3s\tremaining: 20.9s\n",
            "1753:\tlearn: 97.2486568\ttotal: 42.3s\tremaining: 20.9s\n",
            "1754:\tlearn: 97.2416536\ttotal: 42.4s\tremaining: 20.9s\n",
            "1755:\tlearn: 97.2416143\ttotal: 42.4s\tremaining: 20.8s\n",
            "1756:\tlearn: 97.2311996\ttotal: 42.4s\tremaining: 20.8s\n",
            "1757:\tlearn: 97.2127204\ttotal: 42.4s\tremaining: 20.8s\n",
            "1758:\tlearn: 97.1895041\ttotal: 42.4s\tremaining: 20.8s\n",
            "1759:\tlearn: 97.1762092\ttotal: 42.5s\tremaining: 20.7s\n",
            "1760:\tlearn: 97.1532574\ttotal: 42.5s\tremaining: 20.7s\n",
            "1761:\tlearn: 97.1475199\ttotal: 42.5s\tremaining: 20.7s\n",
            "1762:\tlearn: 97.1338652\ttotal: 42.5s\tremaining: 20.7s\n",
            "1763:\tlearn: 97.1221775\ttotal: 42.5s\tremaining: 20.6s\n",
            "1764:\tlearn: 97.1191106\ttotal: 42.6s\tremaining: 20.6s\n",
            "1765:\tlearn: 97.1114553\ttotal: 42.6s\tremaining: 20.6s\n",
            "1766:\tlearn: 97.1007328\ttotal: 42.6s\tremaining: 20.6s\n",
            "1767:\tlearn: 97.0962345\ttotal: 42.6s\tremaining: 20.6s\n",
            "1768:\tlearn: 97.0898360\ttotal: 42.7s\tremaining: 20.5s\n",
            "1769:\tlearn: 97.0813528\ttotal: 42.7s\tremaining: 20.5s\n",
            "1770:\tlearn: 97.0722131\ttotal: 42.7s\tremaining: 20.5s\n",
            "1771:\tlearn: 97.0711581\ttotal: 42.7s\tremaining: 20.5s\n",
            "1772:\tlearn: 97.0645789\ttotal: 42.8s\tremaining: 20.4s\n",
            "1773:\tlearn: 97.0490998\ttotal: 42.8s\tremaining: 20.4s\n",
            "1774:\tlearn: 97.0377803\ttotal: 42.8s\tremaining: 20.4s\n",
            "1775:\tlearn: 97.0309641\ttotal: 42.8s\tremaining: 20.4s\n",
            "1776:\tlearn: 97.0120275\ttotal: 42.9s\tremaining: 20.3s\n",
            "1777:\tlearn: 96.9973574\ttotal: 42.9s\tremaining: 20.3s\n",
            "1778:\tlearn: 96.9971150\ttotal: 42.9s\tremaining: 20.3s\n",
            "1779:\tlearn: 96.9801561\ttotal: 42.9s\tremaining: 20.3s\n",
            "1780:\tlearn: 96.9662034\ttotal: 42.9s\tremaining: 20.2s\n",
            "1781:\tlearn: 96.9513821\ttotal: 43s\tremaining: 20.2s\n",
            "1782:\tlearn: 96.9400559\ttotal: 43s\tremaining: 20.2s\n",
            "1783:\tlearn: 96.9369411\ttotal: 43s\tremaining: 20.2s\n",
            "1784:\tlearn: 96.9300019\ttotal: 43.1s\tremaining: 20.1s\n",
            "1785:\tlearn: 96.9293869\ttotal: 43.1s\tremaining: 20.1s\n",
            "1786:\tlearn: 96.9241916\ttotal: 43.1s\tremaining: 20.1s\n",
            "1787:\tlearn: 96.9186849\ttotal: 43.1s\tremaining: 20.1s\n",
            "1788:\tlearn: 96.9168778\ttotal: 43.2s\tremaining: 20.1s\n",
            "1789:\tlearn: 96.9168778\ttotal: 43.2s\tremaining: 20s\n",
            "1790:\tlearn: 96.9070373\ttotal: 43.2s\tremaining: 20s\n",
            "1791:\tlearn: 96.8985813\ttotal: 43.2s\tremaining: 20s\n",
            "1792:\tlearn: 96.8810594\ttotal: 43.2s\tremaining: 19.9s\n",
            "1793:\tlearn: 96.8754192\ttotal: 43.2s\tremaining: 19.9s\n",
            "1794:\tlearn: 96.8694189\ttotal: 43.3s\tremaining: 19.9s\n",
            "1795:\tlearn: 96.8628100\ttotal: 43.3s\tremaining: 19.9s\n",
            "1796:\tlearn: 96.8573763\ttotal: 43.3s\tremaining: 19.8s\n",
            "1797:\tlearn: 96.8467219\ttotal: 43.3s\tremaining: 19.8s\n",
            "1798:\tlearn: 96.8436118\ttotal: 43.3s\tremaining: 19.8s\n",
            "1799:\tlearn: 96.8260836\ttotal: 43.4s\tremaining: 19.8s\n",
            "1800:\tlearn: 96.8231499\ttotal: 43.4s\tremaining: 19.7s\n",
            "1801:\tlearn: 96.8171775\ttotal: 43.4s\tremaining: 19.7s\n",
            "1802:\tlearn: 96.8168654\ttotal: 43.4s\tremaining: 19.7s\n",
            "1803:\tlearn: 96.8119381\ttotal: 43.5s\tremaining: 19.7s\n",
            "1804:\tlearn: 96.7788229\ttotal: 43.5s\tremaining: 19.6s\n",
            "1805:\tlearn: 96.7633369\ttotal: 43.5s\tremaining: 19.6s\n",
            "1806:\tlearn: 96.7555168\ttotal: 43.5s\tremaining: 19.6s\n",
            "1807:\tlearn: 96.7473422\ttotal: 43.5s\tremaining: 19.6s\n",
            "1808:\tlearn: 96.7270000\ttotal: 43.6s\tremaining: 19.5s\n",
            "1809:\tlearn: 96.7180992\ttotal: 43.6s\tremaining: 19.5s\n",
            "1810:\tlearn: 96.7075137\ttotal: 43.6s\tremaining: 19.5s\n",
            "1811:\tlearn: 96.7042591\ttotal: 43.6s\tremaining: 19.5s\n",
            "1812:\tlearn: 96.6904416\ttotal: 43.7s\tremaining: 19.4s\n",
            "1813:\tlearn: 96.6868324\ttotal: 43.7s\tremaining: 19.4s\n",
            "1814:\tlearn: 96.6762000\ttotal: 43.7s\tremaining: 19.4s\n",
            "1815:\tlearn: 96.6669823\ttotal: 43.7s\tremaining: 19.4s\n",
            "1816:\tlearn: 96.6562852\ttotal: 43.8s\tremaining: 19.3s\n",
            "1817:\tlearn: 96.6468396\ttotal: 43.8s\tremaining: 19.3s\n",
            "1818:\tlearn: 96.6355941\ttotal: 43.8s\tremaining: 19.3s\n",
            "1819:\tlearn: 96.6200978\ttotal: 43.8s\tremaining: 19.3s\n",
            "1820:\tlearn: 96.6029779\ttotal: 43.8s\tremaining: 19.2s\n",
            "1821:\tlearn: 96.5951793\ttotal: 43.9s\tremaining: 19.2s\n",
            "1822:\tlearn: 96.5891415\ttotal: 43.9s\tremaining: 19.2s\n",
            "1823:\tlearn: 96.5808908\ttotal: 43.9s\tremaining: 19.2s\n",
            "1824:\tlearn: 96.5679478\ttotal: 43.9s\tremaining: 19.1s\n",
            "1825:\tlearn: 96.5633523\ttotal: 44s\tremaining: 19.1s\n",
            "1826:\tlearn: 96.5567733\ttotal: 44s\tremaining: 19.1s\n",
            "1827:\tlearn: 96.5509261\ttotal: 44s\tremaining: 19.1s\n",
            "1828:\tlearn: 96.5416967\ttotal: 44s\tremaining: 19s\n",
            "1829:\tlearn: 96.5322433\ttotal: 44.1s\tremaining: 19s\n",
            "1830:\tlearn: 96.5225983\ttotal: 44.1s\tremaining: 19s\n",
            "1831:\tlearn: 96.5127582\ttotal: 44.1s\tremaining: 19s\n",
            "1832:\tlearn: 96.4976610\ttotal: 44.1s\tremaining: 18.9s\n",
            "1833:\tlearn: 96.4935159\ttotal: 44.1s\tremaining: 18.9s\n",
            "1834:\tlearn: 96.4807863\ttotal: 44.2s\tremaining: 18.9s\n",
            "1835:\tlearn: 96.4761407\ttotal: 44.2s\tremaining: 18.9s\n",
            "1836:\tlearn: 96.4619328\ttotal: 44.2s\tremaining: 18.9s\n",
            "1837:\tlearn: 96.4597830\ttotal: 44.3s\tremaining: 18.8s\n",
            "1838:\tlearn: 96.4574737\ttotal: 44.3s\tremaining: 18.8s\n",
            "1839:\tlearn: 96.4429115\ttotal: 44.3s\tremaining: 18.8s\n",
            "1840:\tlearn: 96.4375737\ttotal: 44.3s\tremaining: 18.8s\n",
            "1841:\tlearn: 96.4320518\ttotal: 44.4s\tremaining: 18.7s\n",
            "1842:\tlearn: 96.4260448\ttotal: 44.4s\tremaining: 18.7s\n",
            "1843:\tlearn: 96.4182787\ttotal: 44.4s\tremaining: 18.7s\n",
            "1844:\tlearn: 96.4139853\ttotal: 44.4s\tremaining: 18.7s\n",
            "1845:\tlearn: 96.4062250\ttotal: 44.5s\tremaining: 18.6s\n",
            "1846:\tlearn: 96.3979795\ttotal: 44.5s\tremaining: 18.6s\n",
            "1847:\tlearn: 96.3834148\ttotal: 44.5s\tremaining: 18.6s\n",
            "1848:\tlearn: 96.3706818\ttotal: 44.5s\tremaining: 18.6s\n",
            "1849:\tlearn: 96.3236304\ttotal: 44.6s\tremaining: 18.5s\n",
            "1850:\tlearn: 96.3093567\ttotal: 44.6s\tremaining: 18.5s\n",
            "1851:\tlearn: 96.3012088\ttotal: 44.6s\tremaining: 18.5s\n",
            "1852:\tlearn: 96.2904884\ttotal: 44.6s\tremaining: 18.5s\n",
            "1853:\tlearn: 96.2827323\ttotal: 44.6s\tremaining: 18.4s\n",
            "1854:\tlearn: 96.2701623\ttotal: 44.7s\tremaining: 18.4s\n",
            "1855:\tlearn: 96.2567379\ttotal: 44.7s\tremaining: 18.4s\n",
            "1856:\tlearn: 96.2400577\ttotal: 44.7s\tremaining: 18.4s\n",
            "1857:\tlearn: 96.2250836\ttotal: 44.7s\tremaining: 18.4s\n",
            "1858:\tlearn: 96.2191535\ttotal: 44.8s\tremaining: 18.3s\n",
            "1859:\tlearn: 96.2005004\ttotal: 44.8s\tremaining: 18.3s\n",
            "1860:\tlearn: 96.1953628\ttotal: 44.8s\tremaining: 18.3s\n",
            "1861:\tlearn: 96.1858085\ttotal: 44.8s\tremaining: 18.2s\n",
            "1862:\tlearn: 96.1830850\ttotal: 44.9s\tremaining: 18.2s\n",
            "1863:\tlearn: 96.1737344\ttotal: 44.9s\tremaining: 18.2s\n",
            "1864:\tlearn: 96.1569847\ttotal: 44.9s\tremaining: 18.2s\n",
            "1865:\tlearn: 96.1515469\ttotal: 44.9s\tremaining: 18.2s\n",
            "1866:\tlearn: 96.1465432\ttotal: 45s\tremaining: 18.1s\n",
            "1867:\tlearn: 96.1344825\ttotal: 45s\tremaining: 18.1s\n",
            "1868:\tlearn: 96.1244429\ttotal: 45s\tremaining: 18.1s\n",
            "1869:\tlearn: 96.1105260\ttotal: 45s\tremaining: 18.1s\n",
            "1870:\tlearn: 96.0956075\ttotal: 45s\tremaining: 18s\n",
            "1871:\tlearn: 96.0879603\ttotal: 45.1s\tremaining: 18s\n",
            "1872:\tlearn: 96.0826959\ttotal: 45.1s\tremaining: 18s\n",
            "1873:\tlearn: 96.0736544\ttotal: 45.1s\tremaining: 18s\n",
            "1874:\tlearn: 96.0676254\ttotal: 45.1s\tremaining: 17.9s\n",
            "1875:\tlearn: 96.0568948\ttotal: 45.1s\tremaining: 17.9s\n",
            "1876:\tlearn: 96.0544372\ttotal: 45.2s\tremaining: 17.9s\n",
            "1877:\tlearn: 96.0424667\ttotal: 45.2s\tremaining: 17.9s\n",
            "1878:\tlearn: 96.0331762\ttotal: 45.2s\tremaining: 17.8s\n",
            "1879:\tlearn: 96.0219844\ttotal: 45.2s\tremaining: 17.8s\n",
            "1880:\tlearn: 96.0198812\ttotal: 45.3s\tremaining: 17.8s\n",
            "1881:\tlearn: 95.9861869\ttotal: 45.3s\tremaining: 17.8s\n",
            "1882:\tlearn: 95.9772609\ttotal: 45.3s\tremaining: 17.7s\n",
            "1883:\tlearn: 95.9702470\ttotal: 45.3s\tremaining: 17.7s\n",
            "1884:\tlearn: 95.9605064\ttotal: 45.4s\tremaining: 17.7s\n",
            "1885:\tlearn: 95.9573661\ttotal: 45.4s\tremaining: 17.7s\n",
            "1886:\tlearn: 95.9523557\ttotal: 45.4s\tremaining: 17.6s\n",
            "1887:\tlearn: 95.9436919\ttotal: 45.4s\tremaining: 17.6s\n",
            "1888:\tlearn: 95.9314400\ttotal: 45.5s\tremaining: 17.6s\n",
            "1889:\tlearn: 95.9222355\ttotal: 45.5s\tremaining: 17.6s\n",
            "1890:\tlearn: 95.9118532\ttotal: 45.5s\tremaining: 17.5s\n",
            "1891:\tlearn: 95.8988502\ttotal: 45.5s\tremaining: 17.5s\n",
            "1892:\tlearn: 95.8948045\ttotal: 45.5s\tremaining: 17.5s\n",
            "1893:\tlearn: 95.8922633\ttotal: 45.6s\tremaining: 17.5s\n",
            "1894:\tlearn: 95.8856071\ttotal: 45.6s\tremaining: 17.4s\n",
            "1895:\tlearn: 95.8842533\ttotal: 45.6s\tremaining: 17.4s\n",
            "1896:\tlearn: 95.8722589\ttotal: 45.6s\tremaining: 17.4s\n",
            "1897:\tlearn: 95.8657408\ttotal: 45.7s\tremaining: 17.4s\n",
            "1898:\tlearn: 95.8614648\ttotal: 45.7s\tremaining: 17.3s\n",
            "1899:\tlearn: 95.8588853\ttotal: 45.7s\tremaining: 17.3s\n",
            "1900:\tlearn: 95.8480967\ttotal: 45.7s\tremaining: 17.3s\n",
            "1901:\tlearn: 95.8379446\ttotal: 45.8s\tremaining: 17.3s\n",
            "1902:\tlearn: 95.8298347\ttotal: 45.8s\tremaining: 17.3s\n",
            "1903:\tlearn: 95.8208564\ttotal: 45.8s\tremaining: 17.2s\n",
            "1904:\tlearn: 95.8137930\ttotal: 45.8s\tremaining: 17.2s\n",
            "1905:\tlearn: 95.7853192\ttotal: 45.9s\tremaining: 17.2s\n",
            "1906:\tlearn: 95.7749729\ttotal: 45.9s\tremaining: 17.2s\n",
            "1907:\tlearn: 95.7684744\ttotal: 45.9s\tremaining: 17.1s\n",
            "1908:\tlearn: 95.7519954\ttotal: 45.9s\tremaining: 17.1s\n",
            "1909:\tlearn: 95.7476337\ttotal: 46s\tremaining: 17.1s\n",
            "1910:\tlearn: 95.7423493\ttotal: 46s\tremaining: 17.1s\n",
            "1911:\tlearn: 95.7331169\ttotal: 46s\tremaining: 17s\n",
            "1912:\tlearn: 95.7250056\ttotal: 46s\tremaining: 17s\n",
            "1913:\tlearn: 95.7161784\ttotal: 46.1s\tremaining: 17s\n",
            "1914:\tlearn: 95.7118223\ttotal: 46.1s\tremaining: 17s\n",
            "1915:\tlearn: 95.7059778\ttotal: 46.1s\tremaining: 16.9s\n",
            "1916:\tlearn: 95.6939090\ttotal: 46.1s\tremaining: 16.9s\n",
            "1917:\tlearn: 95.6814212\ttotal: 46.1s\tremaining: 16.9s\n",
            "1918:\tlearn: 95.6716544\ttotal: 46.2s\tremaining: 16.9s\n",
            "1919:\tlearn: 95.6650991\ttotal: 46.2s\tremaining: 16.8s\n",
            "1920:\tlearn: 95.6614011\ttotal: 46.2s\tremaining: 16.8s\n",
            "1921:\tlearn: 95.6540651\ttotal: 46.2s\tremaining: 16.8s\n",
            "1922:\tlearn: 95.6439716\ttotal: 46.3s\tremaining: 16.8s\n",
            "1923:\tlearn: 95.6360854\ttotal: 46.3s\tremaining: 16.7s\n",
            "1924:\tlearn: 95.6236475\ttotal: 46.3s\tremaining: 16.7s\n",
            "1925:\tlearn: 95.6131854\ttotal: 46.3s\tremaining: 16.7s\n",
            "1926:\tlearn: 95.6016042\ttotal: 46.3s\tremaining: 16.7s\n",
            "1927:\tlearn: 95.5918634\ttotal: 46.4s\tremaining: 16.6s\n",
            "1928:\tlearn: 95.5857222\ttotal: 46.4s\tremaining: 16.6s\n",
            "1929:\tlearn: 95.5727170\ttotal: 46.4s\tremaining: 16.6s\n",
            "1930:\tlearn: 95.5679851\ttotal: 46.4s\tremaining: 16.6s\n",
            "1931:\tlearn: 95.5541612\ttotal: 46.5s\tremaining: 16.5s\n",
            "1932:\tlearn: 95.5499498\ttotal: 46.5s\tremaining: 16.5s\n",
            "1933:\tlearn: 95.5368622\ttotal: 46.5s\tremaining: 16.5s\n",
            "1934:\tlearn: 95.5276700\ttotal: 46.5s\tremaining: 16.5s\n",
            "1935:\tlearn: 95.5227440\ttotal: 46.5s\tremaining: 16.4s\n",
            "1936:\tlearn: 95.5155947\ttotal: 46.6s\tremaining: 16.4s\n",
            "1937:\tlearn: 95.5036024\ttotal: 46.6s\tremaining: 16.4s\n",
            "1938:\tlearn: 95.4815554\ttotal: 46.6s\tremaining: 16.4s\n",
            "1939:\tlearn: 95.4796433\ttotal: 46.6s\tremaining: 16.4s\n",
            "1940:\tlearn: 95.4727120\ttotal: 46.7s\tremaining: 16.3s\n",
            "1941:\tlearn: 95.4686783\ttotal: 46.7s\tremaining: 16.3s\n",
            "1942:\tlearn: 95.4620056\ttotal: 46.7s\tremaining: 16.3s\n",
            "1943:\tlearn: 95.4563305\ttotal: 46.8s\tremaining: 16.3s\n",
            "1944:\tlearn: 95.4504708\ttotal: 46.8s\tremaining: 16.2s\n",
            "1945:\tlearn: 95.4420885\ttotal: 46.8s\tremaining: 16.2s\n",
            "1946:\tlearn: 95.4357075\ttotal: 46.8s\tremaining: 16.2s\n",
            "1947:\tlearn: 95.4288447\ttotal: 46.8s\tremaining: 16.2s\n",
            "1948:\tlearn: 95.4247913\ttotal: 46.9s\tremaining: 16.1s\n",
            "1949:\tlearn: 95.4140439\ttotal: 46.9s\tremaining: 16.1s\n",
            "1950:\tlearn: 95.4057389\ttotal: 46.9s\tremaining: 16.1s\n",
            "1951:\tlearn: 95.3946077\ttotal: 46.9s\tremaining: 16.1s\n",
            "1952:\tlearn: 95.3890811\ttotal: 47s\tremaining: 16s\n",
            "1953:\tlearn: 95.3758323\ttotal: 47s\tremaining: 16s\n",
            "1954:\tlearn: 95.3672415\ttotal: 47s\tremaining: 16s\n",
            "1955:\tlearn: 95.3555419\ttotal: 47s\tremaining: 16s\n",
            "1956:\tlearn: 95.3433805\ttotal: 47s\tremaining: 15.9s\n",
            "1957:\tlearn: 95.3344286\ttotal: 47.1s\tremaining: 15.9s\n",
            "1958:\tlearn: 95.3307733\ttotal: 47.1s\tremaining: 15.9s\n",
            "1959:\tlearn: 95.3171024\ttotal: 47.1s\tremaining: 15.9s\n",
            "1960:\tlearn: 95.3058541\ttotal: 47.1s\tremaining: 15.8s\n",
            "1961:\tlearn: 95.3036269\ttotal: 47.2s\tremaining: 15.8s\n",
            "1962:\tlearn: 95.2978855\ttotal: 47.2s\tremaining: 15.8s\n",
            "1963:\tlearn: 95.2870856\ttotal: 47.2s\tremaining: 15.8s\n",
            "1964:\tlearn: 95.2633510\ttotal: 47.2s\tremaining: 15.7s\n",
            "1965:\tlearn: 95.2618424\ttotal: 47.3s\tremaining: 15.7s\n",
            "1966:\tlearn: 95.2422864\ttotal: 47.3s\tremaining: 15.7s\n",
            "1967:\tlearn: 95.2167739\ttotal: 47.3s\tremaining: 15.7s\n",
            "1968:\tlearn: 95.2086250\ttotal: 47.4s\tremaining: 15.7s\n",
            "1969:\tlearn: 95.2053498\ttotal: 47.4s\tremaining: 15.6s\n",
            "1970:\tlearn: 95.1965936\ttotal: 47.4s\tremaining: 15.6s\n",
            "1971:\tlearn: 95.1851904\ttotal: 47.4s\tremaining: 15.6s\n",
            "1972:\tlearn: 95.1803653\ttotal: 47.4s\tremaining: 15.6s\n",
            "1973:\tlearn: 95.1749541\ttotal: 47.5s\tremaining: 15.5s\n",
            "1974:\tlearn: 95.1644097\ttotal: 47.5s\tremaining: 15.5s\n",
            "1975:\tlearn: 95.1620183\ttotal: 47.5s\tremaining: 15.5s\n",
            "1976:\tlearn: 95.1565335\ttotal: 47.5s\tremaining: 15.5s\n",
            "1977:\tlearn: 95.1478187\ttotal: 47.6s\tremaining: 15.4s\n",
            "1978:\tlearn: 95.1394478\ttotal: 47.6s\tremaining: 15.4s\n",
            "1979:\tlearn: 95.1358810\ttotal: 47.6s\tremaining: 15.4s\n",
            "1980:\tlearn: 95.1289798\ttotal: 47.6s\tremaining: 15.4s\n",
            "1981:\tlearn: 95.1169107\ttotal: 47.6s\tremaining: 15.3s\n",
            "1982:\tlearn: 95.1144353\ttotal: 47.7s\tremaining: 15.3s\n",
            "1983:\tlearn: 95.1070954\ttotal: 47.7s\tremaining: 15.3s\n",
            "1984:\tlearn: 95.0965849\ttotal: 47.7s\tremaining: 15.3s\n",
            "1985:\tlearn: 95.0957742\ttotal: 47.7s\tremaining: 15.2s\n",
            "1986:\tlearn: 95.0876477\ttotal: 47.8s\tremaining: 15.2s\n",
            "1987:\tlearn: 95.0744385\ttotal: 47.8s\tremaining: 15.2s\n",
            "1988:\tlearn: 95.0551585\ttotal: 47.8s\tremaining: 15.2s\n",
            "1989:\tlearn: 95.0527756\ttotal: 47.8s\tremaining: 15.1s\n",
            "1990:\tlearn: 95.0434866\ttotal: 47.9s\tremaining: 15.1s\n",
            "1991:\tlearn: 95.0308615\ttotal: 47.9s\tremaining: 15.1s\n",
            "1992:\tlearn: 95.0205411\ttotal: 47.9s\tremaining: 15.1s\n",
            "1993:\tlearn: 95.0156762\ttotal: 47.9s\tremaining: 15.1s\n",
            "1994:\tlearn: 95.0130589\ttotal: 48s\tremaining: 15s\n",
            "1995:\tlearn: 94.9986072\ttotal: 48s\tremaining: 15s\n",
            "1996:\tlearn: 94.9884409\ttotal: 48s\tremaining: 15s\n",
            "1997:\tlearn: 94.9820225\ttotal: 48s\tremaining: 15s\n",
            "1998:\tlearn: 94.9746825\ttotal: 48s\tremaining: 14.9s\n",
            "1999:\tlearn: 94.9709621\ttotal: 48.1s\tremaining: 14.9s\n",
            "2000:\tlearn: 94.9601596\ttotal: 48.1s\tremaining: 14.9s\n",
            "2001:\tlearn: 94.9444487\ttotal: 48.1s\tremaining: 14.9s\n",
            "2002:\tlearn: 94.9404223\ttotal: 48.1s\tremaining: 14.8s\n",
            "2003:\tlearn: 94.9258290\ttotal: 48.2s\tremaining: 14.8s\n",
            "2004:\tlearn: 94.9181601\ttotal: 48.2s\tremaining: 14.8s\n",
            "2005:\tlearn: 94.9150149\ttotal: 48.2s\tremaining: 14.8s\n",
            "2006:\tlearn: 94.9079865\ttotal: 48.2s\tremaining: 14.7s\n",
            "2007:\tlearn: 94.8959950\ttotal: 48.3s\tremaining: 14.7s\n",
            "2008:\tlearn: 94.8768186\ttotal: 48.3s\tremaining: 14.7s\n",
            "2009:\tlearn: 94.8657938\ttotal: 48.3s\tremaining: 14.7s\n",
            "2010:\tlearn: 94.8593628\ttotal: 48.3s\tremaining: 14.6s\n",
            "2011:\tlearn: 94.8473660\ttotal: 48.3s\tremaining: 14.6s\n",
            "2012:\tlearn: 94.8335642\ttotal: 48.4s\tremaining: 14.6s\n",
            "2013:\tlearn: 94.8194289\ttotal: 48.4s\tremaining: 14.6s\n",
            "2014:\tlearn: 94.8135061\ttotal: 48.4s\tremaining: 14.5s\n",
            "2015:\tlearn: 94.8107735\ttotal: 48.4s\tremaining: 14.5s\n",
            "2016:\tlearn: 94.8030371\ttotal: 48.5s\tremaining: 14.5s\n",
            "2017:\tlearn: 94.7923488\ttotal: 48.5s\tremaining: 14.5s\n",
            "2018:\tlearn: 94.7880702\ttotal: 48.5s\tremaining: 14.4s\n",
            "2019:\tlearn: 94.7880463\ttotal: 48.5s\tremaining: 14.4s\n",
            "2020:\tlearn: 94.7798717\ttotal: 48.5s\tremaining: 14.4s\n",
            "2021:\tlearn: 94.7738341\ttotal: 48.6s\tremaining: 14.4s\n",
            "2022:\tlearn: 94.7630254\ttotal: 48.6s\tremaining: 14.3s\n",
            "2023:\tlearn: 94.7566641\ttotal: 48.6s\tremaining: 14.3s\n",
            "2024:\tlearn: 94.7503636\ttotal: 48.6s\tremaining: 14.3s\n",
            "2025:\tlearn: 94.7386625\ttotal: 48.6s\tremaining: 14.3s\n",
            "2026:\tlearn: 94.7345040\ttotal: 48.7s\tremaining: 14.2s\n",
            "2027:\tlearn: 94.7274675\ttotal: 48.7s\tremaining: 14.2s\n",
            "2028:\tlearn: 94.7238111\ttotal: 48.7s\tremaining: 14.2s\n",
            "2029:\tlearn: 94.7207965\ttotal: 48.8s\tremaining: 14.2s\n",
            "2030:\tlearn: 94.7133185\ttotal: 48.8s\tremaining: 14.1s\n",
            "2031:\tlearn: 94.7077170\ttotal: 48.8s\tremaining: 14.1s\n",
            "2032:\tlearn: 94.6921514\ttotal: 48.8s\tremaining: 14.1s\n",
            "2033:\tlearn: 94.6810298\ttotal: 48.9s\tremaining: 14.1s\n",
            "2034:\tlearn: 94.6791154\ttotal: 48.9s\tremaining: 14.1s\n",
            "2035:\tlearn: 94.6732912\ttotal: 48.9s\tremaining: 14s\n",
            "2036:\tlearn: 94.6689592\ttotal: 48.9s\tremaining: 14s\n",
            "2037:\tlearn: 94.6637086\ttotal: 48.9s\tremaining: 14s\n",
            "2038:\tlearn: 94.6523937\ttotal: 49s\tremaining: 14s\n",
            "2039:\tlearn: 94.6426999\ttotal: 49s\tremaining: 13.9s\n",
            "2040:\tlearn: 94.6370876\ttotal: 49s\tremaining: 13.9s\n",
            "2041:\tlearn: 94.6286087\ttotal: 49s\tremaining: 13.9s\n",
            "2042:\tlearn: 94.6272216\ttotal: 49.1s\tremaining: 13.9s\n",
            "2043:\tlearn: 94.6230210\ttotal: 49.1s\tremaining: 13.8s\n",
            "2044:\tlearn: 94.6125304\ttotal: 49.1s\tremaining: 13.8s\n",
            "2045:\tlearn: 94.6019608\ttotal: 49.1s\tremaining: 13.8s\n",
            "2046:\tlearn: 94.5932445\ttotal: 49.2s\tremaining: 13.8s\n",
            "2047:\tlearn: 94.5888708\ttotal: 49.2s\tremaining: 13.7s\n",
            "2048:\tlearn: 94.5803933\ttotal: 49.2s\tremaining: 13.7s\n",
            "2049:\tlearn: 94.5793149\ttotal: 49.3s\tremaining: 13.7s\n",
            "2050:\tlearn: 94.5624322\ttotal: 49.3s\tremaining: 13.7s\n",
            "2051:\tlearn: 94.5511472\ttotal: 49.3s\tremaining: 13.6s\n",
            "2052:\tlearn: 94.5334561\ttotal: 49.3s\tremaining: 13.6s\n",
            "2053:\tlearn: 94.5273791\ttotal: 49.3s\tremaining: 13.6s\n",
            "2054:\tlearn: 94.5075587\ttotal: 49.3s\tremaining: 13.6s\n",
            "2055:\tlearn: 94.5040972\ttotal: 49.4s\tremaining: 13.5s\n",
            "2056:\tlearn: 94.4957735\ttotal: 49.4s\tremaining: 13.5s\n",
            "2057:\tlearn: 94.4858314\ttotal: 49.4s\tremaining: 13.5s\n",
            "2058:\tlearn: 94.4756299\ttotal: 49.5s\tremaining: 13.5s\n",
            "2059:\tlearn: 94.4680545\ttotal: 49.5s\tremaining: 13.5s\n",
            "2060:\tlearn: 94.4675712\ttotal: 49.5s\tremaining: 13.4s\n",
            "2061:\tlearn: 94.4555997\ttotal: 49.5s\tremaining: 13.4s\n",
            "2062:\tlearn: 94.4412975\ttotal: 49.6s\tremaining: 13.4s\n",
            "2063:\tlearn: 94.4310680\ttotal: 49.6s\tremaining: 13.4s\n",
            "2064:\tlearn: 94.4263742\ttotal: 49.6s\tremaining: 13.3s\n",
            "2065:\tlearn: 94.4174222\ttotal: 49.6s\tremaining: 13.3s\n",
            "2066:\tlearn: 94.4075906\ttotal: 49.7s\tremaining: 13.3s\n",
            "2067:\tlearn: 94.3967035\ttotal: 49.7s\tremaining: 13.3s\n",
            "2068:\tlearn: 94.3849250\ttotal: 49.7s\tremaining: 13.2s\n",
            "2069:\tlearn: 94.3694137\ttotal: 49.7s\tremaining: 13.2s\n",
            "2070:\tlearn: 94.3591194\ttotal: 49.8s\tremaining: 13.2s\n",
            "2071:\tlearn: 94.3564398\ttotal: 49.8s\tremaining: 13.2s\n",
            "2072:\tlearn: 94.3552972\ttotal: 49.8s\tremaining: 13.1s\n",
            "2073:\tlearn: 94.3516463\ttotal: 49.8s\tremaining: 13.1s\n",
            "2074:\tlearn: 94.3486033\ttotal: 49.9s\tremaining: 13.1s\n",
            "2075:\tlearn: 94.3332045\ttotal: 49.9s\tremaining: 13.1s\n",
            "2076:\tlearn: 94.3208657\ttotal: 49.9s\tremaining: 13s\n",
            "2077:\tlearn: 94.3069773\ttotal: 49.9s\tremaining: 13s\n",
            "2078:\tlearn: 94.2997416\ttotal: 49.9s\tremaining: 13s\n",
            "2079:\tlearn: 94.2910387\ttotal: 50s\tremaining: 13s\n",
            "2080:\tlearn: 94.2851755\ttotal: 50s\tremaining: 12.9s\n",
            "2081:\tlearn: 94.2730050\ttotal: 50s\tremaining: 12.9s\n",
            "2082:\tlearn: 94.2646216\ttotal: 50s\tremaining: 12.9s\n",
            "2083:\tlearn: 94.2607885\ttotal: 50.1s\tremaining: 12.9s\n",
            "2084:\tlearn: 94.2363008\ttotal: 50.1s\tremaining: 12.9s\n",
            "2085:\tlearn: 94.2299408\ttotal: 50.1s\tremaining: 12.8s\n",
            "2086:\tlearn: 94.2201484\ttotal: 50.1s\tremaining: 12.8s\n",
            "2087:\tlearn: 94.2179015\ttotal: 50.2s\tremaining: 12.8s\n",
            "2088:\tlearn: 94.2155762\ttotal: 50.2s\tremaining: 12.8s\n",
            "2089:\tlearn: 94.2060209\ttotal: 50.2s\tremaining: 12.7s\n",
            "2090:\tlearn: 94.2028801\ttotal: 50.3s\tremaining: 12.7s\n",
            "2091:\tlearn: 94.1943698\ttotal: 50.3s\tremaining: 12.7s\n",
            "2092:\tlearn: 94.1897092\ttotal: 50.3s\tremaining: 12.7s\n",
            "2093:\tlearn: 94.1866195\ttotal: 50.3s\tremaining: 12.6s\n",
            "2094:\tlearn: 94.1814211\ttotal: 50.4s\tremaining: 12.6s\n",
            "2095:\tlearn: 94.1785802\ttotal: 50.4s\tremaining: 12.6s\n",
            "2096:\tlearn: 94.1746163\ttotal: 50.4s\tremaining: 12.6s\n",
            "2097:\tlearn: 94.1689721\ttotal: 50.4s\tremaining: 12.5s\n",
            "2098:\tlearn: 94.1561939\ttotal: 50.5s\tremaining: 12.5s\n",
            "2099:\tlearn: 94.1524583\ttotal: 50.5s\tremaining: 12.5s\n",
            "2100:\tlearn: 94.1474598\ttotal: 50.5s\tremaining: 12.5s\n",
            "2101:\tlearn: 94.1391421\ttotal: 50.5s\tremaining: 12.4s\n",
            "2102:\tlearn: 94.1359039\ttotal: 50.5s\tremaining: 12.4s\n",
            "2103:\tlearn: 94.1269517\ttotal: 50.6s\tremaining: 12.4s\n",
            "2104:\tlearn: 94.1146813\ttotal: 50.6s\tremaining: 12.4s\n",
            "2105:\tlearn: 94.1078648\ttotal: 50.6s\tremaining: 12.3s\n",
            "2106:\tlearn: 94.0997205\ttotal: 50.6s\tremaining: 12.3s\n",
            "2107:\tlearn: 94.0956365\ttotal: 50.7s\tremaining: 12.3s\n",
            "2108:\tlearn: 94.0878845\ttotal: 50.7s\tremaining: 12.3s\n",
            "2109:\tlearn: 94.0811095\ttotal: 50.7s\tremaining: 12.3s\n",
            "2110:\tlearn: 94.0775732\ttotal: 50.7s\tremaining: 12.2s\n",
            "2111:\tlearn: 94.0675136\ttotal: 50.7s\tremaining: 12.2s\n",
            "2112:\tlearn: 94.0585386\ttotal: 50.8s\tremaining: 12.2s\n",
            "2113:\tlearn: 94.0536283\ttotal: 50.8s\tremaining: 12.2s\n",
            "2114:\tlearn: 94.0506257\ttotal: 50.8s\tremaining: 12.1s\n",
            "2115:\tlearn: 94.0457988\ttotal: 50.8s\tremaining: 12.1s\n",
            "2116:\tlearn: 94.0248316\ttotal: 50.9s\tremaining: 12.1s\n",
            "2117:\tlearn: 94.0200853\ttotal: 50.9s\tremaining: 12.1s\n",
            "2118:\tlearn: 94.0104317\ttotal: 50.9s\tremaining: 12s\n",
            "2119:\tlearn: 94.0012658\ttotal: 50.9s\tremaining: 12s\n",
            "2120:\tlearn: 93.9921248\ttotal: 50.9s\tremaining: 12s\n",
            "2121:\tlearn: 93.9784151\ttotal: 51s\tremaining: 12s\n",
            "2122:\tlearn: 93.9672123\ttotal: 51s\tremaining: 11.9s\n",
            "2123:\tlearn: 93.9613625\ttotal: 51s\tremaining: 11.9s\n",
            "2124:\tlearn: 93.9479237\ttotal: 51s\tremaining: 11.9s\n",
            "2125:\tlearn: 93.9426377\ttotal: 51s\tremaining: 11.9s\n",
            "2126:\tlearn: 93.9315707\ttotal: 51.1s\tremaining: 11.8s\n",
            "2127:\tlearn: 93.9202291\ttotal: 51.1s\tremaining: 11.8s\n",
            "2128:\tlearn: 93.9190009\ttotal: 51.1s\tremaining: 11.8s\n",
            "2129:\tlearn: 93.9088037\ttotal: 51.2s\tremaining: 11.8s\n",
            "2130:\tlearn: 93.9067622\ttotal: 51.2s\tremaining: 11.7s\n",
            "2131:\tlearn: 93.9028278\ttotal: 51.2s\tremaining: 11.7s\n",
            "2132:\tlearn: 93.8968656\ttotal: 51.2s\tremaining: 11.7s\n",
            "2133:\tlearn: 93.8857737\ttotal: 51.3s\tremaining: 11.7s\n",
            "2134:\tlearn: 93.8836378\ttotal: 51.3s\tremaining: 11.6s\n",
            "2135:\tlearn: 93.8812433\ttotal: 51.3s\tremaining: 11.6s\n",
            "2136:\tlearn: 93.8758875\ttotal: 51.3s\tremaining: 11.6s\n",
            "2137:\tlearn: 93.8526152\ttotal: 51.3s\tremaining: 11.6s\n",
            "2138:\tlearn: 93.8499424\ttotal: 51.4s\tremaining: 11.6s\n",
            "2139:\tlearn: 93.8434376\ttotal: 51.4s\tremaining: 11.5s\n",
            "2140:\tlearn: 93.8325029\ttotal: 51.4s\tremaining: 11.5s\n",
            "2141:\tlearn: 93.8270502\ttotal: 51.4s\tremaining: 11.5s\n",
            "2142:\tlearn: 93.8219043\ttotal: 51.5s\tremaining: 11.5s\n",
            "2143:\tlearn: 93.8093378\ttotal: 51.5s\tremaining: 11.4s\n",
            "2144:\tlearn: 93.8085987\ttotal: 51.5s\tremaining: 11.4s\n",
            "2145:\tlearn: 93.8006713\ttotal: 51.5s\tremaining: 11.4s\n",
            "2146:\tlearn: 93.7925959\ttotal: 51.6s\tremaining: 11.4s\n",
            "2147:\tlearn: 93.7852192\ttotal: 51.6s\tremaining: 11.3s\n",
            "2148:\tlearn: 93.7801230\ttotal: 51.6s\tremaining: 11.3s\n",
            "2149:\tlearn: 93.7676616\ttotal: 51.6s\tremaining: 11.3s\n",
            "2150:\tlearn: 93.7607126\ttotal: 51.7s\tremaining: 11.3s\n",
            "2151:\tlearn: 93.7538708\ttotal: 51.7s\tremaining: 11.2s\n",
            "2152:\tlearn: 93.7449016\ttotal: 51.7s\tremaining: 11.2s\n",
            "2153:\tlearn: 93.7436766\ttotal: 51.7s\tremaining: 11.2s\n",
            "2154:\tlearn: 93.7388405\ttotal: 51.8s\tremaining: 11.2s\n",
            "2155:\tlearn: 93.7309206\ttotal: 51.8s\tremaining: 11.1s\n",
            "2156:\tlearn: 93.7212675\ttotal: 51.8s\tremaining: 11.1s\n",
            "2157:\tlearn: 93.7054597\ttotal: 51.8s\tremaining: 11.1s\n",
            "2158:\tlearn: 93.6964633\ttotal: 51.9s\tremaining: 11.1s\n",
            "2159:\tlearn: 93.6887702\ttotal: 51.9s\tremaining: 11s\n",
            "2160:\tlearn: 93.6863001\ttotal: 51.9s\tremaining: 11s\n",
            "2161:\tlearn: 93.6835918\ttotal: 51.9s\tremaining: 11s\n",
            "2162:\tlearn: 93.6813673\ttotal: 52s\tremaining: 11s\n",
            "2163:\tlearn: 93.6578961\ttotal: 52s\tremaining: 11s\n",
            "2164:\tlearn: 93.6550102\ttotal: 52s\tremaining: 10.9s\n",
            "2165:\tlearn: 93.6397329\ttotal: 52s\tremaining: 10.9s\n",
            "2166:\tlearn: 93.6337331\ttotal: 52s\tremaining: 10.9s\n",
            "2167:\tlearn: 93.6201425\ttotal: 52.1s\tremaining: 10.9s\n",
            "2168:\tlearn: 93.6097076\ttotal: 52.1s\tremaining: 10.8s\n",
            "2169:\tlearn: 93.5987178\ttotal: 52.1s\tremaining: 10.8s\n",
            "2170:\tlearn: 93.5979477\ttotal: 52.1s\tremaining: 10.8s\n",
            "2171:\tlearn: 93.5812138\ttotal: 52.2s\tremaining: 10.8s\n",
            "2172:\tlearn: 93.5664202\ttotal: 52.2s\tremaining: 10.7s\n",
            "2173:\tlearn: 93.5577580\ttotal: 52.2s\tremaining: 10.7s\n",
            "2174:\tlearn: 93.5543894\ttotal: 52.2s\tremaining: 10.7s\n",
            "2175:\tlearn: 93.5473330\ttotal: 52.3s\tremaining: 10.7s\n",
            "2176:\tlearn: 93.5376812\ttotal: 52.3s\tremaining: 10.6s\n",
            "2177:\tlearn: 93.5238094\ttotal: 52.3s\tremaining: 10.6s\n",
            "2178:\tlearn: 93.5149958\ttotal: 52.3s\tremaining: 10.6s\n",
            "2179:\tlearn: 93.5074211\ttotal: 52.3s\tremaining: 10.6s\n",
            "2180:\tlearn: 93.4983541\ttotal: 52.4s\tremaining: 10.5s\n",
            "2181:\tlearn: 93.4831117\ttotal: 52.4s\tremaining: 10.5s\n",
            "2182:\tlearn: 93.4789141\ttotal: 52.4s\tremaining: 10.5s\n",
            "2183:\tlearn: 93.4672435\ttotal: 52.5s\tremaining: 10.5s\n",
            "2184:\tlearn: 93.4601696\ttotal: 52.5s\tremaining: 10.4s\n",
            "2185:\tlearn: 93.4584329\ttotal: 52.5s\tremaining: 10.4s\n",
            "2186:\tlearn: 93.4498886\ttotal: 52.5s\tremaining: 10.4s\n",
            "2187:\tlearn: 93.4438868\ttotal: 52.6s\tremaining: 10.4s\n",
            "2188:\tlearn: 93.4304426\ttotal: 52.6s\tremaining: 10.4s\n",
            "2189:\tlearn: 93.4265486\ttotal: 52.6s\tremaining: 10.3s\n",
            "2190:\tlearn: 93.4201797\ttotal: 52.6s\tremaining: 10.3s\n",
            "2191:\tlearn: 93.4031227\ttotal: 52.7s\tremaining: 10.3s\n",
            "2192:\tlearn: 93.3993661\ttotal: 52.7s\tremaining: 10.3s\n",
            "2193:\tlearn: 93.3780709\ttotal: 52.7s\tremaining: 10.2s\n",
            "2194:\tlearn: 93.3748078\ttotal: 52.7s\tremaining: 10.2s\n",
            "2195:\tlearn: 93.3669532\ttotal: 52.7s\tremaining: 10.2s\n",
            "2196:\tlearn: 93.3592964\ttotal: 52.8s\tremaining: 10.2s\n",
            "2197:\tlearn: 93.3559624\ttotal: 52.8s\tremaining: 10.1s\n",
            "2198:\tlearn: 93.3513335\ttotal: 52.8s\tremaining: 10.1s\n",
            "2199:\tlearn: 93.3407043\ttotal: 52.8s\tremaining: 10.1s\n",
            "2200:\tlearn: 93.3360142\ttotal: 52.9s\tremaining: 10.1s\n",
            "2201:\tlearn: 93.3331555\ttotal: 52.9s\tremaining: 10s\n",
            "2202:\tlearn: 93.3278696\ttotal: 52.9s\tremaining: 10s\n",
            "2203:\tlearn: 93.3262643\ttotal: 52.9s\tremaining: 9.99s\n",
            "2204:\tlearn: 93.3180518\ttotal: 53s\tremaining: 9.97s\n",
            "2205:\tlearn: 93.3157421\ttotal: 53s\tremaining: 9.94s\n",
            "2206:\tlearn: 93.3046562\ttotal: 53s\tremaining: 9.92s\n",
            "2207:\tlearn: 93.2964702\ttotal: 53s\tremaining: 9.89s\n",
            "2208:\tlearn: 93.2869585\ttotal: 53.1s\tremaining: 9.87s\n",
            "2209:\tlearn: 93.2830755\ttotal: 53.1s\tremaining: 9.85s\n",
            "2210:\tlearn: 93.2760484\ttotal: 53.1s\tremaining: 9.82s\n",
            "2211:\tlearn: 93.2653489\ttotal: 53.1s\tremaining: 9.8s\n",
            "2212:\tlearn: 93.2583661\ttotal: 53.2s\tremaining: 9.78s\n",
            "2213:\tlearn: 93.2563210\ttotal: 53.2s\tremaining: 9.75s\n",
            "2214:\tlearn: 93.2476158\ttotal: 53.2s\tremaining: 9.73s\n",
            "2215:\tlearn: 93.2430946\ttotal: 53.2s\tremaining: 9.7s\n",
            "2216:\tlearn: 93.2333412\ttotal: 53.3s\tremaining: 9.68s\n",
            "2217:\tlearn: 93.2278499\ttotal: 53.3s\tremaining: 9.65s\n",
            "2218:\tlearn: 93.2182891\ttotal: 53.3s\tremaining: 9.63s\n",
            "2219:\tlearn: 93.2069313\ttotal: 53.3s\tremaining: 9.61s\n",
            "2220:\tlearn: 93.2062969\ttotal: 53.3s\tremaining: 9.58s\n",
            "2221:\tlearn: 93.1993207\ttotal: 53.4s\tremaining: 9.56s\n",
            "2222:\tlearn: 93.1948152\ttotal: 53.4s\tremaining: 9.54s\n",
            "2223:\tlearn: 93.1788581\ttotal: 53.4s\tremaining: 9.51s\n",
            "2224:\tlearn: 93.1745448\ttotal: 53.4s\tremaining: 9.49s\n",
            "2225:\tlearn: 93.1625158\ttotal: 53.5s\tremaining: 9.46s\n",
            "2226:\tlearn: 93.1252279\ttotal: 53.5s\tremaining: 9.44s\n",
            "2227:\tlearn: 93.1201744\ttotal: 53.5s\tremaining: 9.41s\n",
            "2228:\tlearn: 93.1182713\ttotal: 53.5s\tremaining: 9.39s\n",
            "2229:\tlearn: 93.1093153\ttotal: 53.5s\tremaining: 9.37s\n",
            "2230:\tlearn: 93.0993658\ttotal: 53.6s\tremaining: 9.34s\n",
            "2231:\tlearn: 93.0963597\ttotal: 53.6s\tremaining: 9.31s\n",
            "2232:\tlearn: 93.0863941\ttotal: 53.6s\tremaining: 9.29s\n",
            "2233:\tlearn: 93.0786942\ttotal: 53.6s\tremaining: 9.27s\n",
            "2234:\tlearn: 93.0719571\ttotal: 53.7s\tremaining: 9.24s\n",
            "2235:\tlearn: 93.0662015\ttotal: 53.7s\tremaining: 9.22s\n",
            "2236:\tlearn: 93.0580842\ttotal: 53.7s\tremaining: 9.2s\n",
            "2237:\tlearn: 93.0539025\ttotal: 53.7s\tremaining: 9.17s\n",
            "2238:\tlearn: 93.0381026\ttotal: 53.8s\tremaining: 9.15s\n",
            "2239:\tlearn: 93.0344310\ttotal: 53.8s\tremaining: 9.12s\n",
            "2240:\tlearn: 93.0261503\ttotal: 53.8s\tremaining: 9.1s\n",
            "2241:\tlearn: 93.0133640\ttotal: 53.8s\tremaining: 9.07s\n",
            "2242:\tlearn: 93.0133306\ttotal: 53.8s\tremaining: 9.05s\n",
            "2243:\tlearn: 93.0074537\ttotal: 53.9s\tremaining: 9.02s\n",
            "2244:\tlearn: 93.0031284\ttotal: 53.9s\tremaining: 9s\n",
            "2245:\tlearn: 92.9890402\ttotal: 53.9s\tremaining: 8.97s\n",
            "2246:\tlearn: 92.9829833\ttotal: 53.9s\tremaining: 8.95s\n",
            "2247:\tlearn: 92.9790515\ttotal: 53.9s\tremaining: 8.93s\n",
            "2248:\tlearn: 92.9692005\ttotal: 54s\tremaining: 8.9s\n",
            "2249:\tlearn: 92.9511030\ttotal: 54s\tremaining: 8.88s\n",
            "2250:\tlearn: 92.9410386\ttotal: 54s\tremaining: 8.85s\n",
            "2251:\tlearn: 92.9394739\ttotal: 54s\tremaining: 8.83s\n",
            "2252:\tlearn: 92.9372852\ttotal: 54s\tremaining: 8.8s\n",
            "2253:\tlearn: 92.9257482\ttotal: 54.1s\tremaining: 8.78s\n",
            "2254:\tlearn: 92.9226946\ttotal: 54.1s\tremaining: 8.76s\n",
            "2255:\tlearn: 92.9194224\ttotal: 54.1s\tremaining: 8.73s\n",
            "2256:\tlearn: 92.9147731\ttotal: 54.1s\tremaining: 8.71s\n",
            "2257:\tlearn: 92.9033441\ttotal: 54.2s\tremaining: 8.68s\n",
            "2258:\tlearn: 92.9002603\ttotal: 54.2s\tremaining: 8.66s\n",
            "2259:\tlearn: 92.8952806\ttotal: 54.2s\tremaining: 8.63s\n",
            "2260:\tlearn: 92.8898080\ttotal: 54.2s\tremaining: 8.61s\n",
            "2261:\tlearn: 92.8860562\ttotal: 54.2s\tremaining: 8.59s\n",
            "2262:\tlearn: 92.8777073\ttotal: 54.3s\tremaining: 8.56s\n",
            "2263:\tlearn: 92.8670653\ttotal: 54.3s\tremaining: 8.54s\n",
            "2264:\tlearn: 92.8605308\ttotal: 54.3s\tremaining: 8.51s\n",
            "2265:\tlearn: 92.8489333\ttotal: 54.3s\tremaining: 8.49s\n",
            "2266:\tlearn: 92.8476308\ttotal: 54.4s\tremaining: 8.47s\n",
            "2267:\tlearn: 92.8432818\ttotal: 54.4s\tremaining: 8.44s\n",
            "2268:\tlearn: 92.8352906\ttotal: 54.4s\tremaining: 8.42s\n",
            "2269:\tlearn: 92.8323389\ttotal: 54.4s\tremaining: 8.39s\n",
            "2270:\tlearn: 92.8156493\ttotal: 54.5s\tremaining: 8.37s\n",
            "2271:\tlearn: 92.8101320\ttotal: 54.5s\tremaining: 8.35s\n",
            "2272:\tlearn: 92.7935871\ttotal: 54.5s\tremaining: 8.32s\n",
            "2273:\tlearn: 92.7835820\ttotal: 54.5s\tremaining: 8.3s\n",
            "2274:\tlearn: 92.7772677\ttotal: 54.6s\tremaining: 8.27s\n",
            "2275:\tlearn: 92.7670453\ttotal: 54.6s\tremaining: 8.26s\n",
            "2276:\tlearn: 92.7590614\ttotal: 54.7s\tremaining: 8.23s\n",
            "2277:\tlearn: 92.7547181\ttotal: 54.7s\tremaining: 8.21s\n",
            "2278:\tlearn: 92.7387534\ttotal: 54.7s\tremaining: 8.19s\n",
            "2279:\tlearn: 92.7319395\ttotal: 54.7s\tremaining: 8.16s\n",
            "2280:\tlearn: 92.7227578\ttotal: 54.8s\tremaining: 8.14s\n",
            "2281:\tlearn: 92.7085316\ttotal: 54.8s\tremaining: 8.12s\n",
            "2282:\tlearn: 92.6993618\ttotal: 54.8s\tremaining: 8.09s\n",
            "2283:\tlearn: 92.6979506\ttotal: 54.8s\tremaining: 8.07s\n",
            "2284:\tlearn: 92.6806739\ttotal: 54.9s\tremaining: 8.04s\n",
            "2285:\tlearn: 92.6770218\ttotal: 54.9s\tremaining: 8.02s\n",
            "2286:\tlearn: 92.6615299\ttotal: 54.9s\tremaining: 7.99s\n",
            "2287:\tlearn: 92.6608786\ttotal: 54.9s\tremaining: 7.97s\n",
            "2288:\tlearn: 92.6579630\ttotal: 55s\tremaining: 7.95s\n",
            "2289:\tlearn: 92.6433945\ttotal: 55s\tremaining: 7.92s\n",
            "2290:\tlearn: 92.6331357\ttotal: 55s\tremaining: 7.9s\n",
            "2291:\tlearn: 92.6200094\ttotal: 55s\tremaining: 7.88s\n",
            "2292:\tlearn: 92.6148884\ttotal: 55.1s\tremaining: 7.85s\n",
            "2293:\tlearn: 92.6027280\ttotal: 55.1s\tremaining: 7.83s\n",
            "2294:\tlearn: 92.5911114\ttotal: 55.1s\tremaining: 7.8s\n",
            "2295:\tlearn: 92.5898031\ttotal: 55.1s\tremaining: 7.78s\n",
            "2296:\tlearn: 92.5739336\ttotal: 55.2s\tremaining: 7.75s\n",
            "2297:\tlearn: 92.5639828\ttotal: 55.2s\tremaining: 7.73s\n",
            "2298:\tlearn: 92.5543287\ttotal: 55.2s\tremaining: 7.71s\n",
            "2299:\tlearn: 92.5490295\ttotal: 55.2s\tremaining: 7.68s\n",
            "2300:\tlearn: 92.5414484\ttotal: 55.2s\tremaining: 7.66s\n",
            "2301:\tlearn: 92.5368053\ttotal: 55.3s\tremaining: 7.63s\n",
            "2302:\tlearn: 92.5149541\ttotal: 55.3s\tremaining: 7.61s\n",
            "2303:\tlearn: 92.5113639\ttotal: 55.3s\tremaining: 7.59s\n",
            "2304:\tlearn: 92.5055985\ttotal: 55.3s\tremaining: 7.56s\n",
            "2305:\tlearn: 92.4971104\ttotal: 55.4s\tremaining: 7.54s\n",
            "2306:\tlearn: 92.4912072\ttotal: 55.4s\tremaining: 7.52s\n",
            "2307:\tlearn: 92.4856366\ttotal: 55.4s\tremaining: 7.49s\n",
            "2308:\tlearn: 92.4779567\ttotal: 55.4s\tremaining: 7.47s\n",
            "2309:\tlearn: 92.4669920\ttotal: 55.5s\tremaining: 7.45s\n",
            "2310:\tlearn: 92.4656725\ttotal: 55.5s\tremaining: 7.42s\n",
            "2311:\tlearn: 92.4625274\ttotal: 55.5s\tremaining: 7.4s\n",
            "2312:\tlearn: 92.4515010\ttotal: 55.5s\tremaining: 7.37s\n",
            "2313:\tlearn: 92.4496720\ttotal: 55.6s\tremaining: 7.35s\n",
            "2314:\tlearn: 92.4481133\ttotal: 55.6s\tremaining: 7.33s\n",
            "2315:\tlearn: 92.4447197\ttotal: 55.6s\tremaining: 7.3s\n",
            "2316:\tlearn: 92.4324326\ttotal: 55.7s\tremaining: 7.28s\n",
            "2317:\tlearn: 92.4213643\ttotal: 55.7s\tremaining: 7.25s\n",
            "2318:\tlearn: 92.4126998\ttotal: 55.7s\tremaining: 7.23s\n",
            "2319:\tlearn: 92.4112397\ttotal: 55.7s\tremaining: 7.21s\n",
            "2320:\tlearn: 92.4037744\ttotal: 55.8s\tremaining: 7.18s\n",
            "2321:\tlearn: 92.4017772\ttotal: 55.8s\tremaining: 7.16s\n",
            "2322:\tlearn: 92.3901390\ttotal: 55.8s\tremaining: 7.13s\n",
            "2323:\tlearn: 92.3664160\ttotal: 55.8s\tremaining: 7.11s\n",
            "2324:\tlearn: 92.3560685\ttotal: 55.9s\tremaining: 7.09s\n",
            "2325:\tlearn: 92.3540477\ttotal: 55.9s\tremaining: 7.06s\n",
            "2326:\tlearn: 92.3447127\ttotal: 55.9s\tremaining: 7.04s\n",
            "2327:\tlearn: 92.3418490\ttotal: 55.9s\tremaining: 7.01s\n",
            "2328:\tlearn: 92.3306184\ttotal: 55.9s\tremaining: 6.99s\n",
            "2329:\tlearn: 92.3227159\ttotal: 56s\tremaining: 6.96s\n",
            "2330:\tlearn: 92.2829258\ttotal: 56s\tremaining: 6.94s\n",
            "2331:\tlearn: 92.2759392\ttotal: 56s\tremaining: 6.92s\n",
            "2332:\tlearn: 92.2657875\ttotal: 56s\tremaining: 6.89s\n",
            "2333:\tlearn: 92.2546264\ttotal: 56.1s\tremaining: 6.87s\n",
            "2334:\tlearn: 92.2452108\ttotal: 56.1s\tremaining: 6.84s\n",
            "2335:\tlearn: 92.2365104\ttotal: 56.1s\tremaining: 6.82s\n",
            "2336:\tlearn: 92.2208670\ttotal: 56.1s\tremaining: 6.8s\n",
            "2337:\tlearn: 92.2193531\ttotal: 56.2s\tremaining: 6.77s\n",
            "2338:\tlearn: 92.2148589\ttotal: 56.2s\tremaining: 6.75s\n",
            "2339:\tlearn: 92.2029491\ttotal: 56.2s\tremaining: 6.72s\n",
            "2340:\tlearn: 92.1948080\ttotal: 56.2s\tremaining: 6.7s\n",
            "2341:\tlearn: 92.1883308\ttotal: 56.3s\tremaining: 6.68s\n",
            "2342:\tlearn: 92.1793206\ttotal: 56.3s\tremaining: 6.65s\n",
            "2343:\tlearn: 92.1750631\ttotal: 56.3s\tremaining: 6.63s\n",
            "2344:\tlearn: 92.1665273\ttotal: 56.3s\tremaining: 6.61s\n",
            "2345:\tlearn: 92.1566012\ttotal: 56.3s\tremaining: 6.58s\n",
            "2346:\tlearn: 92.1535027\ttotal: 56.4s\tremaining: 6.56s\n",
            "2347:\tlearn: 92.1438623\ttotal: 56.4s\tremaining: 6.53s\n",
            "2348:\tlearn: 92.1394837\ttotal: 56.4s\tremaining: 6.51s\n",
            "2349:\tlearn: 92.1367266\ttotal: 56.5s\tremaining: 6.49s\n",
            "2350:\tlearn: 92.1298602\ttotal: 56.5s\tremaining: 6.46s\n",
            "2351:\tlearn: 92.1243161\ttotal: 56.5s\tremaining: 6.44s\n",
            "2352:\tlearn: 92.1118058\ttotal: 56.5s\tremaining: 6.41s\n",
            "2353:\tlearn: 92.1033078\ttotal: 56.5s\tremaining: 6.39s\n",
            "2354:\tlearn: 92.0970671\ttotal: 56.6s\tremaining: 6.36s\n",
            "2355:\tlearn: 92.0858737\ttotal: 56.6s\tremaining: 6.34s\n",
            "2356:\tlearn: 92.0779596\ttotal: 56.6s\tremaining: 6.32s\n",
            "2357:\tlearn: 92.0670155\ttotal: 56.6s\tremaining: 6.29s\n",
            "2358:\tlearn: 92.0623600\ttotal: 56.6s\tremaining: 6.26s\n",
            "2359:\tlearn: 92.0493993\ttotal: 56.7s\tremaining: 6.24s\n",
            "2360:\tlearn: 92.0362127\ttotal: 56.7s\tremaining: 6.22s\n",
            "2361:\tlearn: 92.0361826\ttotal: 56.7s\tremaining: 6.19s\n",
            "2362:\tlearn: 92.0249259\ttotal: 56.7s\tremaining: 6.17s\n",
            "2363:\tlearn: 92.0142273\ttotal: 56.7s\tremaining: 6.14s\n",
            "2364:\tlearn: 92.0055163\ttotal: 56.8s\tremaining: 6.12s\n",
            "2365:\tlearn: 92.0052675\ttotal: 56.8s\tremaining: 6.09s\n",
            "2366:\tlearn: 91.9994066\ttotal: 56.8s\tremaining: 6.07s\n",
            "2367:\tlearn: 91.9915882\ttotal: 56.8s\tremaining: 6.05s\n",
            "2368:\tlearn: 91.9883709\ttotal: 56.9s\tremaining: 6.02s\n",
            "2369:\tlearn: 91.9827132\ttotal: 56.9s\tremaining: 6s\n",
            "2370:\tlearn: 91.9776176\ttotal: 56.9s\tremaining: 5.98s\n",
            "2371:\tlearn: 91.9715897\ttotal: 56.9s\tremaining: 5.95s\n",
            "2372:\tlearn: 91.9567610\ttotal: 57s\tremaining: 5.93s\n",
            "2373:\tlearn: 91.9383119\ttotal: 57s\tremaining: 5.91s\n",
            "2374:\tlearn: 91.9343573\ttotal: 57s\tremaining: 5.88s\n",
            "2375:\tlearn: 91.9285740\ttotal: 57s\tremaining: 5.86s\n",
            "2376:\tlearn: 91.9247253\ttotal: 57.1s\tremaining: 5.83s\n",
            "2377:\tlearn: 91.9164170\ttotal: 57.1s\tremaining: 5.81s\n",
            "2378:\tlearn: 91.9092426\ttotal: 57.1s\tremaining: 5.78s\n",
            "2379:\tlearn: 91.9002044\ttotal: 57.1s\tremaining: 5.76s\n",
            "2380:\tlearn: 91.8918028\ttotal: 57.1s\tremaining: 5.74s\n",
            "2381:\tlearn: 91.8831726\ttotal: 57.2s\tremaining: 5.71s\n",
            "2382:\tlearn: 91.8778162\ttotal: 57.2s\tremaining: 5.69s\n",
            "2383:\tlearn: 91.8748212\ttotal: 57.2s\tremaining: 5.66s\n",
            "2384:\tlearn: 91.8676698\ttotal: 57.2s\tremaining: 5.64s\n",
            "2385:\tlearn: 91.8617078\ttotal: 57.2s\tremaining: 5.61s\n",
            "2386:\tlearn: 91.8601900\ttotal: 57.3s\tremaining: 5.59s\n",
            "2387:\tlearn: 91.8553498\ttotal: 57.3s\tremaining: 5.57s\n",
            "2388:\tlearn: 91.8462850\ttotal: 57.3s\tremaining: 5.54s\n",
            "2389:\tlearn: 91.8359012\ttotal: 57.3s\tremaining: 5.52s\n",
            "2390:\tlearn: 91.8238705\ttotal: 57.4s\tremaining: 5.49s\n",
            "2391:\tlearn: 91.8171317\ttotal: 57.4s\tremaining: 5.47s\n",
            "2392:\tlearn: 91.8067225\ttotal: 57.4s\tremaining: 5.45s\n",
            "2393:\tlearn: 91.8005669\ttotal: 57.4s\tremaining: 5.42s\n",
            "2394:\tlearn: 91.7950756\ttotal: 57.5s\tremaining: 5.4s\n",
            "2395:\tlearn: 91.7810394\ttotal: 57.5s\tremaining: 5.37s\n",
            "2396:\tlearn: 91.7763274\ttotal: 57.5s\tremaining: 5.35s\n",
            "2397:\tlearn: 91.7691415\ttotal: 57.5s\tremaining: 5.33s\n",
            "2398:\tlearn: 91.7639699\ttotal: 57.5s\tremaining: 5.3s\n",
            "2399:\tlearn: 91.7566000\ttotal: 57.6s\tremaining: 5.28s\n",
            "2400:\tlearn: 91.7548551\ttotal: 57.6s\tremaining: 5.25s\n",
            "2401:\tlearn: 91.7459368\ttotal: 57.6s\tremaining: 5.23s\n",
            "2402:\tlearn: 91.7407373\ttotal: 57.6s\tremaining: 5.21s\n",
            "2403:\tlearn: 91.7300368\ttotal: 57.7s\tremaining: 5.18s\n",
            "2404:\tlearn: 91.7183896\ttotal: 57.7s\tremaining: 5.16s\n",
            "2405:\tlearn: 91.7141940\ttotal: 57.7s\tremaining: 5.13s\n",
            "2406:\tlearn: 91.7067967\ttotal: 57.7s\tremaining: 5.11s\n",
            "2407:\tlearn: 91.6878681\ttotal: 57.8s\tremaining: 5.08s\n",
            "2408:\tlearn: 91.6747820\ttotal: 57.8s\tremaining: 5.06s\n",
            "2409:\tlearn: 91.6658141\ttotal: 57.8s\tremaining: 5.04s\n",
            "2410:\tlearn: 91.6611229\ttotal: 57.8s\tremaining: 5.01s\n",
            "2411:\tlearn: 91.6498846\ttotal: 57.8s\tremaining: 4.99s\n",
            "2412:\tlearn: 91.6485223\ttotal: 57.9s\tremaining: 4.96s\n",
            "2413:\tlearn: 91.6451816\ttotal: 57.9s\tremaining: 4.94s\n",
            "2414:\tlearn: 91.6390712\ttotal: 57.9s\tremaining: 4.91s\n",
            "2415:\tlearn: 91.6279600\ttotal: 57.9s\tremaining: 4.89s\n",
            "2416:\tlearn: 91.6189335\ttotal: 57.9s\tremaining: 4.87s\n",
            "2417:\tlearn: 91.6150862\ttotal: 58s\tremaining: 4.84s\n",
            "2418:\tlearn: 91.6134542\ttotal: 58s\tremaining: 4.82s\n",
            "2419:\tlearn: 91.6105633\ttotal: 58s\tremaining: 4.79s\n",
            "2420:\tlearn: 91.6024048\ttotal: 58s\tremaining: 4.77s\n",
            "2421:\tlearn: 91.6000500\ttotal: 58.1s\tremaining: 4.75s\n",
            "2422:\tlearn: 91.5977296\ttotal: 58.1s\tremaining: 4.72s\n",
            "2423:\tlearn: 91.5957584\ttotal: 58.1s\tremaining: 4.7s\n",
            "2424:\tlearn: 91.5909416\ttotal: 58.1s\tremaining: 4.67s\n",
            "2425:\tlearn: 91.5869170\ttotal: 58.2s\tremaining: 4.65s\n",
            "2426:\tlearn: 91.5774817\ttotal: 58.2s\tremaining: 4.63s\n",
            "2427:\tlearn: 91.5697059\ttotal: 58.2s\tremaining: 4.6s\n",
            "2428:\tlearn: 91.5649620\ttotal: 58.3s\tremaining: 4.58s\n",
            "2429:\tlearn: 91.5599864\ttotal: 58.3s\tremaining: 4.56s\n",
            "2430:\tlearn: 91.5499668\ttotal: 58.3s\tremaining: 4.53s\n",
            "2431:\tlearn: 91.5419700\ttotal: 58.3s\tremaining: 4.51s\n",
            "2432:\tlearn: 91.5395060\ttotal: 58.4s\tremaining: 4.49s\n",
            "2433:\tlearn: 91.5298514\ttotal: 58.4s\tremaining: 4.46s\n",
            "2434:\tlearn: 91.5182174\ttotal: 58.4s\tremaining: 4.44s\n",
            "2435:\tlearn: 91.5141260\ttotal: 58.4s\tremaining: 4.41s\n",
            "2436:\tlearn: 91.5055986\ttotal: 58.4s\tremaining: 4.39s\n",
            "2437:\tlearn: 91.5048336\ttotal: 58.5s\tremaining: 4.37s\n",
            "2438:\tlearn: 91.4969003\ttotal: 58.5s\tremaining: 4.34s\n",
            "2439:\tlearn: 91.4901508\ttotal: 58.5s\tremaining: 4.32s\n",
            "2440:\tlearn: 91.4850388\ttotal: 58.5s\tremaining: 4.29s\n",
            "2441:\tlearn: 91.4796727\ttotal: 58.6s\tremaining: 4.27s\n",
            "2442:\tlearn: 91.4743503\ttotal: 58.6s\tremaining: 4.25s\n",
            "2443:\tlearn: 91.4729887\ttotal: 58.6s\tremaining: 4.22s\n",
            "2444:\tlearn: 91.4676724\ttotal: 58.7s\tremaining: 4.2s\n",
            "2445:\tlearn: 91.4597755\ttotal: 58.7s\tremaining: 4.17s\n",
            "2446:\tlearn: 91.4500703\ttotal: 58.7s\tremaining: 4.15s\n",
            "2447:\tlearn: 91.4457186\ttotal: 58.7s\tremaining: 4.13s\n",
            "2448:\tlearn: 91.4332076\ttotal: 58.7s\tremaining: 4.1s\n",
            "2449:\tlearn: 91.4256082\ttotal: 58.8s\tremaining: 4.08s\n",
            "2450:\tlearn: 91.4143590\ttotal: 58.8s\tremaining: 4.05s\n",
            "2451:\tlearn: 91.4134124\ttotal: 58.8s\tremaining: 4.03s\n",
            "2452:\tlearn: 91.3983633\ttotal: 58.9s\tremaining: 4.01s\n",
            "2453:\tlearn: 91.3893986\ttotal: 58.9s\tremaining: 3.98s\n",
            "2454:\tlearn: 91.3885958\ttotal: 58.9s\tremaining: 3.96s\n",
            "2455:\tlearn: 91.3828307\ttotal: 58.9s\tremaining: 3.93s\n",
            "2456:\tlearn: 91.3811713\ttotal: 59s\tremaining: 3.91s\n",
            "2457:\tlearn: 91.3739505\ttotal: 59s\tremaining: 3.89s\n",
            "2458:\tlearn: 91.3700910\ttotal: 59s\tremaining: 3.86s\n",
            "2459:\tlearn: 91.3592841\ttotal: 59s\tremaining: 3.84s\n",
            "2460:\tlearn: 91.3538519\ttotal: 59s\tremaining: 3.81s\n",
            "2461:\tlearn: 91.3461748\ttotal: 59.1s\tremaining: 3.79s\n",
            "2462:\tlearn: 91.3417088\ttotal: 59.1s\tremaining: 3.77s\n",
            "2463:\tlearn: 91.3331499\ttotal: 59.1s\tremaining: 3.74s\n",
            "2464:\tlearn: 91.3180724\ttotal: 59.2s\tremaining: 3.72s\n",
            "2465:\tlearn: 91.3091515\ttotal: 59.2s\tremaining: 3.69s\n",
            "2466:\tlearn: 91.3053386\ttotal: 59.2s\tremaining: 3.67s\n",
            "2467:\tlearn: 91.3033922\ttotal: 59.2s\tremaining: 3.65s\n",
            "2468:\tlearn: 91.2994412\ttotal: 59.3s\tremaining: 3.62s\n",
            "2469:\tlearn: 91.2940596\ttotal: 59.3s\tremaining: 3.6s\n",
            "2470:\tlearn: 91.2902662\ttotal: 59.3s\tremaining: 3.58s\n",
            "2471:\tlearn: 91.2856280\ttotal: 59.3s\tremaining: 3.55s\n",
            "2472:\tlearn: 91.2722012\ttotal: 59.4s\tremaining: 3.53s\n",
            "2473:\tlearn: 91.2714649\ttotal: 59.4s\tremaining: 3.5s\n",
            "2474:\tlearn: 91.2679398\ttotal: 59.4s\tremaining: 3.48s\n",
            "2475:\tlearn: 91.2660011\ttotal: 59.4s\tremaining: 3.46s\n",
            "2476:\tlearn: 91.2595079\ttotal: 59.5s\tremaining: 3.43s\n",
            "2477:\tlearn: 91.2569313\ttotal: 59.5s\tremaining: 3.41s\n",
            "2478:\tlearn: 91.2487944\ttotal: 59.5s\tremaining: 3.38s\n",
            "2479:\tlearn: 91.2363499\ttotal: 59.5s\tremaining: 3.36s\n",
            "2480:\tlearn: 91.2259222\ttotal: 59.6s\tremaining: 3.34s\n",
            "2481:\tlearn: 91.2166490\ttotal: 59.6s\tremaining: 3.31s\n",
            "2482:\tlearn: 91.2018195\ttotal: 59.6s\tremaining: 3.29s\n",
            "2483:\tlearn: 91.1992671\ttotal: 59.6s\tremaining: 3.26s\n",
            "2484:\tlearn: 91.1923792\ttotal: 59.6s\tremaining: 3.24s\n",
            "2485:\tlearn: 91.1921195\ttotal: 59.7s\tremaining: 3.22s\n",
            "2486:\tlearn: 91.1890426\ttotal: 59.7s\tremaining: 3.19s\n",
            "2487:\tlearn: 91.1865030\ttotal: 59.7s\tremaining: 3.17s\n",
            "2488:\tlearn: 91.1767453\ttotal: 59.7s\tremaining: 3.14s\n",
            "2489:\tlearn: 91.1716085\ttotal: 59.8s\tremaining: 3.12s\n",
            "2490:\tlearn: 91.1710366\ttotal: 59.8s\tremaining: 3.1s\n",
            "2491:\tlearn: 91.1647919\ttotal: 59.8s\tremaining: 3.07s\n",
            "2492:\tlearn: 91.1566376\ttotal: 59.8s\tremaining: 3.05s\n",
            "2493:\tlearn: 91.1502447\ttotal: 59.9s\tremaining: 3.02s\n",
            "2494:\tlearn: 91.1493562\ttotal: 59.9s\tremaining: 3s\n",
            "2495:\tlearn: 91.1446396\ttotal: 59.9s\tremaining: 2.98s\n",
            "2496:\tlearn: 91.1394411\ttotal: 59.9s\tremaining: 2.95s\n",
            "2497:\tlearn: 91.1327793\ttotal: 60s\tremaining: 2.93s\n",
            "2498:\tlearn: 91.1306982\ttotal: 60s\tremaining: 2.9s\n",
            "2499:\tlearn: 91.1223913\ttotal: 1m\tremaining: 2.88s\n",
            "2500:\tlearn: 91.1156911\ttotal: 1m\tremaining: 2.86s\n",
            "2501:\tlearn: 91.1124056\ttotal: 1m\tremaining: 2.83s\n",
            "2502:\tlearn: 91.1028745\ttotal: 1m\tremaining: 2.81s\n",
            "2503:\tlearn: 91.0858912\ttotal: 1m\tremaining: 2.79s\n",
            "2504:\tlearn: 91.0804544\ttotal: 1m\tremaining: 2.76s\n",
            "2505:\tlearn: 91.0702744\ttotal: 1m\tremaining: 2.74s\n",
            "2506:\tlearn: 91.0629660\ttotal: 1m\tremaining: 2.71s\n",
            "2507:\tlearn: 91.0580803\ttotal: 1m\tremaining: 2.69s\n",
            "2508:\tlearn: 91.0539656\ttotal: 1m\tremaining: 2.67s\n",
            "2509:\tlearn: 91.0501024\ttotal: 1m\tremaining: 2.64s\n",
            "2510:\tlearn: 91.0423778\ttotal: 1m\tremaining: 2.62s\n",
            "2511:\tlearn: 91.0399372\ttotal: 1m\tremaining: 2.59s\n",
            "2512:\tlearn: 91.0292661\ttotal: 1m\tremaining: 2.57s\n",
            "2513:\tlearn: 91.0174206\ttotal: 1m\tremaining: 2.55s\n",
            "2514:\tlearn: 91.0113174\ttotal: 1m\tremaining: 2.52s\n",
            "2515:\tlearn: 91.0033562\ttotal: 1m\tremaining: 2.5s\n",
            "2516:\tlearn: 90.9910977\ttotal: 1m\tremaining: 2.47s\n",
            "2517:\tlearn: 90.9858791\ttotal: 1m\tremaining: 2.45s\n",
            "2518:\tlearn: 90.9800175\ttotal: 1m\tremaining: 2.43s\n",
            "2519:\tlearn: 90.9746817\ttotal: 1m\tremaining: 2.4s\n",
            "2520:\tlearn: 90.9642459\ttotal: 1m\tremaining: 2.38s\n",
            "2521:\tlearn: 90.9563326\ttotal: 1m\tremaining: 2.35s\n",
            "2522:\tlearn: 90.9472205\ttotal: 1m\tremaining: 2.33s\n",
            "2523:\tlearn: 90.9375267\ttotal: 1m\tremaining: 2.31s\n",
            "2524:\tlearn: 90.9302783\ttotal: 1m\tremaining: 2.28s\n",
            "2525:\tlearn: 90.9213736\ttotal: 1m\tremaining: 2.26s\n",
            "2526:\tlearn: 90.8967291\ttotal: 1m\tremaining: 2.23s\n",
            "2527:\tlearn: 90.8916449\ttotal: 1m\tremaining: 2.21s\n",
            "2528:\tlearn: 90.8886779\ttotal: 1m\tremaining: 2.19s\n",
            "2529:\tlearn: 90.8794431\ttotal: 1m\tremaining: 2.16s\n",
            "2530:\tlearn: 90.8712121\ttotal: 1m\tremaining: 2.14s\n",
            "2531:\tlearn: 90.8622120\ttotal: 1m\tremaining: 2.11s\n",
            "2532:\tlearn: 90.8603017\ttotal: 1m\tremaining: 2.09s\n",
            "2533:\tlearn: 90.8274252\ttotal: 1m\tremaining: 2.06s\n",
            "2534:\tlearn: 90.8005698\ttotal: 1m\tremaining: 2.04s\n",
            "2535:\tlearn: 90.7940094\ttotal: 1m\tremaining: 2.02s\n",
            "2536:\tlearn: 90.7867428\ttotal: 1m\tremaining: 1.99s\n",
            "2537:\tlearn: 90.7842305\ttotal: 1m\tremaining: 1.97s\n",
            "2538:\tlearn: 90.7671951\ttotal: 1m\tremaining: 1.95s\n",
            "2539:\tlearn: 90.7586597\ttotal: 1m\tremaining: 1.92s\n",
            "2540:\tlearn: 90.7497708\ttotal: 1m 1s\tremaining: 1.9s\n",
            "2541:\tlearn: 90.7340895\ttotal: 1m 1s\tremaining: 1.87s\n",
            "2542:\tlearn: 90.7262621\ttotal: 1m 1s\tremaining: 1.85s\n",
            "2543:\tlearn: 90.7209521\ttotal: 1m 1s\tremaining: 1.82s\n",
            "2544:\tlearn: 90.7039422\ttotal: 1m 1s\tremaining: 1.8s\n",
            "2545:\tlearn: 90.6992798\ttotal: 1m 1s\tremaining: 1.78s\n",
            "2546:\tlearn: 90.6929138\ttotal: 1m 1s\tremaining: 1.75s\n",
            "2547:\tlearn: 90.6889927\ttotal: 1m 1s\tremaining: 1.73s\n",
            "2548:\tlearn: 90.6847562\ttotal: 1m 1s\tremaining: 1.71s\n",
            "2549:\tlearn: 90.6797862\ttotal: 1m 1s\tremaining: 1.68s\n",
            "2550:\tlearn: 90.6721383\ttotal: 1m 1s\tremaining: 1.66s\n",
            "2551:\tlearn: 90.6664770\ttotal: 1m 1s\tremaining: 1.63s\n",
            "2552:\tlearn: 90.6615497\ttotal: 1m 1s\tremaining: 1.61s\n",
            "2553:\tlearn: 90.6473668\ttotal: 1m 1s\tremaining: 1.58s\n",
            "2554:\tlearn: 90.6428618\ttotal: 1m 1s\tremaining: 1.56s\n",
            "2555:\tlearn: 90.6400884\ttotal: 1m 1s\tremaining: 1.54s\n",
            "2556:\tlearn: 90.6346578\ttotal: 1m 1s\tremaining: 1.51s\n",
            "2557:\tlearn: 90.6233128\ttotal: 1m 1s\tremaining: 1.49s\n",
            "2558:\tlearn: 90.6233128\ttotal: 1m 1s\tremaining: 1.46s\n",
            "2559:\tlearn: 90.6137136\ttotal: 1m 1s\tremaining: 1.44s\n",
            "2560:\tlearn: 90.6023166\ttotal: 1m 1s\tremaining: 1.42s\n",
            "2561:\tlearn: 90.5991414\ttotal: 1m 1s\tremaining: 1.39s\n",
            "2562:\tlearn: 90.5932832\ttotal: 1m 1s\tremaining: 1.37s\n",
            "2563:\tlearn: 90.5850194\ttotal: 1m 1s\tremaining: 1.34s\n",
            "2564:\tlearn: 90.5836205\ttotal: 1m 1s\tremaining: 1.32s\n",
            "2565:\tlearn: 90.5763783\ttotal: 1m 1s\tremaining: 1.3s\n",
            "2566:\tlearn: 90.5675356\ttotal: 1m 1s\tremaining: 1.27s\n",
            "2567:\tlearn: 90.5519623\ttotal: 1m 1s\tremaining: 1.25s\n",
            "2568:\tlearn: 90.5457669\ttotal: 1m 1s\tremaining: 1.22s\n",
            "2569:\tlearn: 90.5400423\ttotal: 1m 1s\tremaining: 1.2s\n",
            "2570:\tlearn: 90.5282156\ttotal: 1m 1s\tremaining: 1.18s\n",
            "2571:\tlearn: 90.5243817\ttotal: 1m 1s\tremaining: 1.15s\n",
            "2572:\tlearn: 90.5216908\ttotal: 1m 1s\tremaining: 1.13s\n",
            "2573:\tlearn: 90.5193798\ttotal: 1m 1s\tremaining: 1.1s\n",
            "2574:\tlearn: 90.5137241\ttotal: 1m 1s\tremaining: 1.08s\n",
            "2575:\tlearn: 90.5113751\ttotal: 1m 1s\tremaining: 1.06s\n",
            "2576:\tlearn: 90.5070437\ttotal: 1m 1s\tremaining: 1.03s\n",
            "2577:\tlearn: 90.5056865\ttotal: 1m 1s\tremaining: 1.01s\n",
            "2578:\tlearn: 90.4950247\ttotal: 1m 1s\tremaining: 984ms\n",
            "2579:\tlearn: 90.4850007\ttotal: 1m 1s\tremaining: 960ms\n",
            "2580:\tlearn: 90.4796558\ttotal: 1m 1s\tremaining: 936ms\n",
            "2581:\tlearn: 90.4726924\ttotal: 1m 1s\tremaining: 912ms\n",
            "2582:\tlearn: 90.4653018\ttotal: 1m 2s\tremaining: 888ms\n",
            "2583:\tlearn: 90.4625621\ttotal: 1m 2s\tremaining: 864ms\n",
            "2584:\tlearn: 90.4502830\ttotal: 1m 2s\tremaining: 840ms\n",
            "2585:\tlearn: 90.4447703\ttotal: 1m 2s\tremaining: 816ms\n",
            "2586:\tlearn: 90.4382049\ttotal: 1m 2s\tremaining: 792ms\n",
            "2587:\tlearn: 90.4290343\ttotal: 1m 2s\tremaining: 768ms\n",
            "2588:\tlearn: 90.4264215\ttotal: 1m 2s\tremaining: 744ms\n",
            "2589:\tlearn: 90.4180651\ttotal: 1m 2s\tremaining: 720ms\n",
            "2590:\tlearn: 90.4125363\ttotal: 1m 2s\tremaining: 696ms\n",
            "2591:\tlearn: 90.4059591\ttotal: 1m 2s\tremaining: 672ms\n",
            "2592:\tlearn: 90.4032552\ttotal: 1m 2s\tremaining: 648ms\n",
            "2593:\tlearn: 90.3980887\ttotal: 1m 2s\tremaining: 624ms\n",
            "2594:\tlearn: 90.3939403\ttotal: 1m 2s\tremaining: 600ms\n",
            "2595:\tlearn: 90.3853563\ttotal: 1m 2s\tremaining: 576ms\n",
            "2596:\tlearn: 90.3808850\ttotal: 1m 2s\tremaining: 552ms\n",
            "2597:\tlearn: 90.3769461\ttotal: 1m 2s\tremaining: 528ms\n",
            "2598:\tlearn: 90.3747525\ttotal: 1m 2s\tremaining: 504ms\n",
            "2599:\tlearn: 90.3736879\ttotal: 1m 2s\tremaining: 480ms\n",
            "2600:\tlearn: 90.3671743\ttotal: 1m 2s\tremaining: 456ms\n",
            "2601:\tlearn: 90.3648445\ttotal: 1m 2s\tremaining: 432ms\n",
            "2602:\tlearn: 90.3613829\ttotal: 1m 2s\tremaining: 408ms\n",
            "2603:\tlearn: 90.3519329\ttotal: 1m 2s\tremaining: 384ms\n",
            "2604:\tlearn: 90.3491635\ttotal: 1m 2s\tremaining: 360ms\n",
            "2605:\tlearn: 90.3405705\ttotal: 1m 2s\tremaining: 336ms\n",
            "2606:\tlearn: 90.3048047\ttotal: 1m 2s\tremaining: 312ms\n",
            "2607:\tlearn: 90.2929006\ttotal: 1m 2s\tremaining: 288ms\n",
            "2608:\tlearn: 90.2846066\ttotal: 1m 2s\tremaining: 264ms\n",
            "2609:\tlearn: 90.2764474\ttotal: 1m 2s\tremaining: 240ms\n",
            "2610:\tlearn: 90.2717248\ttotal: 1m 2s\tremaining: 216ms\n",
            "2611:\tlearn: 90.2651964\ttotal: 1m 2s\tremaining: 192ms\n",
            "2612:\tlearn: 90.2564367\ttotal: 1m 2s\tremaining: 168ms\n",
            "2613:\tlearn: 90.2507972\ttotal: 1m 2s\tremaining: 144ms\n",
            "2614:\tlearn: 90.2499574\ttotal: 1m 2s\tremaining: 120ms\n",
            "2615:\tlearn: 90.2480959\ttotal: 1m 2s\tremaining: 96.1ms\n",
            "2616:\tlearn: 90.2443004\ttotal: 1m 2s\tremaining: 72ms\n",
            "2617:\tlearn: 90.2325433\ttotal: 1m 2s\tremaining: 48ms\n",
            "2618:\tlearn: 90.2264895\ttotal: 1m 2s\tremaining: 24ms\n",
            "2619:\tlearn: 90.2238253\ttotal: 1m 2s\tremaining: 0us\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostRegressor at 0x22b032c8490>"
            ]
          },
          "execution_count": 358,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X = train.reset_index().set_index(\"date\").drop(\"total_amount\", axis = 1), \n",
        "          y = train.reset_index().set_index(\"date\")[\"total_amount\"], \n",
        "          cat_features = catfeat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 359,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.3897722499747835, 0.869910192762602)"
            ]
          },
          "execution_count": 359,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions_y = model.predict(val.reset_index().set_index(\"date\").drop(\"total_amount\", axis = 1))\n",
        "mean_absolute_percentage_error(y_true = val[\"total_amount\"], y_pred = predictions_y), r2_score(y_true = val[\"total_amount\"], y_pred = predictions_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 360,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>Store</th>\n",
              "      <th>Item_Category</th>\n",
              "      <th>Date</th>\n",
              "      <th>Observed</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>store_name</th>\n",
              "      <th>item_category</th>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">Altona</th>\n",
              "      <th rowspan=\"5\" valign=\"top\">classics</th>\n",
              "      <th>2024-05-18</th>\n",
              "      <td>Altona</td>\n",
              "      <td>classics</td>\n",
              "      <td>2024-05-18</td>\n",
              "      <td>30</td>\n",
              "      <td>-21.807070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-05-19</th>\n",
              "      <td>Altona</td>\n",
              "      <td>classics</td>\n",
              "      <td>2024-05-19</td>\n",
              "      <td>39</td>\n",
              "      <td>-29.163873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-05-20</th>\n",
              "      <td>Altona</td>\n",
              "      <td>classics</td>\n",
              "      <td>2024-05-20</td>\n",
              "      <td>30</td>\n",
              "      <td>64.827753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-05-21</th>\n",
              "      <td>Altona</td>\n",
              "      <td>classics</td>\n",
              "      <td>2024-05-21</td>\n",
              "      <td>17</td>\n",
              "      <td>20.985689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-05-22</th>\n",
              "      <td>Altona</td>\n",
              "      <td>classics</td>\n",
              "      <td>2024-05-22</td>\n",
              "      <td>52</td>\n",
              "      <td>-5.725597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">Warschauer</th>\n",
              "      <th rowspan=\"5\" valign=\"top\">specials</th>\n",
              "      <th>2024-05-20</th>\n",
              "      <td>Warschauer</td>\n",
              "      <td>specials</td>\n",
              "      <td>2024-05-20</td>\n",
              "      <td>344</td>\n",
              "      <td>312.901047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-05-21</th>\n",
              "      <td>Warschauer</td>\n",
              "      <td>specials</td>\n",
              "      <td>2024-05-21</td>\n",
              "      <td>149</td>\n",
              "      <td>253.116970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-05-22</th>\n",
              "      <td>Warschauer</td>\n",
              "      <td>specials</td>\n",
              "      <td>2024-05-22</td>\n",
              "      <td>202</td>\n",
              "      <td>143.875350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-05-23</th>\n",
              "      <td>Warschauer</td>\n",
              "      <td>specials</td>\n",
              "      <td>2024-05-23</td>\n",
              "      <td>138</td>\n",
              "      <td>188.245474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-05-24</th>\n",
              "      <td>Warschauer</td>\n",
              "      <td>specials</td>\n",
              "      <td>2024-05-24</td>\n",
              "      <td>157</td>\n",
              "      <td>201.750337</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>280 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          Store Item_Category       Date  \\\n",
              "store_name item_category date                                              \n",
              "Altona     classics      2024-05-18      Altona      classics 2024-05-18   \n",
              "                         2024-05-19      Altona      classics 2024-05-19   \n",
              "                         2024-05-20      Altona      classics 2024-05-20   \n",
              "                         2024-05-21      Altona      classics 2024-05-21   \n",
              "                         2024-05-22      Altona      classics 2024-05-22   \n",
              "...                                         ...           ...        ...   \n",
              "Warschauer specials      2024-05-20  Warschauer      specials 2024-05-20   \n",
              "                         2024-05-21  Warschauer      specials 2024-05-21   \n",
              "                         2024-05-22  Warschauer      specials 2024-05-22   \n",
              "                         2024-05-23  Warschauer      specials 2024-05-23   \n",
              "                         2024-05-24  Warschauer      specials 2024-05-24   \n",
              "\n",
              "                                     Observed   Predicted  \n",
              "store_name item_category date                              \n",
              "Altona     classics      2024-05-18        30  -21.807070  \n",
              "                         2024-05-19        39  -29.163873  \n",
              "                         2024-05-20        30   64.827753  \n",
              "                         2024-05-21        17   20.985689  \n",
              "                         2024-05-22        52   -5.725597  \n",
              "...                                       ...         ...  \n",
              "Warschauer specials      2024-05-20       344  312.901047  \n",
              "                         2024-05-21       149  253.116970  \n",
              "                         2024-05-22       202  143.875350  \n",
              "                         2024-05-23       138  188.245474  \n",
              "                         2024-05-24       157  201.750337  \n",
              "\n",
              "[280 rows x 5 columns]"
            ]
          },
          "execution_count": 360,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame({\"Store\":val.index.get_level_values(0), \n",
        "              \"Item_Category\":val.index.get_level_values(1), \n",
        "              \"Date\": val.index.get_level_values(2) ,\n",
        "              \"Observed\": val[\"total_amount\"],\n",
        "              \"Predicted\":predictions_y})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating validation dataset\n",
        "A validation set, containing the last 7 days of the entire training dataset, is created. The validation set is used for evaluation purposes and early stopping in the CatBoost model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "train, val = create_val_set(d2wind.reset_index())\n",
        "train = train.set_index([\"store_name\",\"item_category\",\"date\"]).sort_index()\n",
        "train = train.iloc[train.index.get_level_values(\"date\") >= pd.to_datetime(\"2021-07-12\")]\n",
        "val = val.set_index([\"store_name\",\"item_category\",\"date\"]).sort_index()\n",
        "\n",
        "for col in catfeat[2:]:\n",
        "    train[col] = train[col].apply(np.int64)\n",
        "    val[col] = val[col].apply(np.int64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Time-series cross-validation split**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When performing k-fold cross-validation in a time-series context, the data musn't be shuffled as in a regular cross-validation scenario. Instead, a forecasting horizon has to be defined for each fold, which serves as the validation set. It always comes after the training set chronologically. Because predicting donut sales for more than one week in advance is a difficult endeavor and will most likely lead to imprecise results, the forecasting horizon for this problem was set to 7 days."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 302,
      "metadata": {
        "id": "pfNYh71Coi6u"
      },
      "outputs": [],
      "source": [
        "def window_splitter_prep(train, validation_length, num_folds):\n",
        "    \n",
        "    def get_initial_window_size(store_group, validation_length, num_folds):\n",
        "        total_periods = len(store_group.index.get_level_values(\"date\").unique())\n",
        "        initial_window = total_periods - validation_length * num_folds\n",
        "        return initial_window\n",
        "\n",
        "    cv_list = []\n",
        "    \n",
        "    for (store,item), group in train.groupby([\"store_name\",\"item_category\"]):\n",
        "\n",
        "        # Calculate the initial window size for the current store\n",
        "        initial_window = get_initial_window_size(group, validation_length, num_folds)\n",
        "\n",
        "        # Initialize the ExpandingWindowSplitter for the current group\n",
        "        splitter = ExpandingWindowSplitter(\n",
        "            initial_window=initial_window,\n",
        "            step_length=7,\n",
        "            fh=list(range(1, 7 + 1))\n",
        "        )\n",
        "\n",
        "        cv_list.append(({f\"{store}\"+\"_\"+f\"{item}\":splitter},\n",
        "                            {f\"{store}\"+\"_\"+f\"{item}\":group}))\n",
        "    \n",
        "    return cv_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 303,
      "metadata": {},
      "outputs": [],
      "source": [
        "cv_list = window_splitter_prep(train, validation_length = 7, num_folds = 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The graph below depicts the time-series cross-validation process visually. The forecsasting horizon of 7 days from the first fold becomes part of the training set in the second cross-validation fold, while the next 7 days serve as the second validation set. Five folds were chosen in total, meaning there are 35 validation days on which the training data is evaluated. \n",
        "\n",
        "</br>\n",
        "\n",
        "**Note:** \n",
        "\n",
        "---\n",
        "\n",
        "When making time-series forecasting on a test dataset, predictions are often done recursively. This means that the model does not make predictions for all points in a forecasting horizon at once (7 days in this case), but does so day by day. The reason for that is that when window variables - such as lagged features or rolling averages of the target variable (donut sales) - are considered as explanatory variables, they won't actually exist in the test dataset. They are, in that case, calculated based on future target variable values which are yet to be predicted. \n",
        "\n",
        "This type of assessment will be performed on the testing dataset at the end of the notebook . However, the cross-validation process in this case would not only involve recursive predictions, but would also have to accommodate hierarchical data structures (i.e. one store per one product per one day). \n",
        "\n",
        "In order to simplify this task, no recursive predictions will be carried out on either of the five validation folds at this point. While this won't yield the most optimal predictions, performing time-series cross-validation can still produce good evaluation results.\n",
        "\n",
        "To make the resulst more rigorous, recursive forecasting in the cross-validation scenario should be executed in the future. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1600x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "for i in range(32,33):\n",
        "    plot_windows(list(cv_list[i][0].values())[0], list(cv_list[i][1].values())[0][\"total_amount\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Hyperparameter tuning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Given that CatBoost is a tree-based model, there is a large number of hyperparameters that can be tuned. For this task, the following hyperparameters were chosen:\n",
        "\n",
        "* Number of trees (estimators)\n",
        "* Learning rate\n",
        "* L2 leaf regularization\n",
        "* Tree depth\n",
        "* Percentage of datapoint to be used in each tree (bootstrapping)\n",
        "* Percentage of features to be used in each tree\n",
        "* Smallest number of data to be used in a leaf before a split is made"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_train_validation_folds(df):\n",
        "    last_val_date = df.date.max()\n",
        "    cv = []\n",
        "    for n in range(5):\n",
        "        first_val_date = last_val_date - dt.timedelta(days=6)\n",
        "        train_index = df[df.date<first_val_date].index\n",
        "        val_index = df[(df.date>=first_val_date) & (df.date<=last_val_date)].index\n",
        "        cv.append((train_index,val_index))\n",
        "        last_val_date = first_val_date - dt.timedelta(days=1)\n",
        "    cv = cv[::-1]\n",
        "    return cv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train = train.reset_index().drop(\"total_amount\", axis = 1)\n",
        "x_val = val.reset_index().drop(\"total_amount\", axis = 1).set_index(\"date\")\n",
        "y_train = train.reset_index()[[\"date\",\"total_amount\"]]\n",
        "y_val = val.reset_index()[[\"date\",\"total_amount\"]].set_index(\"date\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "aLuupIDyoi66"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 200, 3000),\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-4, 0.1, log=True),\n",
        "        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 2, 30),\n",
        "        \"depth\": trial.suggest_int(\"depth\", 5, 10),\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
        "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.1, 1.0),\n",
        "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 10, 100),\n",
        "        \"random_strength\": trial.suggest_float(\"random_strength\", 1, 10)\n",
        "    }\n",
        "    \n",
        "    scores = []\n",
        "    for train_idx, test_idx in create_train_validation_folds(x_train):\n",
        "        X_train_fold, X_val_fold = x_train.iloc[train_idx], x_train.iloc[test_idx]\n",
        "        y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
        "\n",
        "        X_train_fold = X_train_fold.set_index(\"date\")\n",
        "        X_val_fold = X_val_fold.set_index(\"date\")\n",
        "        y_train_fold = y_train_fold.set_index(\"date\")\n",
        "        y_val_fold = y_val_fold.set_index(\"date\")\n",
        "\n",
        "        model = CatBoostRegressor(**params, silent=True, allow_writing_files = False)\n",
        " \n",
        "        model.fit(X_train_fold, y_train_fold, eval_set = (x_val, y_val), early_stopping_rounds = 50, cat_features=catfeat)\n",
        "        \n",
        "        y_pred = model.predict(X_val_fold)\n",
        "\n",
        "        score = mean_squared_error(y_val_fold, y_pred, squared=False)\n",
        "        \n",
        "        scores.append(score)\n",
        "    \n",
        "    return np.mean(scores)\n",
        "\n",
        "    #cv_scores = cross_val_score(\n",
        "    #    model,\n",
        "    #    X_train,\n",
        "    #    y_train,\n",
        "    #    scoring='neg_root_mean_squared_error',  # for RMSE\n",
        "    #    cv=create_train_validation_folds(train.reset_index()),\n",
        "    #    n_jobs=-1,\n",
        "    #    error_score = \"raise\"\n",
        "    #)\n",
        "\n",
        "    # Return the mean of the negative RMSE scores, since Optuna maximizes by default\n",
        "    #return -np.mean(cv_scores)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-08-09 12:46:46,326] A new study created in memory with name: no-name-e02b4f96-ab99-457b-9045-1a37b41b3147\n",
            "[W 2024-08-09 12:46:46,568] Trial 1 failed with parameters: {'n_estimators': 1522, 'learning_rate': 0.04179238139310647, 'l2_leaf_reg': 14.90123100908092, 'depth': 5, 'subsample': 0.785190512292149, 'colsample_bylevel': 0.7941570542939638, 'min_data_in_leaf': 11, 'random_strength': 7.951727122387179} because of the following error: NameError(\"name 'y_train' is not defined\").\n",
            "Traceback (most recent call last):\n",
            "  File \"s:\\Repos\\sweet-spot-donut-sales-forecasting\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "                      ^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Flatko\\AppData\\Local\\Temp\\ipykernel_2140\\2714518449.py\", line 16, in objective\n",
            "    y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
            "                               ^^^^^^^\n",
            "NameError: name 'y_train' is not defined\n",
            "[W 2024-08-09 12:46:46,590] Trial 3 failed with parameters: {'n_estimators': 837, 'learning_rate': 0.012697165694297607, 'l2_leaf_reg': 29.303161715634868, 'depth': 10, 'subsample': 0.30584051728656075, 'colsample_bylevel': 0.9214495435680218, 'min_data_in_leaf': 36, 'random_strength': 8.414024240560602} because of the following error: NameError(\"name 'y_train' is not defined\").\n",
            "Traceback (most recent call last):\n",
            "  File \"s:\\Repos\\sweet-spot-donut-sales-forecasting\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "                      ^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Flatko\\AppData\\Local\\Temp\\ipykernel_2140\\2714518449.py\", line 16, in objective\n",
            "    y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
            "                               ^^^^^^^\n",
            "NameError: name 'y_train' is not defined\n",
            "[W 2024-08-09 12:46:46,597] Trial 0 failed with parameters: {'n_estimators': 2639, 'learning_rate': 0.06794003758904572, 'l2_leaf_reg': 7.620043265155671, 'depth': 7, 'subsample': 0.6316126512547816, 'colsample_bylevel': 0.7421722047224989, 'min_data_in_leaf': 33, 'random_strength': 4.468637529277611} because of the following error: NameError(\"name 'y_train' is not defined\").\n",
            "Traceback (most recent call last):\n",
            "  File \"s:\\Repos\\sweet-spot-donut-sales-forecasting\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "                      ^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Flatko\\AppData\\Local\\Temp\\ipykernel_2140\\2714518449.py\", line 16, in objective\n",
            "    y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
            "                               ^^^^^^^\n",
            "NameError: name 'y_train' is not defined\n",
            "[W 2024-08-09 12:46:46,601] Trial 1 failed with value None.\n",
            "[W 2024-08-09 12:46:46,614] Trial 2 failed with parameters: {'n_estimators': 934, 'learning_rate': 0.001270852473295424, 'l2_leaf_reg': 23.91364895481563, 'depth': 8, 'subsample': 0.6038732737566447, 'colsample_bylevel': 0.7627541762841636, 'min_data_in_leaf': 39, 'random_strength': 6.55762103865528} because of the following error: NameError(\"name 'y_train' is not defined\").\n",
            "Traceback (most recent call last):\n",
            "  File \"s:\\Repos\\sweet-spot-donut-sales-forecasting\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "                      ^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Flatko\\AppData\\Local\\Temp\\ipykernel_2140\\2714518449.py\", line 16, in objective\n",
            "    y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
            "                               ^^^^^^^\n",
            "NameError: name 'y_train' is not defined\n",
            "[W 2024-08-09 12:46:46,616] Trial 4 failed with parameters: {'n_estimators': 2760, 'learning_rate': 0.0018225480091923112, 'l2_leaf_reg': 17.45712877818797, 'depth': 6, 'subsample': 0.23564362447946124, 'colsample_bylevel': 0.7264439409378706, 'min_data_in_leaf': 27, 'random_strength': 2.6830722038754873} because of the following error: NameError(\"name 'y_train' is not defined\").\n",
            "Traceback (most recent call last):\n",
            "  File \"s:\\Repos\\sweet-spot-donut-sales-forecasting\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "                      ^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Flatko\\AppData\\Local\\Temp\\ipykernel_2140\\2714518449.py\", line 16, in objective\n",
            "    y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
            "                               ^^^^^^^\n",
            "NameError: name 'y_train' is not defined\n",
            "[W 2024-08-09 12:46:46,616] Trial 5 failed with parameters: {'n_estimators': 1420, 'learning_rate': 0.00018357646874845123, 'l2_leaf_reg': 16.01749430508239, 'depth': 9, 'subsample': 0.45596656349963977, 'colsample_bylevel': 0.4254212102391254, 'min_data_in_leaf': 54, 'random_strength': 8.871572224279126} because of the following error: NameError(\"name 'y_train' is not defined\").\n",
            "Traceback (most recent call last):\n",
            "  File \"s:\\Repos\\sweet-spot-donut-sales-forecasting\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "                      ^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Flatko\\AppData\\Local\\Temp\\ipykernel_2140\\2714518449.py\", line 16, in objective\n",
            "    y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
            "                               ^^^^^^^\n",
            "NameError: name 'y_train' is not defined\n",
            "[W 2024-08-09 12:46:46,617] Trial 3 failed with value None.\n",
            "[W 2024-08-09 12:46:46,623] Trial 0 failed with value None.\n",
            "[W 2024-08-09 12:46:46,629] Trial 7 failed with parameters: {'n_estimators': 1367, 'learning_rate': 0.009312693170442117, 'l2_leaf_reg': 25.755002368281797, 'depth': 9, 'subsample': 0.44539639470281656, 'colsample_bylevel': 0.46643509629187296, 'min_data_in_leaf': 82, 'random_strength': 8.78692151347845} because of the following error: NameError(\"name 'y_train' is not defined\").\n",
            "Traceback (most recent call last):\n",
            "  File \"s:\\Repos\\sweet-spot-donut-sales-forecasting\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "                      ^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Flatko\\AppData\\Local\\Temp\\ipykernel_2140\\2714518449.py\", line 16, in objective\n",
            "    y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
            "                               ^^^^^^^\n",
            "NameError: name 'y_train' is not defined\n",
            "[W 2024-08-09 12:46:46,630] Trial 6 failed with parameters: {'n_estimators': 2584, 'learning_rate': 0.0096219973006125, 'l2_leaf_reg': 10.539274652534752, 'depth': 5, 'subsample': 0.15380523306896665, 'colsample_bylevel': 0.23197649143484303, 'min_data_in_leaf': 76, 'random_strength': 5.346063994093731} because of the following error: NameError(\"name 'y_train' is not defined\").\n",
            "Traceback (most recent call last):\n",
            "  File \"s:\\Repos\\sweet-spot-donut-sales-forecasting\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "                      ^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Flatko\\AppData\\Local\\Temp\\ipykernel_2140\\2714518449.py\", line 16, in objective\n",
            "    y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
            "                               ^^^^^^^\n",
            "NameError: name 'y_train' is not defined\n",
            "[W 2024-08-09 12:46:46,635] Trial 2 failed with value None.\n",
            "[W 2024-08-09 12:46:46,638] Trial 4 failed with value None.\n",
            "[W 2024-08-09 12:46:46,642] Trial 5 failed with value None.\n",
            "[W 2024-08-09 12:46:46,648] Trial 7 failed with value None.\n",
            "[W 2024-08-09 12:46:46,652] Trial 6 failed with value None.\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'y_train' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32ms:\\Repos\\sweet-spot-donut-sales-forecasting\\.venv\\Lib\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32ms:\\Repos\\sweet-spot-donut-sales-forecasting\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:99\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     97\u001b[0m                     \u001b[38;5;66;03m# Raise if exception occurred in executing the completed futures.\u001b[39;00m\n\u001b[0;32m     98\u001b[0m                     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m completed:\n\u001b[1;32m---> 99\u001b[0m                         \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m                 futures\u001b[38;5;241m.\u001b[39madd(\n\u001b[0;32m    102\u001b[0m                     executor\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[0;32m    103\u001b[0m                         _optimize_sequential,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    114\u001b[0m                     )\n\u001b[0;32m    115\u001b[0m                 )\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
            "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.11.3\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
            "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.11.3\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.11.3\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
            "File \u001b[1;32ms:\\Repos\\sweet-spot-donut-sales-forecasting\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
            "File \u001b[1;32ms:\\Repos\\sweet-spot-donut-sales-forecasting\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    246\u001b[0m ):\n\u001b[1;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
            "File \u001b[1;32ms:\\Repos\\sweet-spot-donut-sales-forecasting\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
            "Cell \u001b[1;32mIn[17], line 16\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_idx, test_idx \u001b[38;5;129;01min\u001b[39;00m create_train_validation_folds(x_train):\n\u001b[0;32m     15\u001b[0m     X_train_fold, X_val_fold \u001b[38;5;241m=\u001b[39m x_train\u001b[38;5;241m.\u001b[39miloc[train_idx], x_train\u001b[38;5;241m.\u001b[39miloc[test_idx]\n\u001b[1;32m---> 16\u001b[0m     y_train_fold, y_val_fold \u001b[38;5;241m=\u001b[39m \u001b[43my_train\u001b[49m\u001b[38;5;241m.\u001b[39miloc[train_idx], y_train\u001b[38;5;241m.\u001b[39miloc[test_idx]\n\u001b[0;32m     18\u001b[0m     X_train_fold \u001b[38;5;241m=\u001b[39m X_train_fold\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m     X_val_fold \u001b[38;5;241m=\u001b[39m X_val_fold\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'y_train' is not defined"
          ]
        }
      ],
      "source": [
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials = 15, n_jobs = -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIE8SOQKoi66"
      },
      "outputs": [],
      "source": [
        "print('Best hyperparameters:', study.best_params)\n",
        "print('Best RMSE:', study.best_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36c_rmMAoi68"
      },
      "outputs": [],
      "source": [
        "# Best model\n",
        "\n",
        "model = CatBoostRegressor(n_estimators = 2620, learning_rate = 0.0487,\n",
        " depth = 5, subsample = 0.21, colsample_bylevel = 0.2, min_data_in_leaf = 21, early_stopping_rounds = 69, cat_features = catfeat, random_state = 123, allow_writing_files = True)\n",
        "\n",
        "model.fit(x_train_daily, y_train_daily, eval_set=(x_val_daily, y_val_daily), verbose = 500, plot = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LoTtLlOoi69"
      },
      "source": [
        "### Feature importances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOIGICEyoi69"
      },
      "outputs": [],
      "source": [
        "model.get_feature_importance(prettified=True).plot(x = \"Feature Id\", y = \"Importances\", kind = \"bar\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgJmAhqKoi69"
      },
      "source": [
        "### Evaluation metrics train and validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "geVnLFssoi6-"
      },
      "outputs": [],
      "source": [
        "y_train_pred = model.predict(x_train_daily)\n",
        "print(f\"R-squared train: {round(r2_score(y_train_daily, y_train_pred),6)}\")\n",
        "print(f\"MAPE train: {round(100*mean_absolute_percentage_error(y_train_daily, y_train_pred),2)}\\n\")\n",
        "\n",
        "y_val_pred = model.predict(x_val_daily)\n",
        "print(f\"R-squared validation: {round(r2_score(y_val_daily, y_val_pred),6)}\")\n",
        "print(f\"MAPE validation: {round(100*mean_absolute_percentage_error(y_val_daily, y_val_pred),2)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZTlpJtAoi6-"
      },
      "source": [
        "# Test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPZ_KJhloi7A"
      },
      "outputs": [],
      "source": [
        "x_test_daily_totalamount, y_test_pred =  pred_test(train = train_daily, test = test_daily, model = model, numfeat = numfeat, catfeat = catfeat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8k7U11Poi7A"
      },
      "source": [
        "### Residuals by store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JERZYZkxoi7A"
      },
      "outputs": [],
      "source": [
        "difference_df = diff_overview(data = test_daily, pred = y_test_pred, stores = all)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQe_0aPnoi7B"
      },
      "source": [
        "### Residual Plot Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qddwngE_oi7B"
      },
      "outputs": [],
      "source": [
        "sns.scatterplot(data = difference_df, x = \"Predicted\", y = \"Stand_resid\")\n",
        "\n",
        "plt.axhline(y=0, color='r', linestyle='--')\n",
        "plt.xlabel(\"Predicted Sales (Daily total)\")\n",
        "plt.ylabel(\"Standardized Residuals\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6kBZhTgoi7B"
      },
      "source": [
        "### Evaluation metrics train and test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bb4e769oi7C"
      },
      "outputs": [],
      "source": [
        "fit_overview(ytrain = y_train_daily, ytrainpred = y_train_pred, ytest = y_test_daily, ytestpred = y_test_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yhkYtTloi7C"
      },
      "outputs": [],
      "source": [
        "mape_stores(test_daily, y_test_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VgXSXAUoi7C"
      },
      "source": [
        "### Visualisation of predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cntd3c1Zoi7D"
      },
      "outputs": [],
      "source": [
        "df_predicted = pd.concat(\n",
        "    [\n",
        "    difference_df[[\"Date\",\"Store name\",\"Observed\",\"Predicted\"]].rename(columns = {\"Date\":\"date\",\"Store name\":\"store_name\",\"Observed\":\"total_amount\"}),\n",
        "    d[(d[\"date\"] >= pd.to_datetime(\"2024-05-01\")) & (d[\"item_category\"] == \"daily total\")][[\"date\",\"store_name\",\"total_amount\"]]\n",
        "    ]\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7q68bfB-oi7D"
      },
      "outputs": [],
      "source": [
        "ts_predicted(df_predicted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_train_validation_dataset(df):\n",
        "    last_val_date = df.date.max()\n",
        "    cv = []\n",
        "    for n in range(5):\n",
        "        first_val_date = last_val_date - dt.timedelta(days=6)\n",
        "        train_fold = df[df.date<first_val_date]\n",
        "        val_fold = df[(df.date>=first_val_date) & (df.date<=last_val_date)]\n",
        "        cv.append((train_fold,val_fold))\n",
        "        last_val_date = first_val_date - dt.timedelta(days=1)\n",
        "    cv = cv[::-1]\n",
        "    return cv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(5):\n",
        "  globals()[f\"train_{i}\"], globals()[f\"val_{i}\"] = create_train_validation_dataset(train_daily)[i]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
