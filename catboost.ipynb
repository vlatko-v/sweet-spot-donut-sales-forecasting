{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Catboost Modelling\"\n",
        "author: \"Alex, Rachel, Vlatko, Malte\"\n",
        "date: \"2024-06-20\"\n",
        "format: html\n",
        "execute: \n",
        "  cache: true\n",
        "  echo: false\n",
        "  error: true\n",
        "jupyter: python3\n",
        "editor:\n",
        "  render-on-save: true\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as md\n",
        "from matplotlib.patches import Patch\n",
        "import seaborn as sns\n",
        "import datetime as dt\n",
        "\n",
        "from sklearn.impute import SimpleImputer, KNNImputer \n",
        "from sklearn.preprocessing import OneHotEncoder, RobustScaler, FunctionTransformer, PolynomialFeatures, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import cross_validate, RandomizedSearchCV\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.metrics import mean_absolute_percentage_error, r2_score, mean_squared_error\n",
        "\n",
        "from sklearn.model_selection import TimeSeriesSplit, StratifiedKFold\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "\n",
        "from catboost import CatBoostRegressor\n",
        "import catboost as cb\n",
        "from xgboost import XGBRegressor\n",
        "import optuna "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%run functions_model.py\n",
        "%run functions_vis.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "! jupyter nbextension enable widgetsnbextension --py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pd.set_option(\"display.max_columns\", None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "d = pd.read_csv(\"data/train_df.csv\")\n",
        "d_test = pd.read_csv(\"data/test_df.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "d['date'] = pd.to_datetime(d['date'])\n",
        "d_test['date'] = pd.to_datetime(d_test['date'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Creating validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "train, val = create_val_set(d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modelling\n",
        "\n",
        "## Catboost\n",
        "\n",
        "### Selecting features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "date = [\"date\"]\n",
        "\n",
        "catfeat = [\"store_name\",\"item_category\",\"hol_pub\",\"hol_school\",\"weekday\",\"day\",\"month\",\"year\",\"week_year\",\"nye\",\"valentines_day\",\"halloween\", \"street_market\",\"public_space\",\"box_deal\"]\n",
        "\n",
        "numfeat = [\"days_back\",\"temperature_2m_mean\",\"sunshine_duration\",\"precipitation_hours\"]\n",
        "\n",
        "lag = [\"lag1\",\"lag2\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "x_train = train[date + catfeat + numfeat + lag]\n",
        "x_train = x_train.set_index(\"date\")\n",
        "x_train_daily = x_train[(x_train[\"item_category\"] == \"daily total\")].drop(\"item_category\", axis = 1)\n",
        "y_train = train['total_amount']\n",
        "y_train_daily = train[(train[\"item_category\"] == \"daily total\")]['total_amount']\n",
        "\n",
        "x_val = val[date + catfeat + numfeat + lag]\n",
        "x_val = x_val.set_index(\"date\")\n",
        "x_val_daily = x_val[(x_val[\"item_category\"] == \"daily total\")].drop(\"item_category\", axis = 1)\n",
        "y_val = val['total_amount']\n",
        "y_val_daily = val[(val[\"item_category\"] == \"daily total\") ]['total_amount']\n",
        "\n",
        "x_test = d_test[date + catfeat + numfeat]\n",
        "x_test = x_test.set_index(\"date\")\n",
        "x_test_daily = x_test[(x_test[\"item_category\"] == \"daily total\")].drop(\"item_category\", axis = 1)\n",
        "y_test = d_test['total_amount']\n",
        "y_test_daily = d_test[(d_test[\"item_category\"] == \"daily total\")]['total_amount']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "catfeat.remove(\"item_category\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Convert holiday features to integer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "x_train[\"hol_pub\"] = x_train[\"hol_pub\"].apply(np.int64)\n",
        "x_train[\"hol_school\"] = x_train[\"hol_school\"].apply(np.int64)\n",
        "x_train_daily[\"hol_pub\"] = x_train_daily[\"hol_pub\"].apply(np.int64)\n",
        "x_train_daily[\"hol_school\"] = x_train_daily[\"hol_school\"].apply(np.int64)\n",
        "\n",
        "x_val[\"hol_pub\"] = x_val[\"hol_pub\"].apply(np.int64)\n",
        "x_val[\"hol_school\"] = x_val[\"hol_school\"].apply(np.int64)\n",
        "x_val_daily[\"hol_pub\"] = x_val_daily[\"hol_pub\"].apply(np.int64)\n",
        "x_val_daily[\"hol_school\"] = x_val_daily[\"hol_school\"].apply(np.int64)\n",
        "\n",
        "x_test[\"hol_pub\"] = x_test[\"hol_pub\"].apply(np.int64)\n",
        "x_test[\"hol_school\"] = x_test[\"hol_school\"].apply(np.int64)\n",
        "x_test_daily[\"hol_pub\"] = x_test_daily[\"hol_pub\"].apply(np.int64)\n",
        "x_test_daily[\"hol_school\"] = x_test_daily[\"hol_school\"].apply(np.int64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "x_train_daily_totalamount = pd.concat([x_train_daily.reset_index(), y_train_daily.reset_index(drop= True)], axis = 1)\n",
        "\n",
        "x_test_daily_totalamount = pd.concat([x_test_daily.reset_index(), y_test_daily.reset_index(drop= True)], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Custom CV split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def create_train_validation_folds(df):\n",
        "    last_val_date = df.date.max()\n",
        "    cv = []\n",
        "    for n in range(5):\n",
        "        first_val_date = last_val_date - dt.timedelta(days=6)\n",
        "        train_index = df[df.date<first_val_date].index\n",
        "        val_index = df[(df.date>=first_val_date) & (df.date<=last_val_date)].index\n",
        "        cv.append((train_index,val_index))\n",
        "        last_val_date = first_val_date - dt.timedelta(days=1)\n",
        "    cv = cv[::-1]\n",
        "    return cv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "create_train_validation_folds(x_train_daily_totalamount)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def create_train_validation_dataset(df):\n",
        "    last_val_date = df.date.max()\n",
        "    cv = []\n",
        "    for n in range(5):\n",
        "        first_val_date = last_val_date - dt.timedelta(days=6)\n",
        "        train_fold = df[df.date<first_val_date]\n",
        "        val_fold = df[(df.date>=first_val_date) & (df.date<=last_val_date)]\n",
        "        cv.append((train_fold,val_fold))\n",
        "        last_val_date = first_val_date - dt.timedelta(days=1)\n",
        "    cv = cv[::-1]\n",
        "    return cv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for i in range(5):\n",
        "  globals()[f\"train_{i}\"], globals()[f\"val_{i}\"] = create_train_validation_dataset(x_train_daily_totalamount)[i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "val_4.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "train_val_datasets = [\n",
        "    (\"0\", train_0, val_0),\n",
        "    (\"1\", train_1, val_1),\n",
        "    (\"2\", train_2, val_2),\n",
        "    (\"3\", train_3, val_3),\n",
        "    (\"4\", train_4, val_4)\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for set, train, val:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hyperparameter Tuning\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid = {\n",
        "    'n_estimators': np.arange(1000,5001,1),\n",
        "    \"learning_rate\": np.linspace(1e-3, 0.1),\n",
        "    \"l2_leaf_reg\": np.linspace(2, 30),\n",
        "    \"depth\":np.arange(3,21,1),\n",
        "    \"subsample\": np.linspace(0.05, 1.0),\n",
        "    \"colsample_bylevel\": np.linspace(0.05, 1.0),\n",
        "    \"min_data_in_leaf\": np.arange(10, 101, 1),\n",
        "    #\"min_child_weight\": np.arange(1, 301, 1),\n",
        "    \"early_stopping_rounds\": np.arange(20, 81, 1)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = cb.CatBoostRegressor(cat_features=catfeat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "randomized_search_result = model.randomized_search(grid,\n",
        "                                                  # n_iter=30,\n",
        "                                                   X=x_train_daily,\n",
        "                                                   y=y_train_daily,\n",
        "                                                   cv = create_train_validation_folds(x_train_daily_totalamount),\n",
        "                                                   plot=True,\n",
        "                                                   verbose = 500,\n",
        "                                                   calc_cv_statistics=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pd.DataFrame(randomized_search_result.get(\"cv_results\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "randomized_search_result.get(\"params\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#def objective(trial):\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 3000),\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.3, log=True),\n",
        "        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 2, 30),\n",
        "        \"depth\": trial.suggest_int(\"depth\", 1, 10),\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
        "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.05, 1.0),\n",
        "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 100),\n",
        "        \"min_child_weight\": trial.suggest_int(1, 300),\n",
        "        \"early_stopping_rounds\": trial.suggest_int(\"early_stopping_rounds\", 50, 80)\n",
        "    }\n",
        "\n",
        "    model = CatBoostRegressor(**params, silent=True, allow_writing_files = False, cat_features = catfeatures)\n",
        "\n",
        "    model_cv = optuna.integration.OptunaSearchCV(estimator = model, param_distributions = params, cv = create_train_validation_folds(x_train_daily_totalamount), n_jobs = -1, n_trials = 30)\n",
        "    \n",
        "    #model.fit(x_train_daily, y_train_daily, eval_set = (create_train_validation_folds_cat(x_train_daily_totalamount)), cat_features = catfeat, verbose = 1000, plot = False)\n",
        "\n",
        "    # y_val_pred_daily = model_cv.predict(x_val_daily)\n",
        "    \n",
        "    #rmse = mean_squared_error(y_val_daily, y_val_pred_daily, squared=False)\n",
        "\n",
        "    #return rmse\n",
        "\n",
        "#study = optuna.create_study(direction='minimize')\n",
        "#study.optimize(objective, n_trials=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print('Best hyperparameters:', study.best_params)\n",
        "print('Best RMSE:', study.best_value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Best model\n",
        "\n",
        "model = CatBoostRegressor(n_estimators = 2620, learning_rate = 0.0487,\n",
        " depth = 5, subsample = 0.21, colsample_bylevel = 0.2, min_data_in_leaf = 21, early_stopping_rounds = 69, cat_features = catfeat, random_state = 123, allow_writing_files = True)\n",
        "\n",
        "model.fit(x_train_daily, y_train_daily, eval_set=(x_val_daily, y_val_daily), verbose = 500, plot = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Feature importances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model.get_feature_importance(prettified=True).plot(x = \"Feature Id\", y = \"Importances\", kind = \"bar\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluation metrics train and validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y_train_pred = model.predict(x_train_daily)\n",
        "print(f\"R-squared train: {round(r2_score(y_train_daily, y_train_pred),6)}\")\n",
        "print(f\"MAPE train: {round(100*mean_absolute_percentage_error(y_train_daily, y_train_pred),2)}\\n\")\n",
        "\n",
        "y_val_pred = model.predict(x_val_daily)\n",
        "print(f\"R-squared validation: {round(r2_score(y_val_daily, y_val_pred),6)}\")\n",
        "print(f\"MAPE validation: {round(100*mean_absolute_percentage_error(y_val_daily, y_val_pred),2)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "x_test_daily_totalamount, y_test_pred =  pred_test(train = x_train_daily_totalamount, test = x_test_daily_totalamount, model = model, numfeat = numfeat, catfeat = catfeat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Residuals by store"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "difference_df = diff_overview(data = x_test_daily_totalamount, pred = y_test_pred, stores = all)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Residual Plot Analysis "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sns.scatterplot(data = difference_df, x = \"Predicted\", y = \"Stand_resid\")\n",
        "\n",
        "plt.axhline(y=0, color='r', linestyle='--')\n",
        "plt.xlabel(\"Predicted Sales (Daily total)\")\n",
        "plt.ylabel(\"Standardized Residuals\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluation metrics train and test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit_overview(ytrain = y_train_daily, ytrainpred = y_train_pred, ytest = y_test_daily, ytestpred = y_test_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mape_stores(x_test_daily_totalamount, y_test_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualisation of predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_predicted = pd.concat(\n",
        "    [\n",
        "    difference_df[[\"Date\",\"Store name\",\"Observed\",\"Predicted\"]].rename(columns = {\"Date\":\"date\",\"Store name\":\"store_name\",\"Observed\":\"total_amount\"}),\n",
        "    d[(d[\"date\"] >= pd.to_datetime(\"2024-05-01\")) & (d[\"item_category\"] == \"daily total\")][[\"date\",\"store_name\",\"total_amount\"]]\n",
        "    ]\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ts_predicted(df_predicted)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "S:\\Repos\\sweet-spot-donut-sales-forecasting\\.venv\\share\\jupyter\\kernels\\python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}