{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Linear Regression Modelling\n","\n","The linear regression model is a comparatively simple, yet sophisticated algorithm that can be used for predicting continuous target variables. Because it is not as powerful as the other two models used in the project, the linear regression will serve as a baseline model against which the other two models' results will be compared.\n","\n","The following evaluation metrics are used to assess the model's performance:\n","\n","* R-squared\n","* Mean Absolute Percentage Error (MAPE)\n","\n","The reasoning behind their selection is described in the notebook with the CatBoost model."]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import OneHotEncoder, RobustScaler, FunctionTransformer, PolynomialFeatures\n","from sklearn.model_selection import cross_validate\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline, make_pipeline\n","from sklearn.linear_model import LinearRegression, Ridge, Lasso\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import r2_score\n","from sklearn.metrics import mean_absolute_percentage_error\n","\n","from sktime.transformations.series.summarize import WindowSummarizer"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["%run functions_model.py\n","%run functions_vis.py"]},{"cell_type":"markdown","metadata":{},"source":["### Loading the dataset"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["d = pd.read_csv(\"data/train_df.csv\", parse_dates=[0])\n","d_test = pd.read_csv(\"data/test_df.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## Modelling \n","#### Selecting and defining features "]},{"cell_type":"markdown","metadata":{},"source":["The following features were selected to be included in the baseline model:\n","\n","* Item Category\n","* Store\n","* Weather \n","    * Temperature\n","    * Precipitation\n","    * Sunshine duration\n","* Time variables:\n","    * Timestep (number of days since the first recorded sale)\n","    * Day of the year\n","    * Weekday\n","    * Week of the year \n","    * Month\n","    * Year\n","* Window variables\n","    * Lagged features\n","    * Rolling averages\n","    * Rolling standard deviation\n","* Special events \n","    * New Year's Eve\n","    * Halloween\n","    * Valentine's Day\n","* Public Space dummy variable\n","* Public holidays\n","* Street market dummy variable\n","\n","</br>\n","\n"," Because the variable \"school holidays\" does not seem to significantly impact sales  (p-value in Visualisation notebook), it was not included in the dataset. All the other variables are likely to influence sales to a certain degree. For more information, please refer to the Visualisation notebook."]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["date = [\"date\"]\n","\n","numfeat =[\"days_back\",\"temperature_2m_mean\",\"sunshine_duration\",\"precipitation_hours\"]\n","\n","catfeat = [\"store_name\",\"item_category\", 'day', 'halloween', 'hol_pub', 'month', 'nye', 'public_space', 'street_market', 'valentines_day','week_year', 'weekday', 'year']"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["d2 = d[date + catfeat + numfeat + [\"total_amount\"]]\n","d_test2 = d_test[date + catfeat + numfeat + [\"total_amount\"]]\n"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["agg_columns = d2.columns.difference(['date', 'store_name', 'item_category'] + [\"total_amount\"])\n","agg_dict = {col: \"first\" for col in agg_columns}\n","agg_dict[\"total_amount\"] = \"sum\"\n","\n","d2 = d2.groupby(['date', 'store_name', 'item_category']).agg(agg_dict).reset_index().sort_values(by = \"date\", ascending = False).reset_index(drop = True)\n","d2[\"hol_pub\"] = d2[\"hol_pub\"].apply(np.int64)\n","\n","d2 = d2.set_index([\"store_name\",\"item_category\",\"date\"]).sort_index()\n","\n","d_test2 = d_test2.groupby(['date', 'store_name', 'item_category']).agg(agg_dict).reset_index().sort_values(by = \"date\", ascending = False).reset_index(drop = True)\n","d_test2[\"hol_pub\"] = d_test2[\"hol_pub\"].apply(np.int64)\n","\n","d_test2 = d_test2.set_index([\"store_name\",\"item_category\",\"date\"]).sort_index()"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["kwargs = {\"lag_feature\": {\n","    \"lag\":[1,2,3],\n","    \"mean\": [[1,7], [1, 15], [1,30]],\n","    \"std\": [[1,4]]\n","    },\n","    \"target_cols\":[\"total_amount\"]}\n","\n","transformer = WindowSummarizer(**kwargs, n_jobs= -1)"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["d2wind = transformer.fit_transform(d2)\n","d2wind = pd.concat([d2[\"total_amount\"], d2wind], axis = 1).dropna()"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"data":{"text/plain":["Index(['total_amount', 'total_amount_lag_1', 'total_amount_lag_2',\n","       'total_amount_lag_3', 'total_amount_mean_1_7', 'total_amount_mean_1_15',\n","       'total_amount_mean_1_30', 'total_amount_std_1_4', 'day', 'days_back',\n","       'halloween', 'hol_pub', 'month', 'nye', 'precipitation_hours',\n","       'public_space', 'street_market', 'sunshine_duration',\n","       'temperature_2m_mean', 'valentines_day', 'week_year', 'weekday',\n","       'year'],\n","      dtype='object')"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["d2wind.columns"]},{"cell_type":"markdown","metadata":{},"source":["### Transforming features\n","\n","In order for the linear regression model to work properly, some additional feature preprocessing is necessary. This includes the following transformations of the variables:\n","\n","* Scaling numerical variables, including window variables\n","* Adding polynomial features (i.e. squaring and interactions of numerical features, excluding window variables)\n","* One-hot-encoding of categorical features\n","* Log transforming the target variable"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["num_tr =Pipeline(\n","  steps=[\n","    (\"scaling\", RobustScaler()),\n","    (\"polyint\",PolynomialFeatures(3,include_bias=False))\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cat_tr =Pipeline(steps=[\n","  (\"ohe\", OneHotEncoder(drop='first',sparse_output=False))\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["wind_tr =Pipeline(\n","    steps=[(\"scaling\", RobustScaler())]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["prepro =ColumnTransformer(\n","  transformers=[\n","    (\"num\", num_tr, numfeat),\n","    (\"cat\",cat_tr,catfeat),\n","    (\"wind_tr\", wind_tr,['total_amount_lag_1', 'total_amount_lag_2',\n","       'total_amount_lag_3', 'total_amount_mean_1_7', 'total_amount_mean_1_15',\n","       'total_amount_mean_1_30', 'total_amount_std_1_4'])\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["### Time-series cross-validation\n","\n","For more on how time-series k-fold cross validation is performed, please refer to the CatBoost model notebook."]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["train = d2wind.sample(frac=1, random_state=21)"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["x_train = train.reset_index().drop(\"total_amount\", axis = 1).set_index(\"date\")\n","y_train = train.reset_index()[[\"date\",\"total_amount\"]].set_index(\"date\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["model fit and prediction "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["lr =Pipeline(\n","  steps=[\n","    (\"prepro\", prepro),\n","    (\"lr\",LinearRegression())])\n","lr.fit(xtrain,ytrain)\n","ytrainpred =lr.predict(xtrain)"]},{"cell_type":"markdown","metadata":{},"source":["evaluate model with test data<br>\n","predict"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ytestpred =pred_test(train,test,lr,numfeat,catfeat)"]},{"cell_type":"markdown","metadata":{},"source":["fir statistics for train and test"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fit_overview(ytrain,ytrainpred,ytest,ytestpred)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":2}
